{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaryBall/CSML_notes/blob/master/heterograph_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0YeI-TqptCv",
        "outputId": "6fd25238-67c6-4f9d-dd14-4748c1f5a0da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# mount the google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIugSBZApzSk",
        "outputId": "965111e9-a463-4773-f103-7e5417f82286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "11.8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIUV8oebq9kh",
        "outputId": "937d1447-0a24-4614-8c70-26ecd05ebfa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910459 sha256=d7737628ffd8e2d4a9a055f83df6a8aea738ce1a3f4f6adcb7cd0388c23aa964\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.2.0%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (884 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m884.9/884.9 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.22.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.2.0+pt20cu118 torch_cluster-1.6.1+pt20cu118 torch_scatter-2.1.1+pt20cu118 torch_sparse-0.6.17+pt20cu118 torch_spline_conv-1.2.2+pt20cu118\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "# !pip install rdkit\n",
        "# !pip install hydra-core wandb hydra-core ray ray-lightning torchmetrics overrides imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RvYCtJy4h5g",
        "outputId": "7772e151-cf66-4a65-d0ec-16faf65c1813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n",
            "fatal: destination path 'MiDi' already exists and is not an empty directory.\n",
            "/content/MiDi\n"
          ]
        }
      ],
      "source": [
        "%cd content\n",
        "!git clone https://github.com/cvignac/MiDi/\n",
        "%cd MiDi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SaTKOEV5fVf"
      },
      "outputs": [],
      "source": [
        "from src.datasets import qm9_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuqX0T0K-YZg"
      },
      "outputs": [],
      "source": [
        "import hydra\n",
        "import omegaconf\n",
        "\n",
        "@hydra.main(version_base='1.3', config_path='../configs', config_name='config')\n",
        "def get_cfg(cfg: omegaconf.DictConfig):\n",
        "  return cfg\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATs0EKwbBifS"
      },
      "outputs": [],
      "source": [
        "datamodule = qm9_dataset.QM9DataModule(cfg)\n",
        "dataset_infos = qm9_dataset.QM9infos(datamodule=datamodule, cfg=cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p06XLrQgpu9u"
      },
      "source": [
        "# Molecule Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj3aQf7buZTp"
      },
      "source": [
        "## QM9 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vf8KSZgrLzb",
        "outputId": "f1d0308e-9ef0-4ec9-89ea-8f20b0b40933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset: QM9(3000):\n",
            "======================\n",
            "Number of graphs: 3000\n",
            "Number of features: 11\n",
            "Number of classes: 19\n",
            "\n",
            "Data(x=[5, 11], edge_index=[2, 8], edge_attr=[8, 4], y=[1, 19], pos=[5, 3], idx=[1], name='gdb_1', z=[5])\n",
            "===========================================================================================================\n",
            "Number of nodes: 5\n",
            "Number of edges: 8\n",
            "Average node degree: 1.60\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = QM9(root='/tmp/QM9')\n",
        "dataset = dataset[0:3000]\n",
        "\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFG2VK5orL5b",
        "outputId": "4fa7f199-aff6-464a-e394-70188b36755a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training graphs: 2000\n",
            "Number of test graphs: 1000\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(12345)\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "train_dataset = dataset[:2000]\n",
        "test_dataset = dataset[2000:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORTXcSFVrL-A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loNXffqWXpGa"
      },
      "source": [
        "# Synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoV2Hf-GXoj0",
        "outputId": "7fbde438-41e9-4329-e1cc-5cef4a6f4da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All binary combinations: [('A', 'A'), ('A', 'B'), ('A', 'C'), ('A', 'D'), ('B', 'B'), ('B', 'C'), ('B', 'D'), ('C', 'C'), ('C', 'D'), ('D', 'D')]\n",
            "Sampled subset (40%): [('C', 'C'), ('C', 'D'), ('B', 'D'), ('A', 'D')]\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "# Define the nodes\n",
        "nodes = ['A', 'B', 'C', 'D']\n",
        "\n",
        "# Generate all binary combinations\n",
        "combinations = list(itertools.combinations_with_replacement(nodes, 2))\n",
        "\n",
        "# Calculate 40% of the total combinations\n",
        "sample_size = round(len(combinations) * 0.4)\n",
        "\n",
        "# Randomly sample a subset of the combinations\n",
        "subset = random.sample(combinations, sample_size)\n",
        "\n",
        "# Print the results\n",
        "print(\"All binary combinations:\", combinations)\n",
        "print(\"Sampled subset (40%):\", subset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH2NVN2unyNv",
        "outputId": "3483ec26-50cc-4326-f0fb-9fd7ed9bc2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled X: [-0.20645818 -0.83766477 -0.50566071]\n",
            "Sampled Y: [-0.08627419 -0.0929522  -0.99192573]\n",
            "Sampled Z: [-0.16942467 -0.43031945 -1.19557923]\n",
            "X^T * Y = 0.5972526642115094\n",
            "Y^T * Z = 1.2405419193037635\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import random\n",
        "\n",
        "def random_unit_vector(K):\n",
        "    \"\"\"Generate a random K-dimensional unit vector.\"\"\"\n",
        "    v = np.random.randn(K)\n",
        "    return v / np.linalg.norm(v)\n",
        "\n",
        "def sample_vectors(K):\n",
        "    # Generate random K-dimensional unit vectors for X and Y\n",
        "    X = random_unit_vector(K)\n",
        "    Y = random_unit_vector(K)\n",
        "\n",
        "    # Compute the projection of Y onto X\n",
        "    Y_proj_X = np.dot(X, Y) * X\n",
        "\n",
        "    # Compute the orthogonal component of Y with respect to X\n",
        "    Y_orth = Y - Y_proj_X\n",
        "\n",
        "    # Compute Z by adding a scaled orthogonal component of Y to X\n",
        "    Z = X + np.sqrt(1 - np.dot(X, Y)**2) * Y_orth / np.linalg.norm(Y_orth)\n",
        "\n",
        "    return X, Y, Z\n",
        "\n",
        "# Example usage:\n",
        "K = 3\n",
        "\n",
        "X, Y, Z = sample_vectors(K)\n",
        "\n",
        "print(\"Sampled X:\", X)\n",
        "print(\"Sampled Y:\", Y)\n",
        "print(\"Sampled Z:\", Z)\n",
        "print(\"X^T * Y =\", np.dot(X, Y))\n",
        "print(\"Y^T * Z =\", np.dot(Y, Z))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zN617cw9Hl-"
      },
      "source": [
        "# Function for generating Heterogeneous Graphs \n",
        "\n",
        "- with Small world assumption - Watts Strogatz Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "SE4mRj1vguCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ebedb7-0c1a-4a47-d552-02482aa1baee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': 0.2, 'B': 0.2, 'C': 0.2, 'D': 0.2, 'E': 0.2}\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "deque([0])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 26: E\n",
            "deque([26])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 27: D\n",
            "deque([27])\n",
            "D ['C', 'D', 'E']\n",
            "sampled node type for node 28: E\n",
            "D ['C', 'D', 'E']\n",
            "sampled node type for node 2: C\n",
            "deque([28, 2])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 9: D\n",
            "deque([2, 9])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 38: D\n",
            "deque([9, 38])\n",
            "D ['C', 'D', 'E']\n",
            "sampled node type for node 10: C\n",
            "deque([38, 10])\n",
            "deque([10])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 11: B\n",
            "deque([11])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 12: E\n",
            "deque([12])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 13: B\n",
            "deque([13])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 14: C\n",
            "B ['C', 'E']\n",
            "sampled node type for node 33: C\n",
            "deque([14, 33])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 1: B\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 42: A\n",
            "deque([33, 1, 42])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 32: B\n",
            "deque([1, 42, 32])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 46: E\n",
            "deque([42, 32, 46])\n",
            "A ['C']\n",
            "sampled node type for node 4: C\n",
            "A ['C']\n",
            "sampled node type for node 16: C\n",
            "deque([32, 46, 4, 16])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 31: E\n",
            "deque([46, 4, 16, 31])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 37: B\n",
            "E ['B', 'D']\n",
            "sampled node type for node 41: B\n",
            "deque([4, 16, 31, 37, 41])\n",
            "deque([16, 31, 37, 41])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 15: D\n",
            "deque([31, 37, 41, 15])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 30: D\n",
            "E ['B', 'D']\n",
            "sampled node type for node 21: D\n",
            "E ['B', 'D']\n",
            "sampled node type for node 25: B\n",
            "deque([37, 41, 15, 30, 21, 25])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 36: E\n",
            "deque([41, 15, 30, 21, 25, 36])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 40: E\n",
            "deque([15, 30, 21, 25, 36, 40])\n",
            "deque([30, 21, 25, 36, 40])\n",
            "D ['C', 'D', 'E']\n",
            "sampled node type for node 18: C\n",
            "deque([21, 25, 36, 40, 18])\n",
            "D ['C', 'D', 'E']\n",
            "sampled node type for node 20: E\n",
            "deque([25, 36, 40, 18, 20])\n",
            "deque([36, 40, 18, 20])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 35: D\n",
            "E ['B', 'D']\n",
            "sampled node type for node 19: B\n",
            "deque([40, 18, 20, 35, 19])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 39: B\n",
            "deque([18, 20, 35, 19, 39])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 17: A\n",
            "deque([20, 35, 19, 39, 17])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 8: B\n",
            "deque([35, 19, 39, 17, 8])\n",
            "D ['C', 'D', 'E']\n",
            "sampled node type for node 34: C\n",
            "deque([19, 39, 17, 8, 34])\n",
            "deque([39, 17, 8, 34])\n",
            "deque([17, 8, 34])\n",
            "deque([8, 34])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 7: E\n",
            "B ['C', 'E']\n",
            "sampled node type for node 3: C\n",
            "B ['C', 'E']\n",
            "sampled node type for node 24: C\n",
            "B ['C', 'E']\n",
            "sampled node type for node 45: E\n",
            "deque([34, 7, 3, 24, 45])\n",
            "deque([7, 3, 24, 45])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 6: B\n",
            "deque([3, 24, 45, 6])\n",
            "deque([24, 45, 6])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 23: B\n",
            "deque([45, 6, 23])\n",
            "E ['B', 'D']\n",
            "sampled node type for node 44: B\n",
            "deque([6, 23, 44])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 5: E\n",
            "deque([23, 44, 5])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 22: C\n",
            "B ['C', 'E']\n",
            "sampled node type for node 48: C\n",
            "deque([44, 5, 22, 48])\n",
            "B ['C', 'E']\n",
            "sampled node type for node 43: E\n",
            "B ['C', 'E']\n",
            "sampled node type for node 29: E\n",
            "deque([5, 22, 48, 43, 29])\n",
            "deque([22, 48, 43, 29])\n",
            "deque([48, 43, 29])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 47: D\n",
            "deque([43, 29, 47])\n",
            "deque([29, 47])\n",
            "deque([47])\n",
            "D ['C', 'D', 'E']\n",
            "sampled node type for node 49: E\n",
            "deque([49])\n",
            "0 26 B E rel_BE\n",
            "1 14 B C rel_BC\n",
            "1 46 B E rel_BE\n",
            "2 27 C D rel_CD\n",
            "2 38 C D rel_CD\n",
            "3 8 C B rel_BC\n",
            "4 42 C A rel_AC\n",
            "5 6 E B rel_BE\n",
            "6 7 B E rel_BE\n",
            "7 8 E B rel_BE\n",
            "8 20 B E rel_BE\n",
            "8 24 B C rel_BC\n",
            "8 45 B E rel_BE\n",
            "9 10 D C rel_CD\n",
            "9 28 D E rel_DE\n",
            "10 11 C B rel_BC\n",
            "11 12 B E rel_BE\n",
            "12 13 E B rel_BE\n",
            "13 14 B C rel_BC\n",
            "13 33 B C rel_BC\n",
            "14 42 C A rel_AC\n",
            "15 16 D C rel_CD\n",
            "16 41 C B rel_BC\n",
            "16 42 C A rel_AC\n",
            "17 18 A C rel_AC\n",
            "18 30 C D rel_CD\n",
            "19 36 B E rel_BE\n",
            "20 21 E D rel_DE\n",
            "21 31 D E rel_DE\n",
            "22 23 C B rel_BC\n",
            "23 24 B C rel_BC\n",
            "23 48 B C rel_BC\n",
            "25 31 B E rel_BE\n",
            "26 27 E D rel_DE\n",
            "27 28 D E rel_DE\n",
            "29 44 E B rel_BE\n",
            "30 31 D E rel_DE\n",
            "31 32 E B rel_BE\n",
            "32 33 B C rel_BC\n",
            "34 35 C D rel_CD\n",
            "35 36 D E rel_DE\n",
            "36 37 E B rel_BE\n",
            "37 46 B E rel_BE\n",
            "39 40 B E rel_BE\n",
            "40 41 E B rel_BE\n",
            "41 46 B E rel_BE\n",
            "43 44 E B rel_BE\n",
            "44 45 B E rel_BE\n",
            "47 48 D C rel_CD\n",
            "47 49 D E rel_DE\n"
          ]
        }
      ],
      "source": [
        "from IPython.terminal.embed import ultratb\n",
        "import networkx as nx\n",
        "import random\n",
        "from collections import deque\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "def ws_graph (n,k,p):\n",
        "  return nx.watts_strogatz_graph(n, k, p)\n",
        "\n",
        "def get_available_node_types(current_node, graph, meta_graph):\n",
        "    if current_node is not None:\n",
        "      current_node_type = graph.nodes[current_node].get('type')\n",
        "    else:\n",
        "      current_node_type = None\n",
        "    \n",
        "    # process the case when we randomly select a node to start\n",
        "    if not current_node_type:\n",
        "        return list(meta_graph.keys())\n",
        "    else:\n",
        "        return list(meta_graph[current_node_type].keys())\n",
        "\n",
        "\n",
        "def normalize_node_type_prob(available_types, node_type_prob):\n",
        "    total_prob = sum(node_type_prob[available_types].values())\n",
        "    node_type_prob_normalized = {}\n",
        "    for node_type, prob in node_type_prob.items():\n",
        "      normalized_prob = prob / total_prob\n",
        "      node_type_prob_normalized[node_type] = normalized_prob\n",
        "\n",
        "    return node_type_prob_normalized\n",
        "\n",
        "\n",
        "\n",
        "def generate_heterogeneous_small_world(graph, meta_graph, node_type_prob):\n",
        "    # Step 1: Generate a Watts-Strogatz graph\n",
        "    \n",
        "\n",
        "    # Step 2: Normalize node type probabilities\n",
        "    node_type_prob_normalized = {node_type: prob / sum(node_type_prob.values()) for node_type, prob in node_type_prob.items()}\n",
        "    print(node_type_prob_normalized)\n",
        "\n",
        "    # Step 3: Assign node and edge types using BFS\n",
        "    visited = set()\n",
        "    print(graph.nodes())\n",
        "    current_node = None\n",
        "    last_node = None\n",
        "\n",
        "    possible_rel = [(i,j) for i in meta_graph.keys() for j in meta_graph[i].keys()]\n",
        "\n",
        "    for node in graph.nodes():\n",
        "        if node not in visited:\n",
        "            # BFS traversal\n",
        "            queue = deque([node])\n",
        "            \n",
        "            visited.add(node)\n",
        "\n",
        "            while queue:\n",
        "                print(queue)\n",
        "            \n",
        "                current_node = queue.popleft()\n",
        "                \n",
        "                if not graph.nodes[current_node].get('type'):\n",
        "                  possible_start_type = get_available_node_types(current_node, graph, meta_graph)\n",
        "                  sample_prob = [node_type_prob_normalized[node_type] for node_type in possible_start_type]\n",
        "                  node_type = random.choices(possible_start_type, sample_prob, k=1)[0]\n",
        "                  graph.nodes[current_node]['type'] = node_type\n",
        "\n",
        "                available_node_types = get_available_node_types(current_node, graph, meta_graph)\n",
        "\n",
        "                # Assign edge types and add unvisited neighbors to queue\n",
        "                for neighbor in graph.neighbors(current_node):\n",
        "                    if neighbor not in visited:\n",
        "                        # Assign node type\n",
        "                        if not graph.nodes[neighbor].get('type'):\n",
        "                            sample_prob = [node_type_prob_normalized[node_type] for node_type in available_node_types]\n",
        "                            node_type = random.choices(available_node_types, sample_prob, k=1)[0]\n",
        "\n",
        "                            print(graph.nodes[current_node].get('type'), available_node_types)\n",
        "\n",
        "                            print(\"sampled node type for node {vnumber}: {vtype}\".format(vnumber = neighbor, vtype = node_type))\n",
        "                            graph.nodes[neighbor]['type'] = node_type\n",
        "\n",
        "                        queue.append(neighbor)\n",
        "                        visited.add(neighbor)\n",
        "\n",
        "                last_node = current_node\n",
        "            \n",
        "    for u, v  in graph.edges():\n",
        "      if (graph.nodes[u]['type'],graph.nodes[v]['type']) in possible_rel:\n",
        "        print(u,v, graph.nodes[u]['type'], graph.nodes[v]['type'], meta_graph[graph.nodes[u]['type']][graph.nodes[v]['type']])\n",
        "        graph.edges[u, v]['type'] = meta_graph[graph.nodes[u]['type']][graph.nodes[v]['type']]\n",
        "      else:\n",
        "        print(u,v, graph.nodes[u]['type'], graph.nodes[v]['type'], 'NA')\n",
        "        graph.edges[u, v]['type'] = 'NA'\n",
        "    \n",
        "    return graph\n",
        "\n",
        "meta_graph = {\n",
        "    'A': {'C': 'rel_AC'},\n",
        "    'B': {'C': 'rel_BC', 'E': 'rel_BE'},\n",
        "    'C': {'A':'rel_AC','B':'rel_BC', 'D':'rel_CD'},\n",
        "    'D': {'C':'rel_CD','D':'rel_DD', 'E':'rel_DE'}, \n",
        "    'E': {'B':'rel_BE','D':'rel_DE'}\n",
        "}\n",
        "node_type_prob = {'A': 1, 'B': 1, 'C': 1, 'D': 1, 'E':1}\n",
        "num_nodes = 50\n",
        "graph = ws_graph(num_nodes, 3, 0.5)\n",
        "hetero_graph = generate_heterogeneous_small_world(graph, meta_graph, node_type_prob)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0sOim0bXdZ5"
      },
      "source": [
        "## Graph_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfJl6L56XEaN",
        "outputId": "5c680ded-74bc-43dc-cbe4-ac59ad83bf32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rel_AC', 'rel_BC', 'rel_BE', 'rel_CD', 'rel_DD', 'rel_DE']\n"
          ]
        }
      ],
      "source": [
        "# find unique relation types\n",
        "def unique_rel(meta_graph):\n",
        "  unique_elements = set()\n",
        "  for inner_dict in meta_graph.values():\n",
        "    for element in inner_dict.values():\n",
        "      unique_elements.add(element)\n",
        "\n",
        "  return unique_elements\n",
        "\n",
        "print(sorted(unique_rel(meta_graph)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW_oeYMakLA2"
      },
      "source": [
        "$\\nabla(f)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "5Cgh2-WFEfbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "5ef40b42-d45d-4df4-b6d3-f5d4d18a4d1c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos = nx.spring_layout(hetero_graph, seed=0)  # positions for all nodes\n",
        "\n",
        "# nodes\n",
        "options = {\"edgecolors\": \"tab:gray\", \"node_size\": 200, \"alpha\": 0.9}\n",
        "nx.draw_networkx_nodes(hetero_graph, pos, **options)\n",
        "\n",
        "# edges\n",
        "nx.draw_networkx_edges(hetero_graph, pos, width=1.0, alpha=0.5, edge_color=\"tab:red\",)\n",
        "\n",
        "labels = {i: graph.nodes[i]['type']+str(i) for i in range(len(graph.nodes))}\n",
        "nx.draw_networkx_labels(hetero_graph, pos, labels, font_size=5, font_color=\"whitesmoke\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLmE_0IIT1PS",
        "outputId": "011273f5-39e9-478c-abdc-26b6ecd99f93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "def adjacency_tensor(graph, meta_graph):\n",
        "    edge_types = ['rel_'+i+j for i,j in itertools.combinations_with_replacement(meta_graph.keys(), 2)]\n",
        "    n = len(graph.nodes())\n",
        "    r = len(edge_types)\n",
        "\n",
        "    adj_matrices = []\n",
        "\n",
        "    for edge_type in edge_types:\n",
        "        adj_matrix = np.zeros((n, n), dtype=np.int32)\n",
        "        \n",
        "        for u, v, data in graph.edges(data=True):\n",
        "            if data['type'] == edge_type:\n",
        "                adj_matrix[u, v] = 1\n",
        "                adj_matrix[v, u] = 1\n",
        "        \n",
        "        adj_matrices.append(adj_matrix)\n",
        "\n",
        "    edge_dict = {i: edge_types[i] for i in range(len(edge_types))}\n",
        "    return np.stack(adj_matrices, axis=-1), edge_dict\n",
        "\n",
        "adj_tsr, edge_dict = adjacency_tensor(hetero_graph, meta_graph)\n",
        "adj_tsr.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1gvg86mwrY-",
        "outputId": "6b3c76f6-d2de-4068-aac8-703928524620"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 'rel_AA',\n",
              "  1: 'rel_AB',\n",
              "  2: 'rel_AC',\n",
              "  3: 'rel_AD',\n",
              "  4: 'rel_AE',\n",
              "  5: 'rel_BB',\n",
              "  6: 'rel_BC',\n",
              "  7: 'rel_BD',\n",
              "  8: 'rel_BE',\n",
              "  9: 'rel_CC',\n",
              "  10: 'rel_CD',\n",
              "  11: 'rel_CE',\n",
              "  12: 'rel_DD',\n",
              "  13: 'rel_DE',\n",
              "  14: 'rel_EE'},\n",
              " {'A': {'C': 'rel_AC'},\n",
              "  'B': {'C': 'rel_BC', 'E': 'rel_BE'},\n",
              "  'C': {'A': 'rel_AC', 'B': 'rel_BC', 'D': 'rel_CD'},\n",
              "  'D': {'C': 'rel_CD', 'D': 'rel_DD', 'E': 'rel_DE'},\n",
              "  'E': {'B': 'rel_BE', 'D': 'rel_DE'}})"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "edge_dict, meta_graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj_tsr[:,:,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMDF6He8ni1C",
        "outputId": "ed3634c4-f342-4c8f-8749-9e6d5ce73c7c"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQHoxjkgPiwL",
        "outputId": "c7ba6c63-cead-430b-9f9c-88ba0371f38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "1500 100\n"
          ]
        }
      ],
      "source": [
        "def adj_to_cov(W_GT, num_nodes):\n",
        "  # W_GT = nx.adjacency_matrix(hetero_graph).todense()\n",
        "  weights = np.random.lognormal(0, 0.2, (num_nodes, num_nodes))\n",
        "  weights = (weights + weights.T) / 2\n",
        "  \n",
        "  W_GT = W_GT * weights\n",
        "  W_GT = W_GT * num_nodes / (np.sum(W_GT)+1e-10)\n",
        "  L_GT = np.diag(W_GT @ np.ones(num_nodes)) - W_GT\n",
        "  \n",
        "  cov_GT = np.linalg.inv(L_GT + (1e-1) * np.eye(num_nodes))\n",
        "  return cov_GT\n",
        "\n",
        "\n",
        "\n",
        "def generate_rel_signals(num_nodes, adj_tensor, sgl_dim):\n",
        "  noise_sigma = 1e-02\n",
        "  _ ,_, rel_num = adj_tensor.shape\n",
        "  print(rel_num)\n",
        "  emb_dim = sgl_dim * rel_num\n",
        "  print(emb_dim, sgl_dim)\n",
        "  signals_nodes = np.random.multivariate_normal(np.zeros(num_nodes), noise_sigma* np.eye(num_nodes), emb_dim)\n",
        "  signals_edges = np.zeros((rel_num, emb_dim))\n",
        "  \n",
        "  for rel in range(rel_num):\n",
        "    # the dimensions that are specific to relation type\n",
        "    cov = adj_to_cov(adj_tensor[:,:,rel], num_nodes)\n",
        "    # signals_rel = np.random.multivariate_normal(np.zeros(num_nodes), cov, sgl_dim)\n",
        "    # the dimension that is not relevant to relation type\n",
        "    signals_nodes[sgl_dim*rel:sgl_dim*(rel+1)] += np.random.multivariate_normal(np.zeros(num_nodes), cov, sgl_dim)\n",
        "    signals_edges[rel, sgl_dim*rel:sgl_dim*(rel+1)] = 1/sgl_dim\n",
        "  \n",
        "  return signals_nodes.T, signals_edges\n",
        "\n",
        "sgl_dim = 100\n",
        "signal_vtx, signals_edge = generate_rel_signals(num_nodes, adj_tsr, sgl_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MGQCk6cvn5qW"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hqoe5vKr2he"
      },
      "source": [
        "## From signal estimate Laplacian Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "LFELdOO26bcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5495577c-572c-48e3-e093-47c283aaebf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -0.,  0., ...,  0., -0., -0.],\n",
              "       [-0.,  0., -0., ...,  0.,  0., -0.],\n",
              "       [ 0., -0.,  0., ...,  0., -0., -0.],\n",
              "       ...,\n",
              "       [ 0.,  0.,  0., ...,  0., -0., -0.],\n",
              "       [-0.,  0., -0., ..., -0.,  0.,  0.],\n",
              "       [-0., -0., -0., ..., -0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "def estimate_L(sgl_vtx, sgl_edge, dim):\n",
        "  out_product = sgl_vtx[:, np.newaxis, np.newaxis, :] * sgl_vtx[np.newaxis, : ,np.newaxis, :] * sgl_edge[ np.newaxis, np.newaxis, :,  :]\n",
        "  _,_,_,K = out_product.shape\n",
        "  L_hat = np.linalg.inv((np.sum(out_product, axis = 3)[:,:,dim]/K))/K\n",
        "  L_hat_undiag = L_hat *(1 - np.diag(L_hat))\n",
        "  threshold = 0.7*(np.max(L_hat_undiag) - np.min(L_hat_undiag))+ np.min(L_hat_undiag)\n",
        "  L_hat_undiag = (L_hat_undiag > threshold) * L_hat_undiag\n",
        "  L_recover = - np.diag(L_hat_undiag @ np.ones(num_nodes)) + L_hat_undiag\n",
        "  return L_recover\n",
        "\n",
        "estimate_L(signal_vtx, signals_edge, 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ADMM():\n",
        "    def __init__(self, l2_penalty, log_penalty, step_size=1e-02, relaxation_factor = 1.8):\n",
        "        self.alpha = log_penalty  # the penalty before log barrier\n",
        "        self.beta = l2_penalty  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "        self.relax = relaxation_factor\n",
        "\n",
        "    def initialisation(self, l, m, batch_size=1):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        up = y ** 2 + 4 * gn * alpha\n",
        "        up = torch.clamp(up, 1e-08)\n",
        "        return (y - torch.sqrt(up)) / 2\n",
        "\n",
        "    def objective(self, w, D, z):\n",
        "        f1 = self.beta * torch.norm(w, 2) ** 2\n",
        "        f2 = w.T @ z\n",
        "        f3 = - self.alpha * torch.sum(torch.log(D @ w))\n",
        "\n",
        "        if all(np.round(w, 4) >= 0):\n",
        "            return f1 + f2 + f3\n",
        "        else:\n",
        "            return 10**3\n",
        "\n",
        "    def solve(self, smooth, max_iter=1000, verbose=True):\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # D * shift_sum if the new operator\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_ite, l))\n",
        "        # print(w_list.shape)\n",
        "\n",
        "        lambda_ = self.relax\n",
        "\n",
        "        for i in range(max_iter):\n",
        "\n",
        "            y1 = w - self.gn * (2 * self.beta * w + torch.matmul(v, D))\n",
        "            p1 = torch.max(zero_vec, y1 - 2 * self.gn * z)\n",
        "\n",
        "            y2 = v + self.gn * torch.matmul(2 * p1 - w, D.T)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            w = w + lambda_ * (p1 - w)\n",
        "            v = v + lambda_ * (p2 - v)\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n",
        "\n",
        "#%%\n",
        "\n",
        "class PDS():\n",
        "    def __init__(self, l2_psi, log_psi, step_size):\n",
        "        self.alpha = log_psi  # the penalty before log barrier\n",
        "        self.beta = l2_psi  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        return (y - torch.sqrt(y ** 2 + 4 * gn * alpha)) / 2\n",
        "\n",
        "    def initialisation(self, l, m, batch_size):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def solve(self, smooth, max_iter = 500):\n",
        "        # z \\in 1* m* m * r\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_iter, l)).to(device)\n",
        "        for i in range(max_iter):\n",
        "            # print(z.shape)\n",
        "            y1 = w - self.gn * (2 * self.beta * w + 2 * z + torch.matmul(v, D))\n",
        "            y2 = v + self.gn * torch.matmul(w, D.T)\n",
        "\n",
        "            p1 = torch.max(zero_vec, y1)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            q1 = p1 - self.gn * (2 * self.beta * p1 + 2 * z + torch.matmul(p2, D))\n",
        "            q2 = p2 + self.gn * torch.matmul(p1, D.T)\n",
        "\n",
        "            w = w - y1 + q1\n",
        "            v = v - y2 + q2\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n"
      ],
      "metadata": {
        "id": "DiYPmEAFtNai"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "def auc_test(model, loader, device):\n",
        "  preds = []\n",
        "  ground_truths = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  for test_batch in tqdm.tqdm(loader):\n",
        "      test_batch = test_batch.to(device)\n",
        "      preds.append(model(test_batch))\n",
        "      with torch.no_grad():\n",
        "        for edge_type in test_batch.edge_types:\n",
        "          ground_truths.append(test_batch[edge_type].edge_label)\n",
        "  pred = torch.cat(preds, dim=0).cpu().detach().numpy()\n",
        "  # pred = pred/np.max(pred)\n",
        "  ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "  auc = roc_auc_score(ground_truth, pred)\n",
        "  f1 = f1_score(ground_truth, (pred>0.5))\n",
        "  return auc, f1"
      ],
      "metadata": {
        "id": "C927h38nwdmS"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pds_opt = PDS(1, 1, 1e-2)"
      ],
      "metadata": {
        "id": "VYuxhkoA11ve"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def estimate_w(signal_vtx, signals_edge, adj_tensor, optimizer):\n",
        "  diff_tensor = (signal_vtx[:, None, None, :] - signal_vtx[None,: , None, :]) * signals_edge[ None, None, :, :]\n",
        "  diff_tensor = torch.Tensor(diff_tensor)\n",
        "  num_nodes,_,num_relations ,K = diff_tensor.shape\n",
        "  smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "  # est_tensor = torch.exp(- 1/sigma * smooth_tensor)\n",
        "  adj_tensor = torch.Tensor(adj_tensor).unsqueeze(0).to(device)\n",
        "  mask = torch.triu(torch.ones(num_nodes, num_nodes), diagonal=1).bool()\n",
        "  adj_vec = adj_tensor[:, mask].view(1, -1)\n",
        "  print(smooth_tensor.shape)\n",
        "  w = optimizer.solve(smooth_tensor.unsqueeze(0).to(device), max_iter = 500)\n",
        "  # Normalization\n",
        "  w = w/torch.max(w)\n",
        "  GMSE_error = torch.sum(torch.square(w-adj_vec)/(w+1e-12))\n",
        "\n",
        "  num_samples = w.shape[0] * w.shape[1]*w.shape[0]\n",
        "  edge_indices = torch.where(adj_vec == 1)\n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = w[edge_indices]\n",
        "  print(adj_vec[edge_indices])\n",
        "  print(w)\n",
        "  print(out_edges)\n",
        "  link_error = torch.mean(torch.square(adj_vec[edge_indices] - out_edges))\n",
        "  print(GMSE_error/num_samples)\n",
        "  print(torch.sqrt(link_error))\n",
        "  auc = roc_auc_score(adj_vec.to('cpu')[0], w.to('cpu')[0])\n",
        "  f1 = f1_score(adj_vec.to('cpu')[0], (w>0.8).to('cpu')[0])\n",
        "  print(auc, f1)\n",
        "  # auc = roc_auc_score(adj_vec[edge_indices].to('cpu').detach().numpy(), out_edge\n",
        "\n",
        "\n",
        "estimate_w(signal_vtx, signals_edge, adj_tsr, pds_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qm7BNj-oCca",
        "outputId": "bccc4ace-2f79-496a-c75b-bee717597198"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 50, 15])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0780, 0.0017]],\n",
            "       device='cuda:0')\n",
            "tensor([0.9177, 0.7802, 0.8040, 0.9259, 1.0000, 0.8178, 0.9631, 0.8684, 0.8491,\n",
            "        0.7792, 0.7406, 0.8238, 0.8172, 0.8991, 0.9152, 0.8845, 0.8673, 0.8551,\n",
            "        0.8046, 0.8564, 0.8953, 0.9133, 0.8265, 0.9013, 0.9212, 0.8798, 0.8573,\n",
            "        0.8404, 0.8569, 0.8760, 0.8845, 0.8614, 0.8399, 0.8472, 0.8905, 0.8669,\n",
            "        0.8424, 0.7950, 0.8678, 0.9401, 0.8787, 0.8440, 0.8593, 0.8717, 0.8180,\n",
            "        0.8329, 0.8441, 0.8793, 0.8900, 0.9675], device='cuda:0')\n",
            "tensor(0.0442, device='cuda:0')\n",
            "tensor(0.1436, device='cuda:0')\n",
            "0.9994826739427013 0.7419354838709677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "admm_opt = ADMM(l2_penalty=2, log_penalty=1, step_size=1e-02, relaxation_factor = 1.8)\n",
        "estimate_w(signal_vtx, signals_edge, adj_tsr, admm_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k1teprfrc85",
        "outputId": "ea8c3b76-d382-4c2d-8350-8a8a24717f46"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 50, 15])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[ 9.3078e-02, -2.9427e-44,  5.7762e-02,  ..., -2.9427e-44,\n",
            "          1.6641e-01,  9.5891e-02]], device='cuda:0')\n",
            "tensor([0.9519, 0.8509, 0.8758, 0.9388, 1.0000, 0.8812, 0.9650, 0.9385, 0.9189,\n",
            "        0.8664, 0.8285, 0.8937, 0.8985, 0.9194, 0.9301, 0.9270, 0.9160, 0.9065,\n",
            "        0.8700, 0.9062, 0.9256, 0.9198, 0.8712, 0.9219, 0.9439, 0.8959, 0.9051,\n",
            "        0.8782, 0.8873, 0.9201, 0.9253, 0.9095, 0.8782, 0.8949, 0.9091, 0.9214,\n",
            "        0.8798, 0.8581, 0.9152, 0.9520, 0.9108, 0.8998, 0.9200, 0.9185, 0.8673,\n",
            "        0.8894, 0.9047, 0.9358, 0.9261, 0.9774], device='cuda:0')\n",
            "tensor(0.0736, device='cuda:0')\n",
            "tensor(0.0966, device='cuda:0')\n",
            "0.999587448840382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcO5vCZzw4BA"
      },
      "source": [
        "# Graph Sampling from huge heterogeneous graph\n",
        "\n",
        "Loading graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAVnfyAiPXVJ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import DBLP\n",
        "\n",
        "dataset_dblp = DBLP(root='./data/dblp')\n",
        "data = dataset_dblp[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link Prediction"
      ],
      "metadata": {
        "id": "j5A_1jP9rmui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random.mtrand import noncentral_chisquare\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.loader import HGTLoader\n",
        "\n",
        "def data_preprocessing(data):\n",
        "  # node type processing\n",
        "  # for node_type in data.node_types:\n",
        "  #   if data[node_type].x is None:\n",
        "  data['conference'].x = torch.eye(data['conference'].num_nodes)\n",
        "\n",
        "  # edge type processing\n",
        "  edge_onehot = torch.eye(len(data.edge_types))\n",
        "  i=0\n",
        "  for edge_type in data.edge_types:\n",
        "    data[edge_type].x = edge_onehot[i].reshape(1,-1)\n",
        "    i+=1\n",
        "  return data\n",
        "\n",
        "def data_spliting(data):\n",
        "  transform = RandomLinkSplit(num_val=0.3, num_test=0.2, \n",
        "                            is_undirected=True,\n",
        "                            neg_sampling_ratio=1.0,\n",
        "                            add_negative_train_samples=True,\n",
        "                            edge_types=data.edge_types)\n",
        "  train_test_split = transform(data)\n",
        "  data_list = []\n",
        "  for b_data in train_test_split:\n",
        "    b_data.generate_ids()\n",
        "    \n",
        "    for edge_type in b_data.edge_types:\n",
        "      b_data[edge_type].e_id = torch.arange(len(b_data[edge_type].edge_label))\n",
        "      b_data[edge_type].edge_index = b_data[edge_type].edge_label_index\n",
        "      del b_data[edge_type].edge_label_index\n",
        "    data_list.append(b_data)\n",
        "  \n",
        "  return data_list\n",
        "\n",
        "def data_batching(data, batch_size, input_nodes):\n",
        "    loader = HGTLoader(\n",
        "    data,\n",
        "    # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "    num_samples={key: [16] * 4 for key in data.node_types},\n",
        "    # Use a batch size of 128 for sampling training nodes of type paper\n",
        "    batch_size = batch_size,\n",
        "    input_nodes=input_nodes,\n",
        "    )\n",
        "    return loader\n",
        "\n",
        "\n",
        "data = data_preprocessing(data)\n",
        "train_data, val_data, test_data = data_spliting(data)\n",
        "train_loader = data_batching(train_data, 8, ('paper'))\n",
        "val_loader = data_batching(val_data, 8, ('paper'))\n",
        "test_loader = data_batching(test_data, 4, ('paper'))"
      ],
      "metadata": {
        "id": "2k2yyvqZBGAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7_RdFuTdhtB",
        "outputId": "377bace8-a9e6-44f8-d070-a3c9e81f66e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mauthor\u001b[0m={\n",
              "    x=[40, 334],\n",
              "    y=[40],\n",
              "    train_mask=[40],\n",
              "    val_mask=[40],\n",
              "    test_mask=[40],\n",
              "    n_id=[40]\n",
              "  },\n",
              "  \u001b[1mpaper\u001b[0m={\n",
              "    x=[56, 4231],\n",
              "    n_id=[56],\n",
              "    input_id=[8],\n",
              "    batch_size=8\n",
              "  },\n",
              "  \u001b[1mterm\u001b[0m={\n",
              "    x=[64, 50],\n",
              "    n_id=[64]\n",
              "  },\n",
              "  \u001b[1mconference\u001b[0m={\n",
              "    num_nodes=15,\n",
              "    x=[15, 20],\n",
              "    n_id=[15]\n",
              "  },\n",
              "  \u001b[1m(author, to, paper)\u001b[0m={\n",
              "    edge_index=[2, 49],\n",
              "    x=[1, 6],\n",
              "    edge_label=[49],\n",
              "    e_id=[49]\n",
              "  },\n",
              "  \u001b[1m(paper, to, author)\u001b[0m={\n",
              "    edge_index=[2, 34],\n",
              "    x=[1, 6],\n",
              "    edge_label=[34],\n",
              "    e_id=[34]\n",
              "  },\n",
              "  \u001b[1m(paper, to, term)\u001b[0m={\n",
              "    edge_index=[2, 49],\n",
              "    x=[1, 6],\n",
              "    edge_label=[49],\n",
              "    e_id=[49]\n",
              "  },\n",
              "  \u001b[1m(paper, to, conference)\u001b[0m={\n",
              "    edge_index=[2, 2],\n",
              "    x=[1, 6],\n",
              "    edge_label=[2],\n",
              "    e_id=[2]\n",
              "  },\n",
              "  \u001b[1m(term, to, paper)\u001b[0m={\n",
              "    edge_index=[2, 80],\n",
              "    x=[1, 6],\n",
              "    edge_label=[80],\n",
              "    e_id=[80]\n",
              "  },\n",
              "  \u001b[1m(conference, to, paper)\u001b[0m={\n",
              "    edge_index=[2, 51],\n",
              "    x=[1, 6],\n",
              "    edge_label=[51],\n",
              "    e_id=[51]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for edge_type in train_data.edge_types:\n",
        "  print(train_data[edge_type].edge_label.shape)\n",
        "for edge_type in train_data.edge_types:\n",
        "  print(train_data[edge_type].edge_index.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "530j0V6WrgIu",
        "outputId": "a3c3e07d-a9cf-4942-d7ea-1bb8ab6df06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([2, 19646])\n",
            "torch.Size([2, 19646])\n",
            "torch.Size([2, 85810])\n",
            "torch.Size([2, 14330])\n",
            "torch.Size([2, 85810])\n",
            "torch.Size([2, 14330])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_complete_subgraph(subgraph, graph):\n",
        "  for edge_type in subgraph.edge_types:\n",
        "    # assuming edge_index is your edge index tensor with shape [2, E]\n",
        "    # and sampled_nodes is your tensor of node indices to include in the subgraph\n",
        "\n",
        "    # get the start and end nodes for each edge\n",
        "    s_ntype, _, t_ntype = edge_type\n",
        "    s_mapping = {old_id: new_id for new_id, old_id in enumerate(subgraph[s_ntype].n_id.tolist())}\n",
        "    t_mapping = {old_id: new_id for new_id, old_id in enumerate(subgraph[t_ntype].n_id.tolist())}\n",
        "\n",
        "    s_nodes, t_nodes = graph[edge_type].edge_index\n",
        "\n",
        "    # find the indices of the edges where both the start node and end node are in sampled_nodes\n",
        "    mask = (torch.isin(s_nodes, subgraph[s_ntype].n_id) & torch.isin(t_nodes, subgraph[t_ntype].n_id))\n",
        "    print(mask.shape)\n",
        "\n",
        "    # subset the edge index tensor to include only these edges\n",
        "    subgraph_edge_index = graph[edge_type].edge_index[:, mask]\n",
        "    s_idx, t_idx = subgraph_edge_index\n",
        "    new_s_nodes = torch.tensor([s_mapping[node.item()] for node in s_idx])\n",
        "    new_e_nodes = torch.tensor([t_mapping[node.item()] for node in t_idx])\n",
        "\n",
        "    # create a new edge index tensor with the re-indexed node IDs\n",
        "    subgraph[edge_type].edge_index = torch.stack([new_s_nodes, new_e_nodes])\n",
        "    subgraph[edge_type].edge_label = graph[edge_type].edge_label[mask]\n",
        "    subgraph[edge_type].e_id = graph[edge_type].e_id[mask]\n",
        "  \n",
        "  return subgraph\n",
        "\n",
        "for batch in test_loader:\n",
        "  batch = get_complete_subgraph(batch, train_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vv6rioeGWUtD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4820d9d-8278-4804-d98f-4e0ba81a3ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e4ed5aa5c03d>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_complete_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/base.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/node_loader.py\u001b[0m in \u001b[0;36mfilter_fn\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroSamplerOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 data = filter_hetero_data(self.data, out.node, out.row,\n\u001b[0m\u001b[1;32m    155\u001b[0m                                           \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                                           self.node_sampler.edge_permutation)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mfilter_hetero_data\u001b[0;34m(data, node_dict, row_dict, col_dict, edge_dict, perm_dict)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         filter_node_store_(data[node_type], out[node_type],\n\u001b[0;32m--> 137\u001b[0;31m                            node_dict[node_type])\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0medge_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conference'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import HeteroConv, Linear, SAGEConv, HeteroDictLinear\n",
        "\n",
        "class LinearProj(torch.nn.Module):\n",
        "    def __init__(self, node_shape, edge_shape, out_channels):\n",
        "        super().__init__()\n",
        "        self.NodeLinear = HeteroDictLinear(in_channels=node_shape,out_channels=out_channels)\n",
        "        self.EdgeLinear = HeteroDictLinear(in_channels=edge_shape,out_channels=out_channels)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      node_attrs = {node_type: batch[node_type].x for node_type in batch.node_types}\n",
        "      edge_attrs = {'_'.join(edge_type): batch[edge_type].x for edge_type in batch.edge_types}\n",
        "\n",
        "      node_out = self.NodeLinear(node_attrs)\n",
        "      edge_out = self.EdgeLinear(edge_attrs)\n",
        "      \n",
        "      for node_type in batch.node_types:\n",
        "        node_out[node_type] = node_out[node_type]/(node_out[node_type].norm(dim=1)[:, None])\n",
        "      for edge_type in edge_attrs:\n",
        "        edge_out[edge_type] = edge_out[edge_type]/(edge_out[edge_type].norm(dim=1)[:, None])\n",
        "      \n",
        "      \n",
        "\n",
        "      return (node_out, edge_out)\n",
        "\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, s_node_x, t_node_x ,r_emb, edge_index):\n",
        "        sigma = 1e-3\n",
        "        s_idx, t_idx = edge_index[0], edge_index[1]\n",
        "        s_nemb, t_nemb = s_node_x[s_idx], t_node_x[t_idx]\n",
        "        diff_vector = r_emb * (s_nemb - t_nemb)\n",
        "        smooth = torch.exp(- 1/sigma * torch.norm(diff_vector, dim=-1)**2)\n",
        "        # print(diff_vector.shape, torch.norm(diff_vector, dim=-1).shape)\n",
        "        # print(torch.norm(diff_vector, dim=-1)**2)\n",
        "        # smooth = torch.exp(-1/sigma* (torch.norm(diff_vector, dim=-1)))\n",
        "        \n",
        "        return smooth\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, node_shape, edge_shape, out_channels=100):\n",
        "        super().__init__()\n",
        "        self.hetero_linear = LinearProj(node_shape, edge_shape, out_channels=100)\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        node_out, edge_out = self.hetero_linear(batch)\n",
        "        pred_list = []\n",
        "        for edge_type in batch.edge_types:\n",
        "          s_ntype, _, t_ntype = edge_type\n",
        "          s_emb, t_emb = node_out[s_ntype], node_out[t_ntype]\n",
        "          r_emb = edge_out['_'.join(edge_type)]\n",
        "          # print(self.classifier(s_emb, t_emb, r_emb, batch[edge_type].edge_index).shape)\n",
        "          # print('gt: {}'.format(batch[edge_type].edge_label))\n",
        "          # print('pred:{}'.format(self.classifier(s_emb, t_emb, r_emb, batch[edge_type].edge_index)))\n",
        "          pred_list += [self.classifier(s_emb, t_emb, r_emb, batch[edge_type].edge_index)]\n",
        "        pred = torch.cat(pred_list)\n",
        "        return pred"
      ],
      "metadata": {
        "id": "ummtLl6jouRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_shape = {node_type: train_data[node_type].x.shape[-1] for node_type in train_data.node_types}\n",
        "edge_shape = {'_'.join(edge_type): train_data[edge_type].x.shape[-1] for edge_type in train_data.edge_types}\n",
        "\n",
        "model = Model(node_shape, edge_shape, out_channels=100)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "3qFg0FHhpL8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "def auc_test(mode, loader, device):\n",
        "  preds = []\n",
        "  ground_truths = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  for test_batch in tqdm.tqdm(loader):\n",
        "      test_batch = test_batch.to(device)\n",
        "      preds.append(model(test_batch))\n",
        "      with torch.no_grad():\n",
        "        for edge_type in test_batch.edge_types:\n",
        "          ground_truths.append(test_batch[edge_type].edge_label)\n",
        "  pred = torch.cat(preds, dim=0).cpu().detach().numpy()\n",
        "  pred = pred/np.max(pred)\n",
        "  ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "  auc = roc_auc_score(ground_truth, pred)\n",
        "  f1 = f1_score(ground_truth, (pred>0.5))\n",
        "  return auc, f1"
      ],
      "metadata": {
        "id": "tZRbI6I48SDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import HGTLoader\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: '{device}'\")\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, \n",
        "                                        T_0 = 8,# Number of iterations for the first restart\n",
        "                                        T_mult = 1, # A factor increases TiTi​ after a restart\n",
        "                                        eta_min = 1e-5) # Minimum learning rate\n",
        "# Adam best learning rate: 1e-2, sigma= 1e-3, weight decay = 0\n",
        "# SGD best learning rate: 1e-3, decay = 0.1, no sigma\n",
        "\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    total_loss = total_examples = 0\n",
        "    for batch in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch)\n",
        "        \n",
        "        gt_list = []\n",
        "        for edge_type in batch.edge_types:\n",
        "          gt_list.append(batch[edge_type].edge_label)\n",
        "        ground_truth = torch.cat(gt_list)\n",
        "        loss = F.binary_cross_entropy(pred, ground_truth, reduction='mean')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}, learning_rate: {get_lr(optimizer):.4f}\")\n",
        "    if epoch % 10 == 0:\n",
        "      auc_result, f1_sco = auc_test(model,test_loader, device)\n",
        "      print(f\"AUC: {auc_result:.4f}, f1 score: {f1_sco:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek5vyZo9mqNI",
        "outputId": "7c16b13f-22c8-42ac-d5fb-38baad53aaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cuda:0'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1791 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nested/__init__.py:58: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
            "  return torch._nested_tensor_from_tensor_list(tensor_list, dtype, None, device, None)\n",
            "100%|██████████| 1791/1791 [00:36<00:00, 49.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.4249, learning_rate: 0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1791/1791 [00:35<00:00, 50.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.3198, learning_rate: 0.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1791/1791 [00:32<00:00, 54.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.3001, learning_rate: 0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1791/1791 [00:32<00:00, 55.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.2869, learning_rate: 0.0050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 103/1791 [00:02<00:39, 42.98it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auc_result, f1 = auc_test(model,test_loader, device)\n",
        "print(auc_result, f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsNFzMM4D5PF",
        "outputId": "f5f2ccc7-ebf2-4e9a-d78e-fbae0ff064ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3582/3582 [00:31<00:00, 112.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8426684596019349 0.7002689798072096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'gdrive/MyDrive/heterograph_learning/linear_model.pth'\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "NpHhum2n7jNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading model\n",
        "path = 'gdrive/MyDrive/heterograph_learning/linear_model.pth'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX-M3NMwYZow",
        "outputId": "c39f6cf0-f062-462b-c88b-1d849974c4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_adjtensor(batch, node_out, edge_out):\n",
        "  # create an empty dictionary to store the indices\n",
        "  indices_dict = {}\n",
        "  # list to hold the tensors\n",
        "  tensor_list = []\n",
        "  start_index = 0\n",
        "  for node_type in batch.node_types:\n",
        "    node_emb = node_out[node_type]\n",
        "    end_index = start_index + node_emb.size(0)\n",
        "    indices_dict[node_type] = (start_index, end_index)  # store the start and end index for this type\n",
        "    tensor_list.append(node_emb)\n",
        "    start_index = end_index  # update the start index for the next type\n",
        "    # concatenate the tensors\n",
        "\n",
        "  node_tensor = torch.cat(tensor_list, dim=0)\n",
        "\n",
        "  adj_matrices = []\n",
        "  # print('start transforming')\n",
        "  for edge_type in batch.edge_types:\n",
        "    # print(edge_type, batch[edge_type].edge_index)\n",
        "    \n",
        "    if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "        continue\n",
        "    # Initialize the adjacency matrix\n",
        "    N = node_tensor.size(0)\n",
        "    adj_matrix = torch.zeros(N, N)\n",
        "    # Populate the adjacency matrix\n",
        "    s_ntype, _, e_ntype = edge_type\n",
        "    start_indices = indices_dict[s_ntype]\n",
        "    end_indices = indices_dict[e_ntype]\n",
        "\n",
        "    # map the indices in edge_index to their corresponding indices in the big tensor\n",
        "    edge_idx = batch[edge_type].edge_index\n",
        "    edge_label = batch[edge_type].edge_label\n",
        "    edge_idx[0] += start_indices[0]  # add the start index of the start node type to the start nodes in edge_index\n",
        "    edge_idx[1] += end_indices[0]  # add the start index of the end node type to the end nodes in edge_index\n",
        "    \n",
        "    for i in range(edge_idx.shape[1]):\n",
        "      if edge_label[i] == 1:\n",
        "        one_edge = edge_idx[:, i]\n",
        "        adj_matrix[one_edge[0], one_edge[1]] = 1\n",
        "    adj_matrices.append(adj_matrix)\n",
        "\n",
        "  adj_matrices = torch.stack(adj_matrices, dim=-1)\n",
        "  return node_tensor, adj_matrices\n",
        "\n"
      ],
      "metadata": {
        "id": "Jl18YKLh7rmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "step = 0\n",
        "GMSE_error = 0\n",
        "total_samples = 0\n",
        "link_errors = []\n",
        "sigma = 1e-3\n",
        "\n",
        "for batch in tqdm.tqdm(test_loader):\n",
        "  batch.to(device)\n",
        "  model.to(device)\n",
        "  step+=1\n",
        "  node_out, edge_out = model.hetero_linear(batch)\n",
        "  n_emb, adj_tensor = batch_to_adjtensor(batch, node_out, edge_out)\n",
        "  # r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[0] != 0]\n",
        "  r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[-1] != 0]\n",
        "  \n",
        "  r_emb = torch.cat(r_emb, dim=0)\n",
        "  diff_tensor = (n_emb[:, None, None, :] - n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "  num_nodes,_,num_relations ,K = diff_tensor.shape\n",
        "  smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "  est_tensor = torch.exp(- 1/sigma * smooth_tensor)\n",
        "  adj_tensor = adj_tensor.to(device)\n",
        "  GMSE_error += torch.sum(torch.square(est_tensor-adj_tensor))\n",
        "\n",
        "  num_samples = est_tensor.shape[0] * est_tensor.shape[1]*est_tensor.shape[0]\n",
        "  total_samples += num_samples\n",
        "\n",
        "  edge_indices = torch.where(adj_tensor == 1)\n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = est_tensor[edge_indices]\n",
        "  link_error = torch.mean(torch.square(adj_tensor[edge_indices] - out_edges))\n",
        "  link_errors.append(torch.sqrt(link_error))\n",
        "\n",
        "print(GMSE_error/total_samples)\n",
        "print(torch.mean(torch.tensor(link_errors)))\n",
        "\n",
        "# Find the indices of the 1 elements in A\n",
        "\n",
        "'''\n",
        "  # combinations = itertools.combinations_with_replacement(batch.node_types, 2)\n",
        "  # possible_edge =  [(s_type,'to',t_type) for s_type,t_type in combinations]\n",
        "  true_edge_types = batch.edge_types\n",
        "  for edge_type in true_edge_types:\n",
        "    if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "      continue\n",
        "    if edge_type in true_edge_types:\n",
        "      print(batch[edge_type].edge_index)\n",
        "    s_ntype, _ , t_ntype = edge_type\n",
        "    # source node embedding and target node embedding\n",
        "    s_nemb, t_nemb = node_out[s_ntype], node_out[t_ntype]\n",
        "    \n",
        "    n_emb = torch.cat([s_nemb, t_nemb], dim=0)\n",
        "    r_emb = edge_out['_'.join(edge_type)]\n",
        "    out_product = n_emb[:, None, :] * n_emb[None,: , :] * r_emb[0][ None, None, :]\n",
        "    N,_,K = out_product.shape\n",
        "    out_adj = torch.sum(out_product, dim=2)\n",
        "    print(out_adj.shape)\n",
        "    # Use torch.topk to get the indices of K largest entrie\n",
        "    values, indices = torch.topk(out_adj.view(-1), K)\n",
        "    row_indices = indices // N\n",
        "    col_indices = indices % N\n",
        "\n",
        "    indices = torch.stack([row_indices, col_indices], dim=0)\n",
        "    # Convert tensors to sets\n",
        "    true_idx = batch[edge_type].edge_index\n",
        "    true_idx[1] += s_nemb.shape[0]\n",
        "    set1 = set(map(tuple, true_idx.t().tolist()))\n",
        "    set2 = set(map(tuple, indices.t().tolist()))\n",
        "    # Find the difference between sets\n",
        "    print(set1,set2)\n",
        "    acc = len(set1 - set2)/len(set1)\n",
        "    print(acc)\n",
        "'''\n",
        "    \n",
        "  \n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "jy9Uo58f7zSQ",
        "outputId": "b8f70e83-5b64-4ed6-b184-4ac14528d2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 162/1791 [00:04<00:45, 35.60it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-69388b075bb1>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_relations\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0msmooth_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mest_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msmooth_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0madj_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mGMSE_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_tensor\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0madj_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 832.00 KiB free; 13.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(GMSE_error/total_samples)\n",
        "print(torch.mean(torch.tensor(link_errors)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD0Trli-ZW0p",
        "outputId": "e310ce79-6c17-4558-fc90-d19063f121bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5301)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimate adjacency tensor"
      ],
      "metadata": {
        "id": "mIodzxzGQRV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import scipy.sparse as sparse\n",
        "\n",
        "def coo_to_sparseTensor(coo):\n",
        "    values = coo.data\n",
        "    indices = np.vstack((coo.row, coo.col))\n",
        "\n",
        "    i = torch.LongTensor(indices)\n",
        "    v = torch.FloatTensor(values)\n",
        "    shape = coo.shape\n",
        "\n",
        "    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()\n",
        "\n",
        "def get_degree_operator(m):\n",
        "  \n",
        "    ncols =int(m*(m - 1)/2)\n",
        "\n",
        "    I = np.zeros(ncols)\n",
        "    J = np.zeros(ncols)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        I[k:(k + m - i)] = np.arange(i, m)\n",
        "        k = k + (m - i)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        J[k: (k + m - i)] = i - 1\n",
        "        k = k + m - i\n",
        "\n",
        "    Row = np.tile(np.arange(0, ncols), 2)\n",
        "    Col = np.append(I, J)\n",
        "    Data = np.ones(Col.size)\n",
        "    St = sparse.coo_matrix((Data, (Row, Col)), shape=(ncols, m))\n",
        "    return St.T"
      ],
      "metadata": {
        "id": "_n7ldolBQfrN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ADMM():\n",
        "    def __init__(self, l2_penalty, log_penalty, step_size=1e-02, relaxation_factor = 1.8):\n",
        "        self.alpha = log_penalty  # the penalty before log barrier\n",
        "        self.beta = l2_penalty  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "        self.relax = relaxation_factor\n",
        "\n",
        "    def initialisation(self, l, m, batch_size=1):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        up = y ** 2 + 4 * gn * alpha\n",
        "        up = torch.clamp(up, 1e-08)\n",
        "        return (y - torch.sqrt(up)) / 2\n",
        "\n",
        "    def objective(self, w, D, z):\n",
        "        f1 = self.beta * torch.norm(w, 2) ** 2\n",
        "        f2 = w.T @ z\n",
        "        f3 = - self.alpha * torch.sum(torch.log(D @ w))\n",
        "\n",
        "        if all(np.round(w, 4) >= 0):\n",
        "            return f1 + f2 + f3\n",
        "        else:\n",
        "            return 10**3\n",
        "\n",
        "    def solve(self, smooth, max_iter=1000, verbose=True):\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # D * shift_sum if the new operator\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_ite, l))\n",
        "        # print(w_list.shape)\n",
        "\n",
        "        lambda_ = self.relax\n",
        "\n",
        "        for i in range(max_iter):\n",
        "\n",
        "            y1 = w - self.gn * (2 * self.beta * w + torch.matmul(v, D))\n",
        "            p1 = torch.max(zero_vec, y1 - 2 * self.gn * z)\n",
        "\n",
        "            y2 = v + self.gn * torch.matmul(2 * p1 - w, D.T)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            w = w + lambda_ * (p1 - w)\n",
        "            v = v + lambda_ * (p2 - v)\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n",
        "\n",
        "#%%\n",
        "\n",
        "class PDS():\n",
        "    def __init__(self, l2_psi, log_psi, step_size):\n",
        "        self.alpha = log_psi  # the penalty before log barrier\n",
        "        self.beta = l2_psi  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        return (y - torch.sqrt(y ** 2 + 4 * gn * alpha)) / 2\n",
        "\n",
        "    def initialisation(self, l, m, batch_size):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def solve(self, smooth, max_iter = 500):\n",
        "        # z \\in 1* m* m * r\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_iter, l)).to(device)\n",
        "        for i in range(max_iter):\n",
        "            # print(z.shape)\n",
        "            y1 = w - self.gn * (2 * self.beta * w + 2 * z + torch.matmul(v, D))\n",
        "            y2 = v + self.gn * torch.matmul(w, D.T)\n",
        "\n",
        "            p1 = torch.max(zero_vec, y1)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            q1 = p1 - self.gn * (2 * self.beta * p1 + 2 * z + torch.matmul(p2, D))\n",
        "            q2 = p2 + self.gn * torch.matmul(p1, D.T)\n",
        "\n",
        "            w = w - y1 + q1\n",
        "            v = v - y2 + q2\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n"
      ],
      "metadata": {
        "id": "wjO1shkKN5iU"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "step = 0\n",
        "GMSE_error = 0\n",
        "total_samples = 0\n",
        "link_errors = []\n",
        "sigma = 1e-3\n",
        "\n",
        "for batch in tqdm.tqdm(test_loader):\n",
        "  step+=1\n",
        "  batch.to(device)\n",
        "  model.to(device)\n",
        "  pds_opt = PDS(1, 1, 1e-2)\n",
        "  \n",
        "  node_out, edge_out = model.hetero_linear(batch)\n",
        "  n_emb, adj_tensor = batch_to_adjtensor(batch, node_out, edge_out)\n",
        "  # r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[0] != 0]\n",
        "  r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[-1] != 0]\n",
        "  \n",
        "  r_emb = torch.cat(r_emb, dim=0)\n",
        "  diff_tensor = (n_emb[:, None, None, :] - n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "  num_nodes,_,num_relations ,K = diff_tensor.shape\n",
        "  smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "  # est_tensor = torch.exp(- 1/sigma * smooth_tensor)\n",
        "  adj_tensor = adj_tensor.unsqueeze(0).to(device)\n",
        "  mask = torch.triu(torch.ones(num_nodes, num_nodes), diagonal=1).bool()\n",
        "  adj_vec = adj_tensor[:, mask].view(1, -1)\n",
        "  \n",
        "  print(smooth_tensor.shape)\n",
        "  w = pds_opt.solve(smooth_tensor.unsqueeze(0), max_iter = 500)\n",
        "  GMSE_error += torch.sum(torch.square(w-adj_vec))\n",
        "\n",
        "  num_samples = w.shape[0] * w.shape[1]*w.shape[0]\n",
        "  total_samples += num_samples\n",
        "\n",
        "  edge_indices = torch.where(adj_vec == 1)\n",
        "  \n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = w[edge_indices]\n",
        "  print(adj_vec[edge_indices])\n",
        "  print(w)\n",
        "  link_error = torch.mean(torch.square(adj_vec[edge_indices] - out_edges))\n",
        "  link_errors.append(torch.sqrt(link_error))\n",
        "  print(GMSE_error/total_samples)\n",
        "  print(torch.mean(torch.tensor(link_errors)))\n",
        "  # auc = roc_auc_score(adj_vec[edge_indices].to('cpu').detach().numpy(), out_edges.to('cpu').detach().numpy())\n",
        "  # print(auc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Eowy8-Oz7r",
        "outputId": "bd9685ac-0f6e-452b-e493-f531cd53ee80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3582 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([124, 124, 6])\n",
            "torch.Size([1, 45756])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8C3OSs4jQQFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.arange(36).view(3,3,4)"
      ],
      "metadata": {
        "id": "eAyG4X36D1Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_matrix(a, k):\n",
        "    # Create an identity matrix with shape a * b\n",
        "    eye = np.eye(a)\n",
        "\n",
        "    # Repeat each element k times along the column axis\n",
        "    repeated_eye = np.repeat(eye, k, axis=1)\n",
        "\n",
        "    return repeated_eye\n",
        "\n",
        "generate_matrix(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AOCOAEb_8bV",
        "outputId": "f28a9917-c1d1-44fc-852f-05f31a4c26ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnjCbMepfG3I"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import HGTLoader\n",
        "\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "import torch_geometric.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "loader = HGTLoader(\n",
        "  data,\n",
        "  # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "  num_samples={key: [16] * 4 for key in data.node_types},\n",
        "  # Use a batch size of 128 for sampling training nodes of type paper\n",
        "  batch_size=8,\n",
        "  input_nodes=('paper'),\n",
        "  )\n",
        "\n",
        "sampled_hetero_data = next(iter(loader))\n",
        "def connected_graph(sampled_graph):\n",
        "  subsampled_G = sampled_graph.to_homogeneous()\n",
        "  largest_component = T.LargestConnectedComponents(num_components=1, connection = 'strong')(subsampled_G)\n",
        "  adj = to_scipy_sparse_matrix(subsampled_G.edge_index, num_nodes=subsampled_G.num_nodes)\n",
        "  return largest_component, adj\n",
        "\n",
        "connected_subsample, adj = connected_graph(sampled_hetero_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldJSUBTJCQBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWHBVXiljqdb"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "# from torch_geometric.data import dataset\n",
        "def sampling_hetero_graphs(hetero_graph, nnodes_per_type,graph_depth):\n",
        "  input_node = 'paper'\n",
        "  num_samples = 1000\n",
        "  rd_idx = np.random.choice(len(data[input_node].x),num_samples,replace=False)\n",
        "  \n",
        "  loader = HGTLoader(\n",
        "  hetero_graph,\n",
        "  # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "  num_samples={key: [nnodes_per_type] * graph_depth for key in hetero_graph.node_types},\n",
        "  # Use a batch size of 128 for sampling training nodes of type paper\n",
        "  batch_size=1,\n",
        "  input_nodes=(input_node),\n",
        "  )\n",
        "  sub_graphs = []\n",
        "  for idx in rd_idx:\n",
        "    sampled_graph = loader.collate_fn(index=[idx])\n",
        "    connected_subsample, adj = connected_graph(loader.filter_fn(sampled_graph))\n",
        "    sub_graphs.append(connected_subsample)\n",
        "    # sub_graphs.append(sampled_graph)\n",
        "  graph_loader = DataLoader(sub_graphs, batch_size=4, shuffle=False)\n",
        "  return graph_loader\n",
        "\n",
        "data_loader = sampling_hetero_graphs(data, 16, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdkRrtaVA48P"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import HeteroConv, Linear, SAGEConv, HeteroDictLinear\n",
        "\n",
        "class LinearProj(torch.nn.Module):\n",
        "    def __init__(self, node_shape, edge_shape, out_channels):\n",
        "        super().__init__()\n",
        "        self.NodeLinear = HeteroDictLinear(in_channels=node_shape,out_channels=out_channels)\n",
        "        self.EdgeLinear = HeteroDictLinear(in_channels=edge_shape,out_channels=out_channels)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      node_attrs = {node_type: batch[node_type].x for node_type in batch.node_types}\n",
        "      num_edges = {edge_type: len(batch[edge_type].e_id) for edge_type in batch.edge_types}\n",
        "      edge_attrs = {'_'.join(edge_type): batch[edge_type].x.repeat(num_edges[edge_type], 1) for edge_type in batch.edge_types}\n",
        "      node_out = self.NodeLinear(node_attrs)\n",
        "      edge_out = self.EdgeLinear(edge_attrs)\n",
        "      \n",
        "      for node_type in batch.node_types:\n",
        "        node_out[node_type] = node_out[node_type]/(node_out[node_type].norm(dim=1)[:, None])\n",
        "      for edge_type in edge_attrs:\n",
        "        edge_out[edge_type] = edge_out[edge_type]/(edge_out[edge_type].norm(dim=1)[:, None])\n",
        "      \n",
        "\n",
        "      return (node_out, edge_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X86GvFMfdBZf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import numpy as np\n",
        "\n",
        "def neg_sample(batch, s_ntype, s_idx, num_samples):\n",
        "  possible_edge = [(s_type, t_type) for s_type, _ , t_type in batch.edge_types if s_ntype in [s_type, t_type]]\n",
        "  # print(possible_edge)\n",
        "  # possible_edge += [(s_ntype, s_ntype)]\n",
        "  samples = []\n",
        "  for t_type in batch.node_types:\n",
        "    # print(t_type)\n",
        "    if s_ntype == t_type: continue;\n",
        "    if (s_ntype, t_type) not in possible_edge and (t_type, s_ntype) not in possible_edge:\n",
        "      sample = np.random.choice(range(batch[t_type].x.shape[0]), num_samples, replace=True)\n",
        "      samples += [{t_type: val} for val in sample]\n",
        "    # print(samples)\n",
        "  \n",
        "  while len(samples) <= 2*num_samples:\n",
        "    # within type sampling\n",
        "    for t_type in batch.node_types:\n",
        "      if (s_ntype, t_type) in possible_edge:\n",
        "        # print((s_ntype, 'to', t_type))\n",
        "        edge_idx = batch[(s_ntype, 'to', t_type)].edge_index\n",
        "        # print(edge_idx)\n",
        "        # within_samples = negative_sampling(edge_idx, num_neg_samples=num_samples)\n",
        "        # print(edge_idx, s_idx)\n",
        "        indices = torch.where(edge_idx == s_idx)[0]\n",
        "        # Create a list of integers from 0 to 33, excluding 2, 5, and 10\n",
        "        numbers = [i for i in range(batch[t_type].x.shape[0]) if i not in indices.tolist()]\n",
        "        try:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=False)\n",
        "        except:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=True)\n",
        "        samples += [{t_type: idx} for idx in sampled_node]\n",
        "      elif (t_type, s_ntype) in possible_edge:\n",
        "        edge_idx = batch[(t_type, 'to', s_ntype)].edge_index\n",
        "        # within_samples = negative_sampling(edge_idx, num_neg_samples=num_samples)\n",
        "        indices = torch.where(edge_idx == s_idx)[0]\n",
        "        # Create a list of integers from 0 to 33, excluding 2, 5, and 10\n",
        "        numbers = [i for i in range(batch[t_type].x.shape[0]) if i not in indices.tolist()]\n",
        "        try:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=False)\n",
        "        except:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=True)\n",
        "        samples += [{t_type: idx} for idx in sampled_node]\n",
        "  random.shuffle(samples)\n",
        "  samples = samples[0:2*num_samples]\n",
        "  sampels_dict = {}\n",
        "  for t_type in batch.node_types:\n",
        "    element = []\n",
        "    for item in samples:\n",
        "      key = next(iter(item))\n",
        "      if key == t_type:\n",
        "        element += [item[key]]\n",
        "    sampels_dict[t_type] =  torch.LongTensor(element)\n",
        "\n",
        "  return sampels_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvHKpXBDN5D2",
        "outputId": "339709b3-00a5-444c-8ad4-e00a9e7ea808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  \u001b[1mauthor\u001b[0m={\n",
            "    x=[35, 334],\n",
            "    y=[35],\n",
            "    train_mask=[35],\n",
            "    val_mask=[35],\n",
            "    test_mask=[35],\n",
            "    n_id=[35]\n",
            "  },\n",
            "  \u001b[1mpaper\u001b[0m={\n",
            "    x=[56, 4231],\n",
            "    n_id=[56],\n",
            "    input_id=[8],\n",
            "    batch_size=8\n",
            "  },\n",
            "  \u001b[1mterm\u001b[0m={\n",
            "    x=[64, 50],\n",
            "    n_id=[64]\n",
            "  },\n",
            "  \u001b[1mconference\u001b[0m={\n",
            "    num_nodes=11,\n",
            "    x=[11, 20],\n",
            "    n_id=[11]\n",
            "  },\n",
            "  \u001b[1m(author, to, paper)\u001b[0m={\n",
            "    edge_index=[2, 63],\n",
            "    x=[6],\n",
            "    e_id=[63]\n",
            "  },\n",
            "  \u001b[1m(paper, to, author)\u001b[0m={\n",
            "    edge_index=[2, 63],\n",
            "    x=[6],\n",
            "    e_id=[63]\n",
            "  },\n",
            "  \u001b[1m(paper, to, term)\u001b[0m={\n",
            "    edge_index=[2, 90],\n",
            "    x=[6],\n",
            "    e_id=[90]\n",
            "  },\n",
            "  \u001b[1m(paper, to, conference)\u001b[0m={\n",
            "    edge_index=[2, 3],\n",
            "    x=[6],\n",
            "    e_id=[3]\n",
            "  },\n",
            "  \u001b[1m(term, to, paper)\u001b[0m={\n",
            "    edge_index=[2, 143],\n",
            "    x=[6],\n",
            "    e_id=[143]\n",
            "  },\n",
            "  \u001b[1m(conference, to, paper)\u001b[0m={\n",
            "    edge_index=[2, 52],\n",
            "    x=[6],\n",
            "    e_id=[52]\n",
            "  }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for batch in loader:\n",
        "  print(batch)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGIS3gw65ky1"
      },
      "outputs": [],
      "source": [
        "def loss_ns(embs, neg_embs, sigma = 0.01):\n",
        "  # loss with negative sampling\n",
        "  s_emb, r_emb, t_emb = embs\n",
        "  diff_vector = r_emb * (s_emb - t_emb)\n",
        "  smooth = - 1/sigma * torch.diagonal(diff_vector @ diff_vector.t())\n",
        "  diff_neg = r_emb[None,:,:] * (s_emb[None,:,:] - neg_embs)\n",
        "  # N \\times neg_sample \\times K -> N * neg_sample \\times K\n",
        "  inner_product = torch.bmm(diff_neg, diff_neg.permute(0,2,1))\n",
        "  diagonal = torch.diagonal(inner_product, dim1 = 1, dim2= 2)\n",
        "  smooth_neg = torch.sum(torch.exp( - 1/sigma * diagonal), dim=0) + torch.exp(smooth)\n",
        "  # print(torch.exp(smooth)/smooth_neg)\n",
        "  loss = - torch.sum(torch.log(torch.exp(smooth)/smooth_neg))\n",
        "  # loss = - torch.sum(torch.exp(smooth)/smooth_neg)\n",
        "  # loss = torch.sum(smooth - torch.log(smooth_neg))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cynixjstWlZR"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loader, device):\n",
        "    total_examples = total_loss = 0\n",
        "    \"\"\"\n",
        "    for batch in loader:\n",
        "      for edge_type in batch.edge_types:\n",
        "          if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "            continue\n",
        "          s_ntype, _ , t_ntype = edge_type\n",
        "          # source node index and target node idx\n",
        "          s_idx, t_idx  = batch[edge_type].edge_index\n",
        "          for s in s_idx:\n",
        "            samples = neg_sample(batch, s_ntype, s, 5)\n",
        "    \"\"\"\n",
        "    step=0\n",
        "    for batch in loader:\n",
        "        step += 1\n",
        "        if step == 100:break;\n",
        "        optimizer.zero_grad()\n",
        "        batch_size = batch['paper'].batch_size\n",
        "        batch = batch.to(device)\n",
        "        node_out, edge_out = model(batch)\n",
        "        loss = 0\n",
        "        num_edges = 0\n",
        "        \n",
        "        for edge_type in batch.edge_types:\n",
        "          if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "            continue\n",
        "          num_edges += batch[edge_type].edge_index.shape[1]\n",
        "          # source node type and target node type\n",
        "          s_ntype, _ , t_ntype = edge_type\n",
        "          # source node index and target node idx\n",
        "          s_idx, t_idx  = batch[edge_type].edge_index\n",
        "          # source node embedding and target node embedding\n",
        "          s_nemb, t_nemb = node_out[s_ntype][s_idx], node_out[t_ntype][t_idx]\n",
        "          # relation embedding\n",
        "          r_emb = edge_out['_'.join(edge_type)]\n",
        "          tensor_list = []\n",
        "          for s in s_idx:\n",
        "            samples = neg_sample(batch, s_ntype, s, 5)\n",
        "\n",
        "            neg_emb_list = []\n",
        "            for node_type, idx_tensor in samples.items():\n",
        "              if idx_tensor is not None:\n",
        "                neg_emb_list += [node_out[node_type][idx_tensor]]\n",
        "            tensor_list += [torch.cat(neg_emb_list, dim=0)]\n",
        "          \n",
        "          neg_emb = torch.stack(tensor_list, dim=0).permute(1,0,2)\n",
        "          \n",
        "          # print(neg_emb.shape)\n",
        "          # print(s_nemb.shape, t_nemb.shape, r_emb.shape)\n",
        "          loss += loss_ns((s_nemb, r_emb, t_nemb), neg_emb, sigma = 1e-3)\n",
        "          \n",
        "          # diff_vector = r_emb * (s_nemb - t_nemb)\n",
        "          # loss += torch.trace(diff_vector.t() @ diff_vector)\n",
        "        # loss = loss / num_edges\n",
        "        # print('Your bullshit training process: step {}, loss {}'.format(step, loss))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_loss += float(loss) * batch_size\n",
        "\n",
        "    return total_loss / total_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "ikzVN0S0extJ",
        "outputId": "f80da534-17d3-41c8-bf5e-f4ea4bac2dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 596.065084129873, epoch: 1\n",
            "loss: 372.0150146484375, epoch: 2\n",
            "loss: 307.96123543170967, epoch: 3\n",
            "loss: 275.6006227743746, epoch: 4\n",
            "loss: 253.29685789166075, epoch: 5\n",
            "loss: 244.41133672540838, epoch: 6\n",
            "loss: 239.55379478377526, epoch: 7\n",
            "loss: 233.59777955334596, epoch: 8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-64f20fafa9a9>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: {}, epoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-99e5c0013e1a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0mtensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_ntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mneg_emb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-301ba4b60674>\u001b[0m in \u001b[0;36mneg_sample\u001b[0;34m(batch, s_ntype, s_idx, num_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Create a list of integers from 0 to 33, excluding 2, 5, and 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0msampled_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-301ba4b60674>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Create a list of integers from 0 to 33, excluding 2, 5, and 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0msampled_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loader = HGTLoader(\n",
        "  data,\n",
        "  # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "  num_samples={key: [16] * 4 for key in data.node_types},\n",
        "  # Use a batch size of 128 for sampling training nodes of type paper\n",
        "  batch_size=8,\n",
        "  input_nodes=('paper'),\n",
        "  )\n",
        "device = 'cuda:0'\n",
        "node_shape = {node_type: data[node_type].x.shape[-1] for node_type in data.node_types}\n",
        "edge_shape = {'_'.join(edge_type): data[edge_type].x.shape[-1] for edge_type in data.edge_types}\n",
        "model = LinearProj(node_shape, edge_shape, 100)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=0.001)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "  model.train()\n",
        "  loss = train(model, optimizer, loader, device)\n",
        "  print('loss: {}, epoch: {}'.format(loss, epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22yPa42lNwFx"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "model2 = copy.deepcopy(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-bTUsiFQPgD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "7zJB7rfelb-h",
        "outputId": "53aa1bc0-96d1-4649-bb8a-a3464e9e65b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.7781e-05, grad_fn=<DivBackward0>)\n",
            "tensor(0.9894)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n  # combinations = itertools.combinations_with_replacement(batch.node_types, 2)\\n  # possible_edge =  [(s_type,'to',t_type) for s_type,t_type in combinations]\\n  true_edge_types = batch.edge_types\\n  for edge_type in true_edge_types:\\n    if batch[edge_type].edge_index.shape[-1] ==0:\\n      continue\\n    if edge_type in true_edge_types:\\n      print(batch[edge_type].edge_index)\\n    s_ntype, _ , t_ntype = edge_type\\n    # source node embedding and target node embedding\\n    s_nemb, t_nemb = node_out[s_ntype], node_out[t_ntype]\\n    \\n    n_emb = torch.cat([s_nemb, t_nemb], dim=0)\\n    r_emb = edge_out['_'.join(edge_type)]\\n    out_product = n_emb[:, None, :] * n_emb[None,: , :] * r_emb[0][ None, None, :]\\n    N,_,K = out_product.shape\\n    out_adj = torch.sum(out_product, dim=2)\\n    print(out_adj.shape)\\n    # Use torch.topk to get the indices of K largest entrie\\n    values, indices = torch.topk(out_adj.view(-1), K)\\n    row_indices = indices // N\\n    col_indices = indices % N\\n\\n    indices = torch.stack([row_indices, col_indices], dim=0)\\n    # Convert tensors to sets\\n    true_idx = batch[edge_type].edge_index\\n    true_idx[1] += s_nemb.shape[0]\\n    set1 = set(map(tuple, true_idx.t().tolist()))\\n    set2 = set(map(tuple, indices.t().tolist()))\\n    # Find the difference between sets\\n    print(set1,set2)\\n    acc = len(set1 - set2)/len(set1)\\n    print(acc)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "step = 0\n",
        "model = model.to('cpu')\n",
        "GMSE_error = 0\n",
        "total_samples = 0\n",
        "link_errors = []\n",
        "\n",
        "for batch in loader:\n",
        "  step+=1\n",
        "  if step <= 100:\n",
        "    continue\n",
        "  \n",
        "  if step ==200:\n",
        "    break\n",
        "\n",
        "  node_out, edge_out = model(batch)\n",
        "  n_emb, adj_matrices = batch_to_adjtensor(batch, node_out, edge_out)\n",
        "  r_emb = [e_tensor[0] for e_type, e_tensor in edge_out.items() if e_tensor.shape[0] != 0]\n",
        "  r_emb = torch.stack(r_emb, dim=0)\n",
        "  out_product = n_emb[:, None, None, :] * n_emb[None,: , None, :] * r_emb[ None, None, :, :]\n",
        "  num_nodes,_,num_relations ,K = out_product.shape\n",
        "  out_adj = torch.sum(out_product, dim=3)\n",
        "  # print(out_adj, adj_matrices)\n",
        "  GMSE_error += torch.sum(torch.square(out_adj-adj_matrices))\n",
        "  num_samples = out_adj.shape[0] * out_adj.shape[1]*out_adj.shape[0]\n",
        "  total_samples += num_samples\n",
        "\n",
        "  edge_indices = torch.where(adj_matrices == 1)\n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = out_adj[edge_indices]\n",
        "  link_error = torch.mean(torch.square(adj_matrices[edge_indices] - out_edges))\n",
        "  link_errors.append(link_error)\n",
        "\n",
        "print(GMSE_error/total_samples)\n",
        "print(torch.mean(torch.tensor(link_errors)))\n",
        "\n",
        "# Find the indices of the 1 elements in A\n",
        "\n",
        "'''\n",
        "  # combinations = itertools.combinations_with_replacement(batch.node_types, 2)\n",
        "  # possible_edge =  [(s_type,'to',t_type) for s_type,t_type in combinations]\n",
        "  true_edge_types = batch.edge_types\n",
        "  for edge_type in true_edge_types:\n",
        "    if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "      continue\n",
        "    if edge_type in true_edge_types:\n",
        "      print(batch[edge_type].edge_index)\n",
        "    s_ntype, _ , t_ntype = edge_type\n",
        "    # source node embedding and target node embedding\n",
        "    s_nemb, t_nemb = node_out[s_ntype], node_out[t_ntype]\n",
        "    \n",
        "    n_emb = torch.cat([s_nemb, t_nemb], dim=0)\n",
        "    r_emb = edge_out['_'.join(edge_type)]\n",
        "    out_product = n_emb[:, None, :] * n_emb[None,: , :] * r_emb[0][ None, None, :]\n",
        "    N,_,K = out_product.shape\n",
        "    out_adj = torch.sum(out_product, dim=2)\n",
        "    print(out_adj.shape)\n",
        "    # Use torch.topk to get the indices of K largest entrie\n",
        "    values, indices = torch.topk(out_adj.view(-1), K)\n",
        "    row_indices = indices // N\n",
        "    col_indices = indices % N\n",
        "\n",
        "    indices = torch.stack([row_indices, col_indices], dim=0)\n",
        "    # Convert tensors to sets\n",
        "    true_idx = batch[edge_type].edge_index\n",
        "    true_idx[1] += s_nemb.shape[0]\n",
        "    set1 = set(map(tuple, true_idx.t().tolist()))\n",
        "    set2 = set(map(tuple, indices.t().tolist()))\n",
        "    # Find the difference between sets\n",
        "    print(set1,set2)\n",
        "    acc = len(set1 - set2)/len(set1)\n",
        "    print(acc)\n",
        "'''\n",
        "    \n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gzov4LywHNS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Assuming you have two tensors of shape 2xK\n",
        "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor2 = torch.tensor([[1, 2, 7], [4, 5, 8]])\n",
        "\n",
        "# Convert tensors to sets\n",
        "set1 = set(map(tuple, tensor1.t().tolist()))\n",
        "set2 = set(map(tuple, tensor2.t().tolist()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8NC_dn_usa4"
      },
      "outputs": [],
      "source": [
        "tensor = torch.Tensor([[2,3,4], [1,3,5], [2,1,2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agb4FT7cuZGF",
        "outputId": "11e4845d-592e-41df-9d23-a5893516ef07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 0, 0])\n",
            "tensor([2, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "# Use torch.topk to get the indices of K largest entries\n",
        "values, indices = torch.topk(tensor.view(-1), 3)\n",
        "\n",
        "row_indices = indices // 3\n",
        "col_indices = indices % 3\n",
        "\n",
        "print(row_indices)  # Output: tensor of row indices of K largest entries\n",
        "print(col_indices)  # Output: tensor of column indices of K largest entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtGMZeVVfNeR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def estimate_L(batch):\n",
        "  out_product = sgl_vtx[:, np.newaxis, np.newaxis, :] * sgl_vtx[np.newaxis, : ,np.newaxis, :] * sgl_edge[ np.newaxis, np.newaxis, :,  :]\n",
        "  _,_,_,K = out_product.shape\n",
        "  L_hat = np.linalg.inv((np.sum(out_product, axis = 3)[:,:,dim]/K))/K\n",
        "  L_hat_undiag = L_hat *(1 - np.diag(L_hat))\n",
        "  threshold = 0.7*(np.max(L_hat_undiag) - np.min(L_hat_undiag))+ np.min(L_hat_undiag)\n",
        "  L_hat_undiag = (L_hat_undiag > threshold) * L_hat_undiag\n",
        "  L_recover = - np.diag(L_hat_undiag @ np.ones(num_nodes)) + L_hat_undiag\n",
        "  return L_recover\n",
        "\n",
        "estimate_L(signal_vtx, signals_edge, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQnqGi7doWRo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7ZEHHgXfN5v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SSdxgODUShW",
        "outputId": "a7fc83d6-e5de-4ecd-8a03-b6b9a45533ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([72, 100])"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_type = batch.edge_types[0]\n",
        "_idx = batch[edge_type].edge_index\n",
        "node_out[edge_type[0]][edge_idx[0]].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4P_wgOmCF59",
        "outputId": "0c00329b-d8cb-42e3-cff9-4204cce02d32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import networkx as nx\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "\n",
        "sampled_graph = to_networkx(graph, to_undirected=True).copy()\n",
        "nx.is_connected(sampled_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP4WXq626tDf"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.sampler import (\n",
        "    BaseSampler,\n",
        "    HeteroSamplerOutput,\n",
        "    NodeSamplerInput,\n",
        "    SamplerOutput,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "input_data = NodeSamplerInput(\n",
        "            input_id=input_id,\n",
        "            node=input_nodes,\n",
        "            time=input_time,\n",
        "            input_type=input_type,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEw02Pydg1xi",
        "outputId": "c0645ac5-f42e-440e-ae6f-f9818bdb62e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 819], y=[291], train_mask=[291], val_mask=[291], test_mask=[291], n_id=[291], input_id=[260], e_id=[819], node_type=[291], edge_type=[819])"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "connected_subsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C8htE37KICW",
        "outputId": "23777891-8a76-4cf6-eef9-90191a365d49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsARKBE7gsql",
        "outputId": "0d42900f-a36f-41ba-db4e-82f2bae37e9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2., 3., 3., 2., 3., 2., 3., 2., 3., 2., 1., 3., 1., 3., 3., 2., 4.,\n",
              "       2., 4., 3., 1., 3., 1., 2., 2., 1., 3., 3., 2., 2., 3., 4., 3., 1.,\n",
              "       2., 1., 1., 2., 1., 1., 1., 1., 3., 2., 2., 3., 2., 2., 1., 1., 1.,\n",
              "       1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2.,\n",
              "       1., 1., 2., 4., 7., 3., 4., 5., 3., 4., 6., 2., 5., 4., 4., 4., 6.,\n",
              "       3., 2., 3., 1., 4., 4., 2., 5., 3., 5., 3., 4., 2., 3., 4., 5., 3.,\n",
              "       2., 4., 2., 2., 4., 3., 3., 3., 2., 2., 3., 1., 3., 2., 1., 3., 2.,\n",
              "       2., 5., 4., 3., 2., 2., 3., 2., 3., 2., 2., 1., 3., 3., 3., 4., 4.,\n",
              "       6., 4., 3., 3., 2., 1., 5., 3., 4., 4., 4., 3., 3., 5., 2., 3., 2.,\n",
              "       3., 2., 2., 2., 4., 2., 3., 1., 2., 1., 1., 3., 1., 2., 2., 2., 4.,\n",
              "       1., 1., 3., 1., 3., 1., 1., 2., 2., 3., 3., 1., 2., 4., 2., 2., 3.,\n",
              "       2., 1., 2., 3., 1., 2., 1., 1., 2., 1., 1., 4., 1., 3., 2., 2., 4.,\n",
              "       1., 3., 1., 1., 4., 2., 3., 2., 2., 2., 3., 2., 1., 1., 1., 2., 1.,\n",
              "       2., 2., 1., 1., 1., 2., 2., 3., 3., 1., 1., 1., 2., 4., 1., 1., 2.,\n",
              "       2., 1., 2., 1., 1., 2., 2., 1., 4., 3., 2., 2., 2., 4., 1., 1., 2.,\n",
              "       2., 2., 1., 2., 1., 3., 2., 1., 2., 1., 2., 1., 2., 2., 2., 1., 1.,\n",
              "       5., 2., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 3.,\n",
              "       2., 1.])"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adj = nx.adjacency_matrix(sampled_graph)\n",
        "adj @ np.ones(adj.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5MAQRpxCuex",
        "outputId": "0728d042-d6f9-48b8-9c17-c3d31f943c91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://docs.google.com/uc?export=download&id=1Juwx8HtDwSzmVIJ31ooVa1WljI4U5JnA&confirm=t\n",
            "Downloading https://docs.google.com/uc?export=download&id=1Zy6BZH_zLEjKlEFSduKE5tV9qqA_8VtM&confirm=t\n",
            "Downloading https://docs.google.com/uc?export=download&id=1VUcBGr0T0-klqerjAjxRmAqFuld_SMWU&confirm=t\n",
            "Downloading https://docs.google.com/uc?export=download&id=1NI5pa5Chpd-52eSmLW60OnB3WS5ikxq_&confirm=t\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import Yelp\n",
        "\n",
        "dataset_yelp = Yelp(root='./data/yelp')\n",
        "data = dataset_yelp[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZMmysc-P7GZ",
        "outputId": "296da5e1-5c56-4335-8d69-cf5251a968f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mauthor\u001b[0m={\n",
              "    x=[4057, 334],\n",
              "    y=[4057],\n",
              "    train_mask=[4057],\n",
              "    val_mask=[4057],\n",
              "    test_mask=[4057]\n",
              "  },\n",
              "  \u001b[1mpaper\u001b[0m={ x=[14328, 4231] },\n",
              "  \u001b[1mterm\u001b[0m={ x=[7723, 50] },\n",
              "  \u001b[1mconference\u001b[0m={ num_nodes=20 },\n",
              "  \u001b[1m(author, to, paper)\u001b[0m={ edge_index=[2, 19645] },\n",
              "  \u001b[1m(paper, to, author)\u001b[0m={ edge_index=[2, 19645] },\n",
              "  \u001b[1m(paper, to, term)\u001b[0m={ edge_index=[2, 85810] },\n",
              "  \u001b[1m(paper, to, conference)\u001b[0m={ edge_index=[2, 14328] },\n",
              "  \u001b[1m(term, to, paper)\u001b[0m={ edge_index=[2, 85810] },\n",
              "  \u001b[1m(conference, to, paper)\u001b[0m={ edge_index=[2, 14328] }\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pXEs1ZDPl7C",
        "outputId": "106df31a-49c7-452d-80b2-4d4ddefb6518"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['author', 'paper', 'term', 'conference']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.node_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYQWLUBuE4hA",
        "outputId": "e51f361a-ba46-4097-d152-5d8a7d6c7957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[716847, 300], edge_index=[2, 13954819], y=[716847, 100], train_mask=[716847], val_mask=[716847], test_mask=[716847])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "hztECn9nSRjS",
        "outputId": "14f721e4-b57a-449b-fa0e-c25f13224fca"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-68c32fbf02bf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/hetero_data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dict$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         raise AttributeError(f\"'{self.__class__.__name__}' has no \"\n\u001b[0m\u001b[1;32m    138\u001b[0m                              f\"attribute '{key}'\")\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'HeteroData' has no attribute 'edge_weights'"
          ]
        }
      ],
      "source": [
        "data.edge_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5weNBoVJGBP"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Flickr\n",
        "\n",
        "dataset_flickr = Flickr(root='./data/Flickr')\n",
        "data = dataset_flickr[0]\n",
        "row, col = data.edge_index\n",
        "data.edge_weight = 1. / degree(col, data.num_nodes)[col]  # Norm by in-degree.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4Z-X1b8J1TD",
        "outputId": "a0ff544e-e38d-4ef3-da26-4b26068690f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[89250, 500], edge_index=[2, 899756], y=[89250], train_mask=[89250], val_mask=[89250], test_mask=[89250], edge_weight=[899756])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "JnjI6nUOQVvL",
        "outputId": "1aa92070-1d15-4c2c-face-03b23c05a526"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-a3f9872efa3a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m loader = GraphSAINTRandomWalkSampler(data, batch_size=60, walk_length=2,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                      \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_coverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                      \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                      num_workers=4)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/graph_saint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, batch_size, walk_length, num_steps, sample_coverage, save_dir, log, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m                  save_dir: Optional[str] = None, log: bool = True, **kwargs):\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalk_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         super().__init__(data, batch_size, num_steps, sample_coverage,\n\u001b[0m\u001b[1;32m    210\u001b[0m                          save_dir, log, **kwargs)\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/graph_saint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, batch_size, num_steps, sample_coverage, save_dir, log, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'collate_fn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m'node_norm'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m'edge_norm'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/hetero_data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dict$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         raise AttributeError(f\"'{self.__class__.__name__}' has no \"\n\u001b[0m\u001b[1;32m    138\u001b[0m                              f\"attribute '{key}'\")\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'HeteroData' has no attribute 'edge_index'"
          ]
        }
      ],
      "source": [
        "loader = GraphSAINTRandomWalkSampler(data, batch_size=60, walk_length=2,\n",
        "                                     num_steps=5, sample_coverage=100,\n",
        "                                     save_dir=dataset.processed_dir,\n",
        "                                     num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NvsJkE4QV0U",
        "outputId": "3497ac1c-dd5e-4948-bb16-ab0adb51f4f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([176])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loader[2][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "KDa-VVF6Hhl6",
        "outputId": "314620e1-e100-448f-eb18-45ab564e7e31"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-34e6c4d6b3d6>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Norm by in-degree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/hetero_data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dict$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         raise AttributeError(f\"'{self.__class__.__name__}' has no \"\n\u001b[0m\u001b[1;32m    138\u001b[0m                              f\"attribute '{key}'\")\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'HeteroData' has no attribute 'edge_index'"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
        "from torch_geometric.nn import GraphConv\n",
        "from torch_geometric.typing import WITH_TORCH_SPARSE\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "row, col = data.edge_index\n",
        "data.edge_weight = 1. / degree(col, data.num_nodes)[col]  # Norm by in-degree.\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--use_normalization', action='store_true')\n",
        "args = parser.parse_args()\n",
        "\n",
        "loader = GraphSAINTRandomWalkSampler(data, batch_size=6000, walk_length=2,\n",
        "                                     num_steps=5, sample_coverage=100,\n",
        "                                     save_dir=dataset.processed_dir,\n",
        "                                     num_workers=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOXjEDiKEm6E"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import IMDB\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "transform = T.ToUndirected()  # Add reverse edge types.\n",
        "data = IMDB(root='./data', transform=transform)[0]\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    data,\n",
        "    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
        "    num_neighbors=[3] * 2,\n",
        "    # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
        "    batch_size=128,\n",
        "    input_nodes=('director'),\n",
        ")\n",
        "\n",
        "batch = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "c_6Q_5A0Gf_t",
        "outputId": "e4405c51-13ee-42c0-af23-22f71596ebb7"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1edc02ae0fde>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/convert.py\u001b[0m in \u001b[0;36mto_networkx\u001b[0;34m(data, node_attrs, edge_attrs, graph_attrs, to_undirected, remove_self_loops)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_attrs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0medge_attrs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgraph_attrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'HeteroData' object is not callable"
          ]
        }
      ],
      "source": [
        "to_networkx(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-wrRlckF375",
        "outputId": "80810fe1-bfc3-458e-bea4-80633984d088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mmovie\u001b[0m={\n",
              "    x=[225, 3066],\n",
              "    y=[225],\n",
              "    train_mask=[225],\n",
              "    val_mask=[225],\n",
              "    test_mask=[225],\n",
              "    n_id=[225],\n",
              "    num_sampled_nodes=[3]\n",
              "  },\n",
              "  \u001b[1mdirector\u001b[0m={\n",
              "    x=[128, 3066],\n",
              "    n_id=[128],\n",
              "    num_sampled_nodes=[3],\n",
              "    input_id=[128],\n",
              "    batch_size=128\n",
              "  },\n",
              "  \u001b[1mactor\u001b[0m={\n",
              "    x=[584, 3066],\n",
              "    n_id=[584],\n",
              "    num_sampled_nodes=[3]\n",
              "  },\n",
              "  \u001b[1m(movie, to, director)\u001b[0m={\n",
              "    edge_index=[2, 199],\n",
              "    e_id=[199],\n",
              "    num_sampled_edges=[2]\n",
              "  },\n",
              "  \u001b[1m(movie, to, actor)\u001b[0m={\n",
              "    edge_index=[2, 0],\n",
              "    e_id=[0],\n",
              "    num_sampled_edges=[2]\n",
              "  },\n",
              "  \u001b[1m(director, to, movie)\u001b[0m={\n",
              "    edge_index=[2, 225],\n",
              "    e_id=[225],\n",
              "    num_sampled_edges=[2]\n",
              "  },\n",
              "  \u001b[1m(actor, to, movie)\u001b[0m={\n",
              "    edge_index=[2, 675],\n",
              "    e_id=[675],\n",
              "    num_sampled_edges=[2]\n",
              "  },\n",
              "  \u001b[1m(director, rev_to, movie)\u001b[0m={\n",
              "    edge_index=[2, 225],\n",
              "    e_id=[225],\n",
              "    num_sampled_edges=[2]\n",
              "  },\n",
              "  \u001b[1m(actor, rev_to, movie)\u001b[0m={\n",
              "    edge_index=[2, 675],\n",
              "    e_id=[675],\n",
              "    num_sampled_edges=[2]\n",
              "  },\n",
              "  \u001b[1m(movie, rev_to, director)\u001b[0m={\n",
              "    edge_index=[2, 199],\n",
              "    e_id=[199],\n",
              "    num_sampled_edges=[2]\n",
              "  },\n",
              "  \u001b[1m(movie, rev_to, actor)\u001b[0m={\n",
              "    edge_index=[2, 0],\n",
              "    e_id=[0],\n",
              "    num_sampled_edges=[2]\n",
              "  }\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF5f4amYDyUT",
        "outputId": "028ecce5-ba8c-4413-e075-4efdd80430f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mmovie\u001b[0m={\n",
              "    x=[4278, 3066],\n",
              "    y=[4278],\n",
              "    train_mask=[4278],\n",
              "    val_mask=[4278],\n",
              "    test_mask=[4278]\n",
              "  },\n",
              "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
              "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
              "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
              "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 12828] },\n",
              "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
              "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 12828] }\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4NoxTu7DNdl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBFxxB0l8ort"
      },
      "outputs": [],
      "source": [
        "from scipy import io\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "mat_file = io.loadmat('gdrive/MyDrive/heterograph_learning/ACM.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0opO0WU9H1Z"
      },
      "outputs": [],
      "source": [
        "paper_conf = mat_file['PvsC'].nonzero()[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVfwNdhx9H8H"
      },
      "outputs": [],
      "source": [
        "# DataBase\n",
        "paper_db = np.isin(paper_conf,[1,13])\n",
        "paper_db_idx = np.where(paper_db == True)[0]\n",
        "paper_db_idx = np.sort(np.random.choice(paper_db_idx,994,replace=False))\n",
        "# Data Mining\n",
        "paper_dm = np.isin(paper_conf,[0])\n",
        "paper_dm_idx = np.where(paper_dm == True)[0]\n",
        "# Wireless Communication\n",
        "paper_wc = np.isin(paper_conf,[9,10])\n",
        "paper_wc_idx = np.where(paper_wc == True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be-MkWeE9IBb"
      },
      "outputs": [],
      "source": [
        "paper_idx = np.sort(list(paper_db_idx)+list(paper_dm_idx)+list(paper_wc_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbpRAh819IDu"
      },
      "outputs": [],
      "source": [
        "# 0 : database, 1: wireless communication, 2: data mining\n",
        "paper_target = []\n",
        "for idx in paper_idx:\n",
        "    if idx in paper_db_idx:\n",
        "        paper_target.append(0)\n",
        "    elif idx in paper_wc_idx:\n",
        "        paper_target.append(1)\n",
        "    else:\n",
        "        paper_target.append(2)\n",
        "paper_target = np.array(paper_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nzo7LkW9eLY"
      },
      "outputs": [],
      "source": [
        "authors = mat_file['PvsA'][paper_idx].nonzero()[1]\n",
        "author_dic = {}\n",
        "re_authors = []\n",
        "for author in authors:\n",
        "    if author not in author_dic:\n",
        "        author_dic[author] = len(author_dic) + len(paper_idx)\n",
        "    re_authors.append(author_dic[author])\n",
        "re_authors = np.array(re_authors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK2qH6k09mNr"
      },
      "outputs": [],
      "source": [
        "subjects = mat_file['PvsL'][paper_idx].nonzero()[1]\n",
        "subject_dic = {}\n",
        "re_subjects = []\n",
        "for subject in subjects:\n",
        "    if subject not in subject_dic:\n",
        "        subject_dic[subject] = len(subject_dic) + len(paper_idx) + len(author_dic)\n",
        "    re_subjects.append(subject_dic[subject])\n",
        "re_subjects = np.array(re_subjects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePExgFTH9mR1"
      },
      "outputs": [],
      "source": [
        "node_num = len(paper_idx) + len(author_dic) + len(subject_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHRMe5Ec9mUU"
      },
      "outputs": [],
      "source": [
        "papers = mat_file['PvsA'][paper_idx].nonzero()[0]\n",
        "data = np.ones_like(papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqP41cMG9mWl"
      },
      "outputs": [],
      "source": [
        "A_pa = csr_matrix((data, (papers, re_authors)), shape=(node_num,node_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZpMeXWP9mYq"
      },
      "outputs": [],
      "source": [
        "papers = mat_file['PvsL'][paper_idx].nonzero()[0]\n",
        "data = np.ones_like(papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akLKIybG9ma2"
      },
      "outputs": [],
      "source": [
        "A_ps = csr_matrix((data, (papers, re_subjects)), shape=(node_num,node_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLDUp1Lu9z17"
      },
      "outputs": [],
      "source": [
        "A_ap = A_pa.transpose()\n",
        "A_sp = A_ps.transpose()\n",
        "edges = [A_pa,A_ap,A_ps,A_sp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-5IzEOR9z38",
        "outputId": "f8f708ad-fbff-40d8-f522-c922cb4ea68a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<12499x1903 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 972973 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "terms = mat_file['TvsP'].transpose()[paper_idx].nonzero()[1]\n",
        "term_dic = {}\n",
        "re_terms = []\n",
        "for term in terms:\n",
        "    if term not in term_dic:\n",
        "        term_dic[term] = len(term_dic) + len(paper_idx) + len(author_dic) + len(subject_dic)\n",
        "    re_terms.append(term_dic[term])\n",
        "re_terms = np.array(re_terms)\n",
        "mat_file['TvsP'].transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXG5NKsk9z58",
        "outputId": "44ad666e-3299-4878-c648-f1ed466652d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-829e80a76f57>:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  paper_feat = np.array(A_pt_tmp[:len(paper_idx),-len(term_dic):].toarray()>0, dtype=np.int)\n",
            "<ipython-input-18-829e80a76f57>:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  author_feat = np.array(A_pa_tmp.transpose().dot(A_pt_tmp)[len(paper_idx):len(paper_idx)+len(author_dic),-len(term_dic):].toarray()>0, dtype=np.int)\n",
            "<ipython-input-18-829e80a76f57>:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  subject_feat = np.array(A_ps_tmp.transpose().dot(A_pt_tmp)[len(paper_idx)+len(author_dic):len(paper_idx)+len(author_dic)+len(subject_dic),-len(term_dic):].toarray()>0, dtype=np.int)\n"
          ]
        }
      ],
      "source": [
        "# tmp\n",
        "tmp_num_node = node_num + len(term_dic)\n",
        "papers = mat_file['PvsA'][paper_idx].nonzero()[0]\n",
        "data = np.ones_like(papers)\n",
        "A_pa_tmp = csr_matrix((data, (papers, re_authors)), shape=(tmp_num_node,tmp_num_node))\n",
        "papers = mat_file['PvsL'][paper_idx].nonzero()[0]\n",
        "data = np.ones_like(papers)\n",
        "A_ps_tmp = csr_matrix((data, (papers, re_subjects)), shape=(tmp_num_node,tmp_num_node))\n",
        "papers = mat_file['PvsT'][paper_idx].nonzero()[0]\n",
        "data = np.ones_like(papers)\n",
        "A_pt_tmp = csr_matrix((data, (papers, re_terms)), shape=(tmp_num_node,tmp_num_node))\n",
        "paper_feat = np.array(A_pt_tmp[:len(paper_idx),-len(term_dic):].toarray()>0, dtype=np.int)\n",
        "author_feat = np.array(A_pa_tmp.transpose().dot(A_pt_tmp)[len(paper_idx):len(paper_idx)+len(author_dic),-len(term_dic):].toarray()>0, dtype=np.int)\n",
        "subject_feat = np.array(A_ps_tmp.transpose().dot(A_pt_tmp)[len(paper_idx)+len(author_dic):len(paper_idx)+len(author_dic)+len(subject_dic),-len(term_dic):].toarray()>0, dtype=np.int)\n",
        "node_faeture = np.concatenate((paper_feat,author_feat,subject_feat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yFgpZZN9z8P"
      },
      "outputs": [],
      "source": [
        "# Train, Valid\n",
        "train_valid_DB = list(np.random.choice(np.where(paper_target==0)[0],300, replace=False))\n",
        "train_valid_WC = list(np.random.choice(np.where(paper_target==1)[0],300, replace=False))\n",
        "train_valid_DM = list(np.random.choice(np.where(paper_target==2)[0],300, replace=False))\n",
        "\n",
        "train_idx = np.array(train_valid_DB[:200] + train_valid_WC[:200] + train_valid_DM[:200])\n",
        "train_target = paper_target[train_idx]\n",
        "train_label = np.vstack((train_idx,train_target)).transpose()\n",
        "valid_idx = np.array(train_valid_DB[200:] + train_valid_WC[200:] + train_valid_DM[200:])\n",
        "valid_target = paper_target[valid_idx]\n",
        "valid_label = np.vstack((valid_idx,valid_target)).transpose()\n",
        "test_idx = np.array(list((set(np.arange(paper_target.shape[0])) - set(train_idx)) - set(valid_idx)))\n",
        "test_target = paper_target[test_idx]\n",
        "test_label = np.vstack((test_idx,test_target)).transpose()\n",
        "labels = [train_label,valid_label,test_label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knf0iScP9z-i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zxuvE3H90A2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "likW46aPw80S"
      },
      "source": [
        "## Random Walk with restart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN_kWvoBw_xB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orGjrqHlVnri"
      },
      "source": [
        "## Generate Adjacancy Tensor from Hetero_graph object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv9oyv18B8ez"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s20RzTd6WX8Y",
        "outputId": "5c876a93-49d2-4279-ec70-efead8840ede"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['rel_AA',\n",
              " 'rel_AB',\n",
              " 'rel_AC',\n",
              " 'rel_AD',\n",
              " 'rel_BB',\n",
              " 'rel_BC',\n",
              " 'rel_BD',\n",
              " 'rel_CC',\n",
              " 'rel_CD',\n",
              " 'rel_DD']"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_types = ['rel_'+i+j for i,j in itertools.combinations_with_replacement(meta_graph.keys(), 2)]\n",
        "edge_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuWdV1mHI5jv",
        "outputId": "4b6d4117-8997-4e07-c1ef-8208a842f96c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 50, 10)"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def adjacency_tensor(graph, meta_graph):\n",
        "    edge_types = ['rel_'+i+j for i,j in itertools.combinations_with_replacement(meta_graph.keys(), 2)]\n",
        "    n = len(graph.nodes())\n",
        "    r = len(edge_types)\n",
        "\n",
        "    adj_matrices = []\n",
        "\n",
        "    for edge_type in edge_types:\n",
        "        adj_matrix = np.empty((n, n), dtype=object)\n",
        "        \n",
        "        for u, v, data in graph.edges(data=True):\n",
        "            if data['type'] == edge_type:\n",
        "                element = graph.nodes[u]['type'] + '_'+ graph.edges[u,v]['type'] +'_'+ graph.nodes[v]['type']\n",
        "                adj_matrix[u, v] = element\n",
        "                adj_matrix[v, u] = adj_matrix[u, v] \n",
        "        \n",
        "        adj_matrices.append(adj_matrix)\n",
        "\n",
        "    return np.stack(adj_matrices, axis=-1)\n",
        "\n",
        "adjacency_tensor_result_cat = adjacency_tensor(hetero_graph, meta_graph)\n",
        "adjacency_tensor_result_cat.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRU15cv5V2q2",
        "outputId": "9da432ac-1392-4181-b62c-e106c716e75a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 50, 10)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def adjacency_tensor(graph, meta_graph):\n",
        "    edge_types = ['rel_'+i+j for i,j in itertools.combinations_with_replacement(meta_graph.keys(), 2)]\n",
        "    n = len(graph.nodes())\n",
        "    r = len(edge_types)\n",
        "\n",
        "    adj_matrices = []\n",
        "\n",
        "    for edge_type in edge_types:\n",
        "        adj_matrix = np.zeros((n, n), dtype=np.int32)\n",
        "        \n",
        "        for u, v, data in graph.edges(data=True):\n",
        "            if data['type'] == edge_type:\n",
        "                adj_matrix[u, v] = 1\n",
        "                adj_matrix[v, u] = 1\n",
        "        \n",
        "        adj_matrices.append(adj_matrix)\n",
        "\n",
        "    return np.stack(adj_matrices, axis=-1)\n",
        "\n",
        "adjacency_tensor_result = adjacency_tensor(hetero_graph, meta_graph)\n",
        "adjacency_tensor_result.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mBWDljuWaZD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from scipy.spatial.distance import squareform\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import scipy.sparse as sparse\n",
        "from sklearn import metrics\n",
        "import scipy.stats\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "def halfvec_to_topo(w, threshold, device):\n",
        "    \"\"\"\n",
        "    from half vectorisation to matrix in batch way.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, l = w.size()\n",
        "    m = int((1 / 2) * (1 + math.sqrt(1 + 8 * l)))\n",
        "\n",
        "    # extract binary edge {0, 1}:\n",
        "    bw = (w.clone().detach() >= threshold).float().to(device)\n",
        "    E = torch.zeros((batch_size, m, m), dtype = w.dtype).to(device)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        E[i, :, :][np.triu_indices(m, 1)] = bw[i].clone().detach()\n",
        "        E[i, :, :] = E[i, :, :].T + E[i, :, :]\n",
        "\n",
        "    return E\n",
        "\n",
        "#%%\n",
        "\n",
        "def torch_sqaureform_to_matrix(w, device):\n",
        "    \"\"\"\n",
        "    from half vectorisation to matrix in batch way.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, l = w.size()\n",
        "    m = int((1 / 2) * (1 + math.sqrt(1 + 8 * l)))\n",
        "\n",
        "    E = torch.zeros((batch_size, m, m), dtype = w.dtype).to(device)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        E[i, :, :][np.triu_indices(m, 1)] = w[i].clone().detach()\n",
        "        E[i, :, :] = E[i, :, :].T + E[i, :, :]\n",
        "\n",
        "    return E\n",
        "\n",
        "#%%\n",
        "\n",
        "def torch_squareform_to_vector(A, device):\n",
        "    batch_size, m, _ = A.size()\n",
        "    l = int(m * (m - 1) / 2)\n",
        "\n",
        "    w = torch.zeros((batch_size, l), dtype = A.dtype).to(device)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        w[i, :] = A[i,:,:][np.triu_indices(m, 1)].clone().detach()\n",
        "\n",
        "    return w\n",
        "\n",
        "#%%\n",
        "\n",
        "def soft_threshold(w, eta):\n",
        "    '''\n",
        "    softthreshold function in a batch way.\n",
        "    '''\n",
        "    return (torch.abs(w) >= eta) * torch.sign(w) * (torch.abs(w) - eta)\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "def check_tensor(x, device):\n",
        "    if isinstance(x, np.ndarray) or type(x) in [int, float]:\n",
        "        x = torch.Tensor(x)\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.to(device=device)\n",
        "    return x\n",
        "\n",
        "#%%\n",
        "\n",
        "def coo_to_sparseTensor(coo):\n",
        "    values = coo.data\n",
        "    indices = np.vstack((coo.row, coo.col))\n",
        "\n",
        "    i = torch.LongTensor(indices)\n",
        "    v = torch.FloatTensor(values)\n",
        "    shape = coo.shape\n",
        "\n",
        "    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "def get_degree_operator(m):\n",
        "    ncols =int(m*(m - 1)/2)\n",
        "\n",
        "    I = np.zeros(ncols)\n",
        "    J = np.zeros(ncols)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        I[k:(k + m - i)] = np.arange(i, m)\n",
        "        k = k + (m - i)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        J[k: (k + m - i)] = i - 1\n",
        "        k = k + m - i\n",
        "\n",
        "    Row = np.tile(np.arange(0, ncols), 2)\n",
        "    Col = np.append(I, J)\n",
        "    Data = np.ones(Col.size)\n",
        "    St = sparse.coo_matrix((Data, (Row, Col)), shape=(ncols, m))\n",
        "    return St.T\n",
        "\n",
        "#%%\n",
        "\n",
        "def get_distance_halfvector(y):\n",
        "    n, _ = y.shape # m nodes, n observations\n",
        "    z = (1 / n) * euclidean_distances(y.T, squared=True)\n",
        "    # z.shape = m, m\n",
        "    return squareform(z, checks=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJt-JM-wWAVX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def _generate_SBM100noise_to_parallel(i, num_nodes, num_signals, graph_hyper, weighted, weight_scale = False):\n",
        "\n",
        "    size = [4, 2, 2, 13, 13, 15, 17, 3, 12, 10, 9]\n",
        "\n",
        "    p = graph_hyper\n",
        "    probs = [[0.95, p, p, p, p, p, p, p, p, p, p],\n",
        "             [p, 1, p, p, p, p, p, p, p, p, p],\n",
        "             [p, p, 1, p, p, p, p, p, p, p, p],\n",
        "             [p, p, p, 0.6, p, p, p, p, p, p, p],\n",
        "             [p, p, p, p, 0.6, p, p, p, p, p, p],\n",
        "             [p, p, p, p, p, 0.5, p, p, p, p, p],\n",
        "             [p, p, p, p, p, p, 0.5, p, p, p, p],\n",
        "             [p, p, p, p, p, p, p, 0.95, p, p, p],\n",
        "             [p, p, p, p, p, p, p, p, 0.65, p, p],\n",
        "             [p, p, p, p, p, p, p, p, p, 0.65, p],\n",
        "             [p, p, p, p, p, p, p, p, p, p, 0.65]]\n",
        "\n",
        "    G = nx.stochastic_block_model(size, probs)\n",
        "\n",
        "    W_GT = nx.adjacency_matrix(G).A\n",
        "\n",
        "    if weighted == 'uniform':\n",
        "        weights = np.random.uniform(0, 2, (num_nodes, num_nodes))\n",
        "        weights = (weights + weights.T) / 2\n",
        "        W_GT = W_GT * weights\n",
        "\n",
        "    if weighted == 'gaussian':\n",
        "        weights = np.random.normal(1, 0.05, (num_nodes, num_nodes))\n",
        "        weights = np.abs(weights)\n",
        "        weights = (weights + weights.T) / 2\n",
        "        W_GT = W_GT * weights\n",
        "\n",
        "    if weighted == 'lognormal':\n",
        "        weights = np.random.lognormal(0, 0.1, (num_nodes, num_nodes))\n",
        "        weights = (weights + weights.T) / 2\n",
        "        W_GT = W_GT * weights\n",
        "\n",
        "\n",
        "    if weight_scale:\n",
        "        W_GT = W_GT * num_nodes / np.sum(W_GT)\n",
        "\n",
        "    L_GT = np.diag(W_GT @ np.ones(num_nodes)) - W_GT\n",
        "\n",
        "    W_GT = scipy.sparse.csr_matrix(W_GT)\n",
        "\n",
        "    cov = np.linalg.inv(L_GT + (1e-06) * np.eye(num_nodes))\n",
        "    z = get_distance_halfvector(np.random.multivariate_normal(np.zeros(num_nodes), cov, num_signals))\n",
        "\n",
        "    return z, W_GT\n",
        "\n",
        "def generate_SBM100noise_parallel(num_samples, num_nodes, num_signals, graph_hyper, weighted, weight_scale):\n",
        "    n_cpu = multiprocess.cpu_count() - 2\n",
        "    pool = multiprocess.Pool(n_cpu)\n",
        "\n",
        "    z_multi, W_multi = zip(*pool.map(partial(_generate_SBM100noise_to_parallel,\n",
        "                                             num_nodes = num_nodes,\n",
        "                                             num_signals = num_signals,\n",
        "                                             graph_hyper = graph_hyper,\n",
        "                                             weighted = weighted,\n",
        "                                             weight_scale = weight_scale),\n",
        "                                     range(num_samples)))\n",
        "\n",
        "    result = {\n",
        "        'z': z_multi,\n",
        "        'W': W_multi\n",
        "    }\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXacU1GJWrr7"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from src.utils_data import *\n",
        "\n",
        "#%%\n",
        "\n",
        "graph_type = 'BA'\n",
        "edge_type = 'lognormal'\n",
        "graph_size = 500\n",
        "\n",
        "graph_hyper = 3\n",
        "\n",
        "data = generate_BA_parallel(num_samples=8064,\n",
        "                            num_signals=3000,\n",
        "                            num_nodes=graph_size,\n",
        "                            graph_hyper=graph_hyper,\n",
        "                            weighted=edge_type,\n",
        "                            weight_scale=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGZleE89pzrF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3apSmsYKYyTV"
      },
      "source": [
        "## Blessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFxAgVNc0zOO"
      },
      "outputs": [],
      "source": [
        "# Divine beast bless no bug here! \n",
        "#         ┌─┐    ┌─┐\n",
        "#      ┌─┘ ┴───┘ ┴──┐\n",
        "#      │                   │\n",
        "#      │       ───       │\n",
        "#      │  ─┬┘     └┬─  │\n",
        "#      │                   │\n",
        "#      │       ─┴─       │\n",
        "#      │                   │\n",
        "#      └─┐         ┌───┘\n",
        "#          │         │\n",
        "#          │         │\n",
        "#          │         │\n",
        "#          │         └──────────────┐\n",
        "#          │                                  │\n",
        "#          │                                  ├─┐\n",
        "#          │                                  ┌─┘\n",
        "#          │                                  │\n",
        "#          └─┐  ┐  ┌──────┬──┐  ┌──┘\n",
        "#            │  ─┤ ─┤         │  ─┤ ─┤\n",
        "#            └──┴──┘         └──┴──┘"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDym5o3f-luP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QHwjrjzDgpq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bblmMuCaDhvA",
        "outputId": "754c5471-7c3c-4359-ac06-87372921d397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[5, 9, 2],\n",
              "         [5, 0, 0],\n",
              "         [5, 6, 7],\n",
              "         [0, 6, 8]],\n",
              "\n",
              "        [[1, 6, 6],\n",
              "         [6, 1, 8],\n",
              "         [0, 8, 4],\n",
              "         [7, 6, 4]],\n",
              "\n",
              "        [[0, 2, 8],\n",
              "         [3, 8, 3],\n",
              "         [5, 4, 8],\n",
              "         [5, 8, 2]]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W = torch.randint(10, (3, 4, 3))\n",
        "W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcuPnkjcDoGM",
        "outputId": "26b77c93-1633-4b28-9eb5-fc6214a4cf80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4, 4, 0, 2, 3, 0, 4, 2, 2, 1],\n",
              "        [4, 0, 3, 1, 2, 2, 0, 0, 2, 4],\n",
              "        [0, 3, 4, 3, 2, 0, 4, 0, 3, 3],\n",
              "        [4, 2, 1, 2, 4, 3, 4, 0, 2, 3]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "E = torch.randint(5, (4, 10))\n",
        "E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zET6oFIdEDbE",
        "outputId": "3ae57f8d-fdc3-41c5-973e-25c0789df845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 0, 3, 3, 3, 1, 1, 0, 1, 4],\n",
              "        [2, 2, 3, 3, 0, 4, 2, 0, 0, 3],\n",
              "        [1, 2, 0, 1, 0, 4, 0, 4, 0, 2]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.randint(5, (3, 10))\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3I2Ra8eJYBx"
      },
      "outputs": [],
      "source": [
        "d_e = 10\n",
        "d_r = 20\n",
        "N = 6\n",
        "W = torch.randint(10, (d_e, d_r, d_e))\n",
        "X = torch.randint(5, (N, d_e))\n",
        "E = torch.randint(3, (N, d_r))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_hbOSu4GHAb"
      },
      "outputs": [],
      "source": [
        "def tucker_decomp(w, h, r, t, ent_num ,rel_mum ):\n",
        "\n",
        "\n",
        "  w = w.view(1, ent_num, rel_mum, ent_num)\n",
        "  r = r.view(-1, 1, 1, rel_mum)\n",
        "  print(w.shape, r.shape)\n",
        "  wr = r @ w\n",
        "  print(wr.shape)\n",
        "\n",
        "  # compute whr = DO(BN(h_n x_1 wr))\n",
        "  wr = wr.view(-1, ent_num, ent_num)\n",
        "  print(wr.shape)\n",
        "  print(h.shape)\n",
        "  whr = (h @ wr)\n",
        "\n",
        "  # Compute whr x_3 t\n",
        "  tensor = whr * t\n",
        "  scores = torch.sum(whr * t, dim=-1)\n",
        "  return tensor, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NJQ9Gt-FCYq",
        "outputId": "eb1f1cd5-756f-4c1a-f491-6283d00f9e46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10, 20, 10]) torch.Size([6, 1, 1, 20])\n",
            "torch.Size([6, 10, 1, 10])\n",
            "torch.Size([6, 10, 10])\n",
            "torch.Size([6, 10])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 6, 10])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor, scores = tucker_decomp(W, X, E, X, d_e, d_r)\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL86IH28Gule",
        "outputId": "cfb886ce-e248-4239-d1c1-c96e4b62f0b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKnRdxKsKHTQ",
        "outputId": "31032475-d9e3-4e9d-cab2-dafc214bb0be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 20, 10]) torch.Size([10, 6])\n",
            "torch.Size([6, 20, 10])\n",
            "torch.Size([6, 1, 20])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 1])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def score(W, X, E, d_e, d_r):\n",
        "  lhs = X\n",
        "  rel = E\n",
        "  rhs = X\n",
        "  print(W.transpose(0, 2).shape, lhs.transpose(0, 1).shape)\n",
        "  lhs_proj = torch.matmul(W.transpose(0, 2), lhs.transpose(0, 1)).transpose(0, 2) # b, rank_r, rank_e\n",
        "  print(lhs_proj.shape)\n",
        "  rel_proj = rel.view(-1, 1, d_r)\n",
        "  print(rel_proj.shape)\n",
        "  lhs_proj = torch.bmm(rel_proj, lhs_proj).view(-1, d_e)\n",
        "  return torch.sum(lhs_proj * rhs, 1, keepdim=True)\n",
        "\n",
        "score(W, X, E, d_e, d_r).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taTgqgGXOCQl",
        "outputId": "24a1be7e-b817-4273-a96b-39f4b014a528"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRVG_lNaK4DY"
      },
      "outputs": [],
      "source": [
        "def p_mode_tensor_mat(Tsr, Mtx, p):\n",
        "  Kp = Tsr.shape[p-1]\n",
        "  K = Mtx.shape[0]\n",
        "  # Tsr K1 x K2 x Kp x ... x Kn; Mtx K x Kp\n",
        "\n",
        "  for i in range(K):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CSOCnNHOTvP"
      },
      "outputs": [],
      "source": [
        "def mode_n_product(x, m, mode):\n",
        "  x = np.asarray(x)\n",
        "  m = np.asarray(m)\n",
        "  if mode <= 0 or mode % 1 != 0:\n",
        "    raise ValueError('`mode` must be a positive interger')\n",
        "  if x.ndim < mode:\n",
        "    raise ValueError('Invalid shape of X for mode = {}: {}'.format(mode, x.shape))\n",
        "  if m.ndim != 2:\n",
        "    raise ValueError('Invalid shape of M: {}'.format(m.shape))\n",
        "  return np.swapaxes(np.swapaxes(x, mode - 1, -1).dot(m.T), mode - 1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcwcQMxEuF_5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def mode_n_product(x, m, mode):\n",
        "    if mode <= 0 or mode % 1 != 0:\n",
        "        raise ValueError('`mode` must be a positive integer')\n",
        "    if x.ndim < mode:\n",
        "        raise ValueError('Invalid shape of X for mode = {}: {}'.format(mode, x.shape))\n",
        "    if m.ndim != 2:\n",
        "        raise ValueError('Invalid shape of M: {}'.format(m.shape))\n",
        "    return torch.transpose(torch.transpose(x, mode - 1, -1).matmul(m.T), mode - 1, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcqlC7vFuKXv"
      },
      "outputs": [],
      "source": [
        "N_e = 6\n",
        "N_r = 10\n",
        "emb_size = 100\n",
        "W = torch.randint(10, (N_e, N_r, N_e))\n",
        "X = torch.randint(5, (emb_size, N_e))\n",
        "E = torch.randint(3, (emb_size, N_r))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0iKtdMtuLLi",
        "outputId": "76178a0c-1a2f-4d09-807c-c5fde1611d34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([100, 100, 100])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1 = mode_n_product(W, X, 1)\n",
        "X2 = mode_n_product(X1, E, 2)\n",
        "X3 = mode_n_product(X2, X, 3)\n",
        "\n",
        "X3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFUmCPEvumSX",
        "outputId": "c0459ad3-4cde-475b-dab8-1fb07a53198a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(707375)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smooth = 0\n",
        "for i in range(N_e):\n",
        "  for j in range(N_r):\n",
        "    for k in range(N_e):\n",
        "      smooth += torch.sum(W[i,j,k] * X[:,i]* E[:,j] * X[:,k])\n",
        "\n",
        "smooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG5v5BVZusYJ",
        "outputId": "f65f9c2a-93d1-4168-ac72-d63f2c62f2c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(707375)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dig = 0\n",
        "for i in range(emb_size):\n",
        "  dig += X3[i,i,i]\n",
        "\n",
        "dig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUqWokncujRo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhtQ9a0hPlDp"
      },
      "outputs": [],
      "source": [
        "X1 = mode_n_product(W, X, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dow8FjyzPoAT"
      },
      "outputs": [],
      "source": [
        "X2 = mode_n_product(X1, E, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4QW2gmSP5uL"
      },
      "outputs": [],
      "source": [
        "X3 = mode_n_product(X2, X, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27NlSdrlP9FG",
        "outputId": "59ff10d4-56e0-478d-b1a9-e026bf2b43e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 6, 6)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGadqoZpP_Xc"
      },
      "outputs": [],
      "source": [
        "N_e = 6\n",
        "N_r = 10\n",
        "emb_size = 100\n",
        "W = torch.randint(10, (N_e, N_r, N_e))\n",
        "X = torch.randint(5, (emb_size, N_e))\n",
        "E = torch.randint(3, (emb_size, N_r))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLWBtIf8QSA4",
        "outputId": "ff29995f-9280-4372-e4f1-6afae94c857b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100, 100)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1 = mode_n_product(W, X, 1)\n",
        "X2 = mode_n_product(X1, E, 2)\n",
        "X3 = mode_n_product(X2, X, 3)\n",
        "\n",
        "X3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiVwmR0dQVkR",
        "outputId": "738b53fd-ad4c-47d4-d18e-f7805f10ba4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "752439"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dig = 0\n",
        "for i in range(emb_size):\n",
        "  dig += X3[i,i,i]\n",
        "\n",
        "dig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYJOZdQoRbA0",
        "outputId": "3d8d7047-cd08-43d2-aecc-1c16d1b86db2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[1].shape\n",
        "E[3].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flvm_R_ERY6_",
        "outputId": "ffe3775e-10db-4f21-9e93-5d7c5bbf1645"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W[1,3,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkU5F6WyRTQ1",
        "outputId": "94a1b504-1fb2-40c2-d826-0988a5bafb69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9,  0,  6,  0,  0,  0,  0, 16,  0,  4,  0,  0,  0,  0, 32,  0,  0, 18,\n",
              "         4,  6,  2, 16,  0, 18, 16,  0,  0,  0,  8,  3,  0,  0,  0,  0,  9,  0,\n",
              "         0,  4,  0,  0,  8,  4,  2,  0, 16,  3,  4,  8,  8, 16,  0,  0,  0,  0,\n",
              "         0,  0,  9,  3,  0,  8,  0, 16,  2,  6,  0,  0,  0,  4,  0,  0,  0,  0,\n",
              "         6, 12, 32, 18,  0, 24, 16,  0,  0,  0, 12,  0,  0, 24,  0,  8,  0,  0,\n",
              "         0,  0, 16,  0,  0, 12,  0,  0,  0,  0])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W[1,3,2] * X[:,1]* E[:,3] * X[:,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0l724d9Qrvj",
        "outputId": "13d02008-508a-4f9e-b38b-872fd8daf262"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(752439)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smooth = 0\n",
        "for i in range(N_e):\n",
        "  for j in range(N_r):\n",
        "    for k in range(N_e):\n",
        "      smooth += torch.sum(W[i,j,k] * X[:,i]* E[:,j] * X[:,k])\n",
        "\n",
        "smooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGbFej-eRsOk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaryBall/CSML_notes/blob/master/hgsl_e2e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0YeI-TqptCv",
        "outputId": "94b19f9c-4649-4456-c5b1-382a7a5bc50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount the google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIugSBZApzSk",
        "outputId": "480d5d2e-0d6e-4991-cc87-c33973390f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "11.8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIUV8oebq9kh",
        "outputId": "6b4693d7-a3be-47f0-88af-9244866f5cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.2.0+pt20cu118)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.1+pt20cu118)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.17+pt20cu118)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.1+pt20cu118)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt20cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "# !pip install rdkit\n",
        "# !pip install hydra-core wandb hydra-core ray ray-lightning torchmetrics overrides imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loNXffqWXpGa"
      },
      "source": [
        "# Synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoV2Hf-GXoj0",
        "outputId": "b2bbe0ee-9cd8-4a43-8a7a-2146be49ac80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All binary combinations: [('A', 'A'), ('A', 'B'), ('A', 'C'), ('A', 'D'), ('B', 'B'), ('B', 'C'), ('B', 'D'), ('C', 'C'), ('C', 'D'), ('D', 'D')]\n",
            "Sampled subset (40%): [('C', 'C'), ('B', 'B'), ('C', 'D'), ('A', 'A')]\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "# Define the nodes\n",
        "nodes = ['A', 'B', 'C', 'D']\n",
        "\n",
        "# Generate all binary combinations\n",
        "combinations = list(itertools.combinations_with_replacement(nodes, 2))\n",
        "\n",
        "# Calculate 40% of the total combinations\n",
        "sample_size = round(len(combinations) * 0.4)\n",
        "\n",
        "# Randomly sample a subset of the combinations\n",
        "subset = random.sample(combinations, sample_size)\n",
        "\n",
        "# Print the results\n",
        "print(\"All binary combinations:\", combinations)\n",
        "print(\"Sampled subset (40%):\", subset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zN617cw9Hl-"
      },
      "source": [
        "# Function for generating Heterogeneous Graphs \n",
        "\n",
        "- with Small world assumption - Watts Strogatz Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE4mRj1vguCE",
        "outputId": "6b7132e8-d251-4d60-ef9c-ce097a4eb5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': 0.25, 'B': 0.25, 'C': 0.25, 'D': 0.25}\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "deque([0])\n",
            "A ['C']\n",
            "sampled node type for node 1: C\n",
            "A ['C']\n",
            "sampled node type for node 49: C\n",
            "A ['C']\n",
            "sampled node type for node 27: C\n",
            "deque([1, 49, 27])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 39: D\n",
            "deque([49, 27, 39])\n",
            "deque([27, 39])\n",
            "deque([39])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 38: C\n",
            "D ['C', 'D']\n",
            "sampled node type for node 18: C\n",
            "deque([38, 18])\n",
            "deque([18])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 5: D\n",
            "deque([5])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 6: D\n",
            "deque([6])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 34: C\n",
            "D ['C', 'D']\n",
            "sampled node type for node 35: C\n",
            "deque([34, 35])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 33: D\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 7: B\n",
            "deque([35, 33, 7])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 29: B\n",
            "deque([33, 7, 29])\n",
            "deque([7, 29])\n",
            "B ['C']\n",
            "sampled node type for node 8: C\n",
            "B ['C']\n",
            "sampled node type for node 14: C\n",
            "deque([29, 8, 14])\n",
            "deque([8, 14])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 36: B\n",
            "deque([14, 36])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 37: B\n",
            "deque([36, 37])\n",
            "B ['C']\n",
            "sampled node type for node 11: C\n",
            "B ['C']\n",
            "sampled node type for node 48: C\n",
            "deque([37, 11, 48])\n",
            "deque([11, 48])\n",
            "deque([48])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 47: A\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 22: B\n",
            "deque([47, 22])\n",
            "deque([22])\n",
            "B ['C']\n",
            "sampled node type for node 17: C\n",
            "deque([17])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 16: B\n",
            "deque([16])\n",
            "deque([2])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 28: D\n",
            "deque([28])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 25: D\n",
            "D ['C', 'D']\n",
            "sampled node type for node 43: C\n",
            "deque([25, 43])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 4: D\n",
            "deque([43, 4])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 32: B\n",
            "deque([4, 32])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 3: C\n",
            "deque([32, 3])\n",
            "B ['C']\n",
            "sampled node type for node 31: C\n",
            "deque([3, 31])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 30: D\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 41: A\n",
            "deque([31, 30, 41])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 13: D\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 42: D\n",
            "deque([30, 41, 13, 42])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 26: C\n",
            "deque([41, 13, 42, 26])\n",
            "deque([13, 42, 26])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 12: D\n",
            "deque([42, 26, 12])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 44: D\n",
            "deque([26, 12, 44])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 23: B\n",
            "deque([12, 44, 23])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 24: C\n",
            "deque([44, 23, 24])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 15: C\n",
            "deque([23, 24, 15])\n",
            "B ['C']\n",
            "sampled node type for node 40: C\n",
            "B ['C']\n",
            "sampled node type for node 46: C\n",
            "deque([24, 15, 40, 46])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 21: D\n",
            "deque([15, 40, 46, 21])\n",
            "deque([40, 46, 21])\n",
            "deque([46, 21])\n",
            "deque([21])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 20: D\n",
            "D ['C', 'D']\n",
            "sampled node type for node 45: D\n",
            "deque([20, 45])\n",
            "D ['C', 'D']\n",
            "sampled node type for node 19: D\n",
            "D ['C', 'D']\n",
            "sampled node type for node 10: C\n",
            "deque([45, 19, 10])\n",
            "deque([19, 10])\n",
            "deque([10])\n",
            "C ['A', 'B', 'D']\n",
            "sampled node type for node 9: B\n",
            "deque([9])\n",
            "0 1 A C ('A', 'to', 'C')\n",
            "0 49 A C ('A', 'to', 'C')\n",
            "0 27 A C ('A', 'to', 'C')\n",
            "1 39 C D ('C', 'to', 'D')\n",
            "2 28 D D ('D', 'to', 'D')\n",
            "3 4 C D ('C', 'to', 'D')\n",
            "3 30 C D ('C', 'to', 'D')\n",
            "3 41 C A ('A', 'to', 'C')\n",
            "4 43 D C ('C', 'to', 'D')\n",
            "4 25 D D ('D', 'to', 'D')\n",
            "5 6 D D ('D', 'to', 'D')\n",
            "5 18 D C ('C', 'to', 'D')\n",
            "6 34 D C ('C', 'to', 'D')\n",
            "6 35 D C ('C', 'to', 'D')\n",
            "7 8 B C ('B', 'to', 'C')\n",
            "7 14 B C ('B', 'to', 'C')\n",
            "7 34 B C ('B', 'to', 'C')\n",
            "8 36 C B ('B', 'to', 'C')\n",
            "9 10 B C ('B', 'to', 'C')\n",
            "10 20 C D ('C', 'to', 'D')\n",
            "11 36 C B ('B', 'to', 'C')\n",
            "12 13 D D ('D', 'to', 'D')\n",
            "12 24 D C ('C', 'to', 'D')\n",
            "13 31 D C ('C', 'to', 'D')\n",
            "14 37 C B ('B', 'to', 'C')\n",
            "15 44 C D ('C', 'to', 'D')\n",
            "16 17 B C ('B', 'to', 'C')\n",
            "17 22 C B ('B', 'to', 'C')\n",
            "18 39 C D ('C', 'to', 'D')\n",
            "19 20 D D ('D', 'to', 'D')\n",
            "20 21 D D ('D', 'to', 'D')\n",
            "21 24 D C ('C', 'to', 'D')\n",
            "21 45 D D ('D', 'to', 'D')\n",
            "22 48 B C ('B', 'to', 'C')\n",
            "23 26 B C ('B', 'to', 'C')\n",
            "23 40 B C ('B', 'to', 'C')\n",
            "23 46 B C ('B', 'to', 'C')\n",
            "25 28 D D ('D', 'to', 'D')\n",
            "26 30 C D ('C', 'to', 'D')\n",
            "28 43 D C ('C', 'to', 'D')\n",
            "29 35 B C ('B', 'to', 'C')\n",
            "31 32 C B ('B', 'to', 'C')\n",
            "31 42 C D ('C', 'to', 'D')\n",
            "32 43 B C ('B', 'to', 'C')\n",
            "33 34 D C ('C', 'to', 'D')\n",
            "36 37 B B NA\n",
            "36 48 B C ('B', 'to', 'C')\n",
            "38 39 C D ('C', 'to', 'D')\n",
            "42 44 D D ('D', 'to', 'D')\n",
            "47 48 A C ('A', 'to', 'C')\n"
          ]
        }
      ],
      "source": [
        "from IPython.terminal.embed import ultratb\n",
        "import networkx as nx\n",
        "import random\n",
        "from collections import deque\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "def ws_graph (n,k,p):\n",
        "  return nx.watts_strogatz_graph(n, k, p)\n",
        "\n",
        "def get_available_node_types(current_node, graph, meta_graph):\n",
        "    if current_node is not None:\n",
        "      current_node_type = graph.nodes[current_node].get('type')\n",
        "    else:\n",
        "      current_node_type = None\n",
        "    \n",
        "    # process the case when we randomly select a node to start\n",
        "    if not current_node_type:\n",
        "        return list(meta_graph.keys())\n",
        "    else:\n",
        "        return list(meta_graph[current_node_type].keys())\n",
        "\n",
        "\n",
        "def normalize_node_type_prob(available_types, node_type_prob):\n",
        "    total_prob = sum(node_type_prob[available_types].values())\n",
        "    node_type_prob_normalized = {}\n",
        "    for node_type, prob in node_type_prob.items():\n",
        "      normalized_prob = prob / total_prob\n",
        "      node_type_prob_normalized[node_type] = normalized_prob\n",
        "\n",
        "    return node_type_prob_normalized\n",
        "\n",
        "\n",
        "\n",
        "def generate_heterogeneous_small_world(graph, meta_graph, node_type_prob):\n",
        "    # Step 1: Generate a Watts-Strogatz graph\n",
        "    \n",
        "\n",
        "    # Step 2: Normalize node type probabilities\n",
        "    node_type_prob_normalized = {node_type: prob / sum(node_type_prob.values()) for node_type, prob in node_type_prob.items()}\n",
        "    print(node_type_prob_normalized)\n",
        "\n",
        "    # Step 3: Assign node and edge types using BFS\n",
        "    visited = set()\n",
        "    print(graph.nodes())\n",
        "    current_node = None\n",
        "    last_node = None\n",
        "\n",
        "    possible_rel = [(i,j) for i in meta_graph.keys() for j in meta_graph[i].keys()]\n",
        "\n",
        "    for node in graph.nodes():\n",
        "        if node not in visited:\n",
        "            # BFS traversal\n",
        "            queue = deque([node])\n",
        "            \n",
        "            visited.add(node)\n",
        "\n",
        "            while queue:\n",
        "                print(queue)\n",
        "            \n",
        "                current_node = queue.popleft()\n",
        "                \n",
        "                if not graph.nodes[current_node].get('type'):\n",
        "                  possible_start_type = get_available_node_types(current_node, graph, meta_graph)\n",
        "                  sample_prob = [node_type_prob_normalized[node_type] for node_type in possible_start_type]\n",
        "                  node_type = random.choices(possible_start_type, sample_prob, k=1)[0]\n",
        "                  graph.nodes[current_node]['type'] = node_type\n",
        "\n",
        "                available_node_types = get_available_node_types(current_node, graph, meta_graph)\n",
        "\n",
        "                # Assign edge types and add unvisited neighbors to queue\n",
        "                for neighbor in graph.neighbors(current_node):\n",
        "                    if neighbor not in visited:\n",
        "                        # Assign node type\n",
        "                        if not graph.nodes[neighbor].get('type'):\n",
        "                            sample_prob = [node_type_prob_normalized[node_type] for node_type in available_node_types]\n",
        "                            node_type = random.choices(available_node_types, sample_prob, k=1)[0]\n",
        "\n",
        "                            print(graph.nodes[current_node].get('type'), available_node_types)\n",
        "\n",
        "                            print(\"sampled node type for node {vnumber}: {vtype}\".format(vnumber = neighbor, vtype = node_type))\n",
        "                            graph.nodes[neighbor]['type'] = node_type\n",
        "\n",
        "                        queue.append(neighbor)\n",
        "                        visited.add(neighbor)\n",
        "\n",
        "                last_node = current_node\n",
        "            \n",
        "    for u, v  in graph.edges():\n",
        "      if (graph.nodes[u]['type'],graph.nodes[v]['type']) in possible_rel:\n",
        "        print(u,v, graph.nodes[u]['type'], graph.nodes[v]['type'], meta_graph[graph.nodes[u]['type']][graph.nodes[v]['type']])\n",
        "        graph.edges[u, v]['type'] = meta_graph[graph.nodes[u]['type']][graph.nodes[v]['type']]\n",
        "      else:\n",
        "        print(u,v, graph.nodes[u]['type'], graph.nodes[v]['type'], 'NA')\n",
        "        graph.edges[u, v]['type'] = 'NA'\n",
        "    \n",
        "    return graph\n",
        "\n",
        "meta_graph = {\n",
        "    'A': {'C': ('A', 'to', 'C')},\n",
        "    'B': {'C': ('B', 'to', 'C')},\n",
        "    'C': {'A': ('A', 'to', 'C'),'B':('B', 'to', 'C'), 'D':('C', 'to', 'D')},\n",
        "    'D': {'C':('C', 'to', 'D'),'D':('D', 'to', 'D')}\n",
        "}\n",
        "node_type_prob = {'A': 1, 'B': 1, 'C': 1, 'D': 1}\n",
        "num_nodes = 50\n",
        "graph = ws_graph(num_nodes, 3, 0.7)\n",
        "hetero_graph = generate_heterogeneous_small_world(graph, meta_graph, node_type_prob)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0sOim0bXdZ5"
      },
      "source": [
        "## Graph_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfJl6L56XEaN",
        "outputId": "d3ea72c2-72ef-47f1-dc51-46b5298b1cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('A', 'to', 'C'), ('B', 'to', 'C'), ('C', 'to', 'D'), ('D', 'to', 'D')]\n"
          ]
        }
      ],
      "source": [
        "# find unique relation types\n",
        "def unique_rel(meta_graph):\n",
        "  unique_elements = set()\n",
        "  for inner_dict in meta_graph.values():\n",
        "    for element in inner_dict.values():\n",
        "      unique_elements.add(element)\n",
        "\n",
        "  return unique_elements\n",
        "\n",
        "print(sorted(unique_rel(meta_graph)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW_oeYMakLA2"
      },
      "source": [
        "$\\nabla(f)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "5Cgh2-WFEfbR",
        "outputId": "4dec5299-cc90-432f-a8a0-0a29bad95ed1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos = nx.spring_layout(hetero_graph, seed=0)  # positions for all nodes\n",
        "\n",
        "# nodes\n",
        "options = {\"edgecolors\": \"tab:gray\", \"node_size\": 200, \"alpha\": 0.9}\n",
        "nx.draw_networkx_nodes(hetero_graph, pos, **options)\n",
        "\n",
        "# edges\n",
        "nx.draw_networkx_edges(hetero_graph, pos, width=1.0, alpha=0.5, edge_color=\"tab:red\",)\n",
        "\n",
        "labels = {i: graph.nodes[i]['type']+str(i) for i in range(len(graph.nodes))}\n",
        "nx.draw_networkx_labels(hetero_graph, pos, labels, font_size=5, font_color=\"whitesmoke\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.axis(\"off\")     \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLmE_0IIT1PS",
        "outputId": "9fffcd95-c05e-4b31-99c1-ec729886eec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('A', 'to', 'C'), ('B', 'to', 'C'), ('C', 'to', 'D'), ('D', 'to', 'D')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "def adjacency_tensor(graph, meta_graph):\n",
        "    edge_types = sorted(unique_rel(meta_graph))\n",
        "    # edge_types = ['rel_'+i+j for i,j in itertools.combinations_with_replacement(meta_graph.keys(), 2)]\n",
        "    print(edge_types)\n",
        "    n = len(graph.nodes())\n",
        "    r = len(edge_types)\n",
        "\n",
        "    adj_matrices = []\n",
        "\n",
        "    for edge_type in edge_types:\n",
        "        adj_matrix = np.zeros((n, n), dtype=np.int32)\n",
        "        \n",
        "        for u, v, data in graph.edges(data=True):\n",
        "            if data['type'] == edge_type:\n",
        "                adj_matrix[u, v] = 1\n",
        "                adj_matrix[v, u] = 1\n",
        "        \n",
        "        adj_matrices.append(adj_matrix)\n",
        "\n",
        "    edge_dict = {i: edge_types[i] for i in range(len(edge_types))}\n",
        "    return np.stack(adj_matrices, axis=-1), edge_dict\n",
        "\n",
        "adj_tsr, edge_dict = adjacency_tensor(hetero_graph, meta_graph)\n",
        "adj_tsr.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQHoxjkgPiwL",
        "outputId": "26135289-8477-4488-cec1-26283c058125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "400 100\n",
            "(400, 50)\n"
          ]
        }
      ],
      "source": [
        "def adj_to_cov(W_GT, num_nodes):\n",
        "  # W_GT = nx.adjacency_matrix(hetero_graph).todense()\n",
        "  weights = np.random.lognormal(0, 0.2, (num_nodes, num_nodes))\n",
        "  weights = (weights + weights.T) / 2\n",
        "  \n",
        "  W_GT = W_GT * weights\n",
        "  W_GT = W_GT * num_nodes / (np.sum(W_GT)+1e-10)\n",
        "  L_GT = np.diag(W_GT @ np.ones(num_nodes)) - W_GT\n",
        "  \n",
        "  cov_GT = np.linalg.inv(L_GT + (1e-1) * np.eye(num_nodes))\n",
        "  return cov_GT\n",
        "\n",
        "\n",
        "\n",
        "def generate_rel_signals(adj_tensor, sgl_dim):\n",
        "  noise_sigma = 1\n",
        "  num_nodes,_, rel_num = adj_tensor.shape\n",
        "  print(rel_num)\n",
        "  emb_dim = sgl_dim * rel_num\n",
        "  print(emb_dim, sgl_dim)\n",
        "  signals_nodes = np.random.multivariate_normal(np.zeros(num_nodes), noise_sigma* np.eye(num_nodes), emb_dim)\n",
        "  signals_edges = np.zeros((rel_num, emb_dim))\n",
        "  print(signals_nodes.shape)\n",
        "  for rel in range(rel_num):\n",
        "    # the dimensions that are specific to relation type\n",
        "    cov = adj_to_cov(adj_tensor[:,:,rel], num_nodes)\n",
        "    # signals_rel = np.random.multivariate_normal(np.zeros(num_nodes), cov, sgl_dim)\n",
        "    # the dimension that is not relevant to relation type\n",
        "    signals_nodes[sgl_dim*rel:sgl_dim*(rel+1)] = np.random.multivariate_normal(np.zeros(num_nodes), noise_sigma*cov, sgl_dim)\n",
        "    signals_edges[rel, sgl_dim*rel:sgl_dim*(rel+1)] = 1/sgl_dim\n",
        "  \n",
        "  return signals_nodes.T, signals_edges\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sgl_dim = 100\n",
        "signal_vtx, signals_edge = generate_rel_signals(adj_tsr, sgl_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULMclthonR05",
        "outputId": "3c3be5fe-6dd9-42dd-92c1-2298900f3d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "400 100\n",
            "rel_AC\n",
            "tensor([[ 0,  0,  0, 41, 47],\n",
            "        [ 1, 27, 49,  3, 48]])\n",
            "tensor([[ 0,  0,  0,  1,  2],\n",
            "        [ 0, 11, 20,  1, 19]], dtype=torch.int32)\n",
            "rel_BC\n",
            "tensor([[ 7,  7,  7,  9, 16, 22, 22, 23, 23, 23, 29, 32, 32, 36, 36, 36, 37],\n",
            "        [ 8, 14, 34, 10, 17, 17, 48, 26, 40, 46, 35, 31, 43,  8, 11, 48, 14]])\n",
            "tensor([[ 0,  0,  0,  1,  2,  3,  3,  4,  4,  4,  5,  6,  6,  7,  7,  7,  8],\n",
            "        [ 2,  5, 13,  3,  7,  7, 19, 10, 16, 18, 14, 12, 17,  2,  4, 19,  5]],\n",
            "       dtype=torch.int32)\n",
            "rel_CD\n",
            "tensor([[ 1,  3,  3, 10, 15, 18, 18, 24, 24, 26, 31, 31, 34, 34, 35, 38, 43, 43],\n",
            "        [39,  4, 30, 20, 44,  5, 39, 12, 21, 30, 13, 42,  6, 33,  6, 39,  4, 28]])\n",
            "tensor([[ 0,  1,  1,  3,  6,  8,  8,  9,  9, 10, 12, 12, 13, 13, 14, 15, 17, 17],\n",
            "        [13,  1, 11,  7, 15,  2, 13,  4,  8, 11,  5, 14,  3, 12,  3, 13,  1, 10]],\n",
            "       dtype=torch.int32)\n",
            "rel_DD\n",
            "tensor([[ 2,  4,  5,  6, 12, 13, 19, 20, 20, 21, 21, 25, 25, 28, 28, 42, 44, 45],\n",
            "        [28, 25,  6,  5, 13, 12, 20, 19, 21, 20, 45,  4, 28,  2, 25, 44, 42, 21]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  7,  8,  8,  9,  9, 10, 10, 14, 15, 16],\n",
            "        [10,  9,  3,  2,  5,  4,  7,  6,  8,  7, 16,  1, 10,  0,  9, 15, 14,  8]],\n",
            "       dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "def get_edge_idx(n_id, n_id_tsr, edge_idx):\n",
        "  # Expand B to have the same shape as (C.size(0), B.size(0))\n",
        "  expanded_ori = n_id_tsr.expand(edge_idx.shape[0], -1)\n",
        "  # Compute a mask where each row corresponds to the comparison of C[i] with B\n",
        "  mask = (expanded_ori == edge_idx.unsqueeze(1))\n",
        "  # Get the index in A by using the computed mask\n",
        "  # The method `max` is used to get the last occurrence, replace it with `min` for the first occurrence\n",
        "  # Use the indices to get the corresponding elements from A\n",
        "  _, indices = mask.max(dim=1)\n",
        "  return n_id[indices]\n",
        "\n",
        "\n",
        "def generate_hetero_sgls(hetero_graph, meta_graph, adj_tensor, sgl_dim, output_dim):\n",
        "  edge_types = sorted(unique_rel(meta_graph))\n",
        "  noise_sigma = 10\n",
        "  num_nodes,_ ,rel_num = adj_tensor.shape\n",
        "  print(rel_num)\n",
        "  emb_dim = sgl_dim * rel_num\n",
        "  print(emb_dim, sgl_dim)\n",
        "\n",
        "\n",
        "  signals_nodes = np.random.multivariate_normal(np.zeros(num_nodes), noise_sigma * np.eye(num_nodes), emb_dim)\n",
        "  signals_edges = np.zeros((rel_num, emb_dim))\n",
        "  \n",
        "  for i in range(len(edge_types)):\n",
        "    # the dimensions that are specific to relation type\n",
        "    cov = adj_to_cov(adj_tensor[:,:,i], num_nodes)\n",
        "    # signals_rel = np.random.multivariate_normal(np.zeros(num_nodes), cov, sgl_dim)\n",
        "    # the dimension that is not relevant to relation type\n",
        "    signals_nodes[sgl_dim*i:sgl_dim*(i+1)] = np.random.multivariate_normal(np.zeros(num_nodes), noise_sigma * cov, sgl_dim)\n",
        "    signals_edges[i, sgl_dim*i:sgl_dim*(i+1)] = 1/sgl_dim\n",
        "\n",
        "  signals_nodes = torch.Tensor(signals_nodes.T)\n",
        "  signals_edges = torch.Tensor(signals_edges)\n",
        "\n",
        "  graph_pyg = HeteroData()\n",
        "  trans_matrix = torch.rand(signals_nodes.shape[-1], output_dim)\n",
        "\n",
        "  for node_type in meta_graph:\n",
        "    node_idxs = [node_idx for node_idx in hetero_graph.nodes if node_type == hetero_graph.nodes[node_idx]['type']]\n",
        "    graph_pyg[node_type].x  = signals_nodes[node_idxs]\n",
        "    graph_pyg[node_type].n_id_tsr = torch.Tensor(node_idxs).int()\n",
        "    graph_pyg[node_type].n_id = torch.Tensor(range(len(graph_pyg[node_type].n_id_tsr))).int()\n",
        "  \n",
        "  for i, j in itertools.combinations_with_replacement(meta_graph.keys(), 2):\n",
        "    if (i, 'to', j) in edge_types:\n",
        "      print('rel_'+i+j)\n",
        "      edge_type_idx = edge_types.index((i, 'to', j))\n",
        "      non_zeros = torch.tensor(adj_tensor)[:,:,edge_type_idx].nonzero().T\n",
        "      mask = torch.isin(non_zeros[0, :], graph_pyg[i].n_id_tsr)\n",
        "      print(non_zeros[:, mask])\n",
        "\n",
        "      s_idx = get_edge_idx(graph_pyg[i].n_id, graph_pyg[i].n_id_tsr, non_zeros[:, mask][0])\n",
        "      t_idx = get_edge_idx(graph_pyg[j].n_id, graph_pyg[j].n_id_tsr, non_zeros[:, mask][1])\n",
        "      print(torch.stack((s_idx, t_idx), dim=0))\n",
        "\n",
        "      graph_pyg[(i, 'to', j)].edge_index = torch.stack((s_idx, t_idx), dim=0)\n",
        "  \n",
        "  edge_onehot = torch.eye(len(graph_pyg.edge_types))\n",
        "\n",
        "  i=0\n",
        "  for edge_type in graph_pyg.edge_types:\n",
        "    graph_pyg[edge_type].x = edge_onehot[i].reshape(1,-1)\n",
        "    # graph_pyg[edge_type].x = signals_edges[i].reshape(1,-1)\n",
        "    i+=1\n",
        "\n",
        "\n",
        "  return graph_pyg\n",
        "\n",
        "data = generate_hetero_sgls(hetero_graph, meta_graph, adj_tsr, sgl_dim, output_dim = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWdRaf1Fl0co"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import scipy.sparse as sparse\n",
        "\n",
        "def coo_to_sparseTensor(coo):\n",
        "    values = coo.data\n",
        "    indices = np.vstack((coo.row, coo.col))\n",
        "\n",
        "    i = torch.LongTensor(indices)\n",
        "    v = torch.FloatTensor(values)\n",
        "    shape = coo.shape\n",
        "\n",
        "    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()\n",
        "\n",
        "def get_degree_operator(m):\n",
        "  \n",
        "    ncols =int(m*(m - 1)/2)\n",
        "\n",
        "    I = np.zeros(ncols)\n",
        "    J = np.zeros(ncols)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        I[k:(k + m - i)] = np.arange(i, m)\n",
        "        k = k + (m - i)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        J[k: (k + m - i)] = i - 1\n",
        "        k = k + m - i\n",
        "\n",
        "    Row = np.tile(np.arange(0, ncols), 2)\n",
        "    Col = np.append(I, J)\n",
        "    Data = np.ones(Col.size)\n",
        "    St = sparse.coo_matrix((Data, (Row, Col)), shape=(ncols, m))\n",
        "    return St.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGQCk6cvn5qW"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import HeteroConv, Linear, SAGEConv, HeteroDictLinear\n",
        "\n",
        "class LinearProj(torch.nn.Module):\n",
        "    def __init__(self, node_shape, edge_shape, out_channels):\n",
        "        super().__init__()\n",
        "        # if node_shape\n",
        "        self.NodeLinear = HeteroDictLinear(in_channels=node_shape,out_channels=out_channels)\n",
        "        self.EdgeLinear = Linear(edge_shape[0],out_channels)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      node_attrs = {node_type: batch[node_type].x for node_type in batch.node_types}\n",
        "\n",
        "      node_out = self.NodeLinear(node_attrs)\n",
        "      edge_out = {edge_type: self.EdgeLinear(batch[edge_type].x) for edge_type in batch.edge_types}\n",
        "      \n",
        "      for node_type in batch.node_types:\n",
        "        node_out[node_type] = node_out[node_type]# /(node_out[node_type].norm(dim=1)[:, None])\n",
        "      for edge_type in batch.edge_types:\n",
        "        edge_out[edge_type] = edge_out[edge_type]# /(edge_out[edge_type].norm(dim=1)[:, None])\n",
        "\n",
        "      return (node_out, edge_out)\n",
        "\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, node_shape, edge_shape, w_l, D, out_channels=100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.out_channels = out_channels\n",
        "        self.w = torch.nn.Parameter(torch.rand(w_l))\n",
        "        self.D = D\n",
        "        self.hetero_linear = LinearProj(node_shape, edge_shape, out_channels=out_channels)\n",
        "        #self.classifier = Classifier()\n",
        "        \n",
        "\n",
        "    def forward(self, batch, device):\n",
        "\n",
        "        # D is the degree operator\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        node_out, edge_out = self.hetero_linear(batch)\n",
        "        pred_list = []\n",
        "        m = batch.num_nodes\n",
        "        r = len(batch.edge_types)\n",
        "        batch_size = 1\n",
        "        n_emb = torch.zeros(m, self.out_channels).to(device)\n",
        "        \n",
        "        for n_type in batch.node_types:\n",
        "          n_emb[batch[n_type].n_id_tsr] = node_out[n_type]\n",
        "          # print('node_out shape',node_out[n_type].shape)\n",
        "          # print(batch[n_type].n_id)\n",
        "        r_emb = [edge_out[r_type] for r_type in sorted(batch.edge_types)]\n",
        "        r_emb = torch.cat(r_emb, dim=0)\n",
        "        n_emb = n_emb/(n_emb.norm(dim=1)[:, None])\n",
        "        r_emb = r_emb/(r_emb.norm(dim=1)[:, None])\n",
        "        diff_tensor = (n_emb[:, None, None, :] - n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "        # diff_tensor = n_emb[:, None, None, :] * n_emb[None,: , None, :] * r_emb[ None, None, :, :]\n",
        "        # print(r_emb.shape)\n",
        "        # print(n_emb.shape)\n",
        "        # print('n_emb', torch.max(torch.abs(n_emb)))\n",
        "        # print('r_emb',torch.max(torch.abs(r_emb)))\n",
        "        sigma = 1e-3\n",
        "        smooth_tensor = torch.exp(-1/sigma * torch.norm(diff_tensor, dim=-1)**2)\n",
        "        smooth_tensor = smooth_tensor.unsqueeze(0)\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth_tensor[:, mask].view(batch_size, -1)\n",
        "\n",
        "        return self.w.view(1,-1), z\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Softmax\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EdgeLinearProj(torch.nn.Module):\n",
        "    def __init__(self, edge_shape, out_channels):\n",
        "        super().__init__()\n",
        "        # if node_shape\n",
        "        self.EdgeLinear = Linear(edge_shape[0],out_channels)\n",
        "        # self.sfx = Softmax(dim=1)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      sigma = 1e-3\n",
        "      edge_in = torch.cat([batch[edge_type].x for edge_type in batch.edge_types], dim=0)\n",
        "      edge_out = self.EdgeLinear(edge_in)\n",
        "      edge_out = self.sfx(F.relu(edge_out)/sigma)\n",
        "      return edge_out\n",
        "\n",
        "\n",
        "class Model_simplified(torch.nn.Module):\n",
        "    def __init__(self, edge_shape, w_l, D, out_channels=100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.out_channels = out_channels\n",
        "        self.w = torch.nn.Parameter(torch.rand(w_l))\n",
        "        self.D = D\n",
        "        self.hetero_linear = EdgeLinearProj(edge_shape, out_channels=out_channels)\n",
        "        #self.classifier = Classifier()\n",
        "        \n",
        "\n",
        "    def forward(self, batch, device):\n",
        "\n",
        "        # D is the degree operator\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        \n",
        "        pred_list = []\n",
        "        m = batch.num_nodes\n",
        "        r = len(batch.edge_types)\n",
        "        batch_size = 1\n",
        "        n_emb = torch.zeros(m, self.out_channels).to(device)\n",
        "        \n",
        "        for n_type in batch.node_types:\n",
        "          n_emb[batch[n_type].n_id_tsr] = batch[n_type].x\n",
        "          # print('node_out shape',node_out[n_type].shape)\n",
        "          # print(batch[n_type].n_id)\n",
        "        r_emb = self.hetero_linear(batch)\n",
        "\n",
        "        diff_tensor = (n_emb[:, None, None, :] - n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "        # diff_tensor = n_emb[:, None, None, :] * n_emb[None,: , None, :] * r_emb[ None, None, :, :]\n",
        "        # print(r_emb.shape)\n",
        "        # print(n_emb.shape)\n",
        "        # print('n_emb', torch.max(torch.abs(n_emb)))\n",
        "        # print('r_emb',torch.max(torch.abs(r_emb)))\n",
        "        smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "        smooth_tensor = smooth_tensor.unsqueeze(0)\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        # print(smooth_tensor[0,:,:,0])\n",
        "        z = smooth_tensor[:, mask].view(batch_size, -1)\n",
        "\n",
        "        return self.w.view(1,-1), z, smooth_tensor\n"
      ],
      "metadata": {
        "id": "TX562upLPaQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Softmax\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EdgeLinearProj(torch.nn.Module):\n",
        "    def __init__(self, edge_shape, out_channels):\n",
        "        super().__init__()\n",
        "        # if node_shape\n",
        "        self.EdgeLinear = Linear(edge_shape[0],out_channels)\n",
        "        self.sfx = Softmax(dim=1)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      sigma = 1e-3\n",
        "      edge_in = torch.cat([batch[edge_type].x for edge_type in batch.edge_types], dim=0)\n",
        "      edge_out = self.EdgeLinear(edge_in)\n",
        "      # edge_out = self.sfx(F.relu(edge_out)/sigma)\n",
        "      return edge_out\n",
        "\n",
        "\n",
        "class Model_simplified(torch.nn.Module):\n",
        "    def __init__(self, edge_shape, w_l, D, out_channels=100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.out_channels = out_channels\n",
        "        self.w = torch.nn.Parameter(torch.rand(w_l))\n",
        "        self.D = D\n",
        "        self.hetero_linear = EdgeLinearProj(edge_shape, out_channels=out_channels)\n",
        "        self.sigma = 1\n",
        "        #self.classifier = Classifier()\n",
        "        \n",
        "\n",
        "    def forward(self, batch, device):\n",
        "\n",
        "        # D is the degree operator\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        \n",
        "        pred_list = []\n",
        "        m = batch.num_nodes\n",
        "        r = len(batch.edge_types)\n",
        "        batch_size = 1\n",
        "        n_emb = torch.zeros(m, self.out_channels).to(device)\n",
        "        \n",
        "        for n_type in batch.node_types:\n",
        "          n_emb[batch[n_type].n_id_tsr] = batch[n_type].x\n",
        "          # print('node_out shape',node_out[n_type].shape)\n",
        "          # print(batch[n_type].n_id)\n",
        "        r_emb = self.hetero_linear(batch)\n",
        "\n",
        "        diff_tensor = (n_emb[:, None, None, :] -n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "        # diff_tensor = n_emb[:, None, None, :] * n_emb[None,: , None, :] * r_emb[ None, None, :, :]\n",
        "        # print(r_emb.shape)\n",
        "        # print(n_emb.shape)\n",
        "        # print('n_emb', torch.max(torch.abs(n_emb)))\n",
        "        # print('r_emb',torch.max(torch.abs(r_emb)))\n",
        "        smooth_tensor = torch.exp(- 1/self.sigma *torch.mean(diff_tensor**2, dim=-1))\n",
        "        smooth_tensor = smooth_tensor.unsqueeze(0)\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        # print(smooth_tensor[0,:,:,0])\n",
        "        z = smooth_tensor[:, mask].view(batch_size, -1)\n",
        "        # print(torch.norm(diff_tensor, dim=-1))\n",
        "\n",
        "        return self.w.view(1,-1), z, smooth_tensor\n"
      ],
      "metadata": {
        "id": "WzjMl7W_Gb8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifVs1-vdxjoD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import itertools\n",
        "\n",
        "def objective(w, D, z, l2_penalty=1, log_penalty=1):\n",
        "  alpha = log_penalty\n",
        "  beta = l2_penalty \n",
        "\n",
        "  w = F.relu(w)\n",
        "  '''\n",
        "  f1 = beta * torch.norm(w, 2)\n",
        "  f2 = w @ z.T \n",
        "  f3 = - alpha * torch.sum(torch.log(w@D.T))\n",
        "  f4 = 1 * torch.norm(z, 1)\n",
        "  '''\n",
        "  f1 = beta * torch.norm(z, 2)\n",
        "  f2 = z@torch.ones_like(z).T \n",
        "  f3 = - alpha * torch.sum(torch.log(z@D.T))\n",
        "  print(f1,f2[0][0],f3)\n",
        "  \n",
        "\n",
        "  if torch.all(w.ge(0)) >= 0:\n",
        "    return f1 + f2[0][0] + f3 \n",
        "  else:\n",
        "    return 10**3\n",
        "\n",
        "\n",
        "def permute_auc(predict_w, rel_num, adj_vec):\n",
        "  predict_w = predict_w/(torch.max(predict_w))\n",
        "  predict_w = predict_w.reshape(-1, rel_num)\n",
        "  # generate all permutations of the indices [0, 1, ..., dim_size-1]\n",
        "  permutations = list(itertools.permutations(range(rel_num)))\n",
        "  # convert to a list of PyTorch tensors\n",
        "  idx_list = [torch.tensor(p) for p in permutations]\n",
        "  auc_max = 0\n",
        "  auc_list = []\n",
        "  GMSE_smallest = 1\n",
        "  GMSE_list = []\n",
        "  for permute_idx in idx_list:\n",
        "    predict_w_flatten = predict_w[:, permute_idx].view(1,-1)\n",
        "    auc = roc_auc_score(adj_vec[0].long().numpy(), predict_w_flatten.to('cpu')[0].detach())\n",
        "    auc_list.append(auc)\n",
        "    GMSE_error = torch.mean(torch.square(predict_w[:, permute_idx].view(1,-1).to('cpu')-adj_vec.to('cpu')))\n",
        "    GMSE_list.append(GMSE_error)\n",
        "  return np.max(auc_list), auc_list, torch.min(GMSE_error), GMSE_list\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## experiment on synthetic dataset"
      ],
      "metadata": {
        "id": "lnAjlMb1Aewf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mask = torch.triu(torch.ones(data.num_nodes, data.num_nodes), diagonal=1).bool()\n",
        "adj_vec = torch.Tensor(adj_tsr)[mask].view(1, -1)\n",
        "\n",
        "node_shape = {node_type: data[node_type].x.shape[-1] for node_type in data.node_types}\n",
        "edge_shape = [data[edge_type].x.shape[-1] for edge_type in data.edge_types]\n",
        "\n",
        "\n",
        "w_l = int(data.num_nodes*(data.num_nodes-1)*len(data.edge_types)/2)\n",
        "D_ori = coo_to_sparseTensor(get_degree_operator(data.num_nodes)).to(device)\n",
        "eye = torch.eye(int(data.num_nodes*(data.num_nodes-1)/2))\n",
        "shift_sum = eye.repeat_interleave(len(data.edge_types), dim=1)\n",
        "D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "model = Model_simplified(edge_shape, w_l, D, out_channels=sgl_dim*len(data.edge_types))\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-3)\n",
        "data = data.to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(1, 3001):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  loss = 0\n",
        "  w, z, smooth_vector = model(data, device)\n",
        "  loss = objective(w=w.to(device), D=D.to(device), z=z.to(device))\n",
        "  print(loss)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  \n",
        "  # auc, auc_list, GMSE, GMSE_list = permute_auc(w, len(data.edge_types), adj_vec)\n",
        "  auc, auc_list, GMSE, GMSE_list = permute_auc(z, len(data.edge_types), adj_vec)\n",
        "  print('loss: {}, epoch: {}, auc: {}, GMSE: {}'.format(loss, epoch, auc, GMSE))\n"
      ],
      "metadata": {
        "id": "Oj8yUi6fAeFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmV_Sma4_wt4"
      },
      "outputs": [],
      "source": [
        "permute_auc(z, len(data.edge_types), adj_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVmtbgxdAQFH"
      },
      "outputs": [],
      "source": [
        "def get_w_indices(adj_vec, w):\n",
        "  rel_num=4\n",
        "  predict_w = w.reshape(-1, rel_num)\n",
        "  indices = torch.where(adj_vec==1)\n",
        "  permutations = list(itertools.permutations(range(rel_num)))\n",
        "  # convert to a list of PyTorch tensors\n",
        "  idx_list = [torch.tensor(p) for p in permutations]\n",
        "  for permute_idx in idx_list:\n",
        "    predict_w_flatten = predict_w[:, permute_idx].view(1,-1)\n",
        "    print(F.relu(predict_w_flatten))\n",
        "\n",
        "\n",
        "get_w_indices(adj_vec, w)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z[0,300:400]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ujDjGxW7PFL",
        "outputId": "2c8b14c7-09f3-49a9-ed8c-96717ff32f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0092, 0.0096, 0.0127, 0.0094, 0.0111, 0.0101, 0.0088, 0.0076, 0.0095,\n",
              "        0.0095, 0.0116, 0.0104, 0.0132, 0.0114, 0.0098, 0.0104, 0.0093, 0.0087,\n",
              "        0.0095, 0.0097, 0.0121, 0.0100, 0.0109, 0.0100, 0.0117, 0.0095, 0.0082,\n",
              "        0.0092, 0.0099, 0.0111, 0.0129, 0.0112, 0.0121, 0.0095, 0.0095, 0.0089,\n",
              "        0.0099, 0.0099, 0.0098, 0.0097, 0.0132, 0.0121, 0.0129, 0.0105, 0.0113,\n",
              "        0.0109, 0.0121, 0.0110, 0.0137, 0.0119, 0.0099, 0.0106, 0.0128, 0.0102,\n",
              "        0.0093, 0.0093, 0.0111, 0.0101, 0.0099, 0.0108, 0.0123, 0.0114, 0.0106,\n",
              "        0.0100, 0.0099, 0.0097, 0.0112, 0.0108, 0.0085, 0.0078, 0.0097, 0.0079,\n",
              "        0.0083, 0.0080, 0.0084, 0.0089, 0.0115, 0.0096, 0.0084, 0.0087, 0.0112,\n",
              "        0.0095, 0.0094, 0.0092, 0.0108, 0.0111, 0.0116, 0.0105, 0.0094, 0.0092,\n",
              "        0.0110, 0.0095, 0.0103, 0.0133, 0.0112, 0.0106, 0.0118, 0.0107, 0.0105,\n",
              "        0.0115], device='cuda:0', grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj_vec[0,300:400]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRtJie5CZsq7",
        "outputId": "432656c0-ebaa-48b6-f2a8-ab3e1645d03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JgawRtQ9-q-",
        "outputId": "65801270-bfa9-4469-b1b6-de240af0f4d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 546
        }
      ],
      "source": [
        "adj_vec[indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXAnopZv4iiq",
        "outputId": "3a944f38-30d5-443d-98ee-2fae6bb8fff3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0472, -0.0928, -0.0822,  ..., -0.0066, -0.0161, -0.0383],\n",
              "        [ 0.0393,  0.0571, -0.0352,  ...,  0.0610,  0.0225, -0.0507],\n",
              "        [-0.0182, -0.0076, -0.0363,  ..., -0.0866,  0.0406, -0.0427],\n",
              "        ...,\n",
              "        [-0.0538,  0.0435, -0.0638,  ...,  0.0683, -0.0199, -0.1065],\n",
              "        [-0.0917, -0.0734,  0.0220,  ...,  0.0162, -0.0171,  0.0488],\n",
              "        [-0.0965, -0.0540,  0.0426,  ..., -0.0566,  0.0819,  0.0432]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model.hetero_linear.NodeLinear.reset_parameters()\n",
        "model.hetero_linear.NodeLinear.lins['A'].weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hqoe5vKr2he"
      },
      "source": [
        "## From signal estimate Laplacian Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiYPmEAFtNai"
      },
      "outputs": [],
      "source": [
        "class ADMM():\n",
        "    def __init__(self, l2_penalty, log_penalty, step_size=1e-02, relaxation_factor = 1.8):\n",
        "        self.alpha = log_penalty  # the penalty before log barrier\n",
        "        self.beta = l2_penalty  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "        self.relax = relaxation_factor\n",
        "\n",
        "    def initialisation(self, l, m, batch_size=1):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        up = y ** 2 + 4 * gn * alpha\n",
        "        up = torch.clamp(up, 1e-08)\n",
        "        return (y - torch.sqrt(up)) / 2\n",
        "\n",
        "    def objective(self, w, D, z):\n",
        "        f1 = self.beta * torch.norm(w, 2) ** 2\n",
        "        f2 = w.T @ z\n",
        "        f3 = - self.alpha * torch.sum(torch.log(D @ w))\n",
        "\n",
        "        if all(np.round(w, 4) >= 0):\n",
        "            return f1 + f2 + f3\n",
        "        else:\n",
        "            return 10**3\n",
        "\n",
        "    def solve(self, smooth, max_iter=1000, verbose=True):\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # D * shift_sum if the new operator\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_ite, l))\n",
        "        # print(w_list.shape)\n",
        "\n",
        "        lambda_ = self.relax\n",
        "\n",
        "        for i in range(max_iter):\n",
        "\n",
        "            y1 = w - self.gn * (2 * self.beta * w + torch.matmul(v, D))\n",
        "            p1 = torch.max(zero_vec, y1 - 2 * self.gn * z)\n",
        "\n",
        "            y2 = v + self.gn * torch.matmul(2 * p1 - w, D.T)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            w = w + lambda_ * (p1 - w)\n",
        "            v = v + lambda_ * (p2 - v)\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n",
        "\n",
        "#%%\n",
        "\n",
        "class PDS():\n",
        "    def __init__(self, l2_psi, log_psi, step_size):\n",
        "        self.alpha = log_psi  # the penalty before log barrier\n",
        "        self.beta = l2_psi  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        return (y - torch.sqrt(y ** 2 + 4 * gn * alpha)) / 2\n",
        "\n",
        "    def initialisation(self, l, m, batch_size):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def solve(self, smooth, max_iter = 500):\n",
        "        # z \\in 1* m* m * r\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_iter, l)).to(device)\n",
        "        for i in range(max_iter):\n",
        "            # print(z.shape)\n",
        "            y1 = w - self.gn * (2 * self.beta * w + 2 * z + torch.matmul(v, D))\n",
        "            y2 = v + self.gn * torch.matmul(w, D.T)\n",
        "\n",
        "            p1 = torch.max(zero_vec, y1)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            q1 = p1 - self.gn * (2 * self.beta * p1 + 2 * z + torch.matmul(p2, D))\n",
        "            q2 = p2 + self.gn * torch.matmul(p1, D.T)\n",
        "\n",
        "            w = w - y1 + q1\n",
        "            v = v - y2 + q2\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C927h38nwdmS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "def auc_test(model, loader, device):\n",
        "  preds = []\n",
        "  ground_truths = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  for test_batch in tqdm.tqdm(loader):\n",
        "      test_batch = test_batch.to(device)\n",
        "      preds.append(model(test_batch))\n",
        "      with torch.no_grad():\n",
        "        for edge_type in test_batch.edge_types:\n",
        "          ground_truths.append(test_batch[edge_type].edge_label)\n",
        "  pred = torch.cat(preds, dim=0).cpu().detach().numpy()\n",
        "  # pred = pred/np.max(pred)\n",
        "  ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "  auc = roc_auc_score(ground_truth, pred)\n",
        "  f1 = f1_score(ground_truth, (pred>0.5))\n",
        "  return auc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYuxhkoA11ve"
      },
      "outputs": [],
      "source": [
        "pds_opt = PDS(1, 1, 1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qm7BNj-oCca"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def estimate_w(signal_vtx, signals_edge, adj_tensor, optimizer):\n",
        "  diff_tensor = (signal_vtx[:, None, None, :] - signal_vtx[None,: , None, :]) * signals_edge[ None, None, :, :]\n",
        "  diff_tensor = torch.Tensor(diff_tensor)\n",
        "  num_nodes,_,num_relations ,K = diff_tensor.shape\n",
        "  smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "  # est_tensor = torch.exp(- 1/sigma * smooth_tensor)\n",
        "  adj_tensor = torch.Tensor(adj_tensor).unsqueeze(0).to(device)\n",
        "  mask = torch.triu(torch.ones(num_nodes, num_nodes), diagonal=1).bool()\n",
        "  adj_vec = adj_tensor[:, mask].view(1, -1)\n",
        "  print(smooth_tensor.shape)\n",
        "  w = optimizer.solve(smooth_tensor.unsqueeze(0).to(device), max_iter = 500)\n",
        "  # Normalization\n",
        "  w = w/torch.max(w)\n",
        "  GMSE_error = torch.sum(torch.square(w-adj_vec)/(w+1e-12))\n",
        "\n",
        "  num_samples = w.shape[0] * w.shape[1]*w.shape[0]\n",
        "  edge_indices = torch.where(adj_vec == 1)\n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = w[edge_indices]\n",
        "  print(adj_vec[edge_indices])\n",
        "  print(w)\n",
        "  print(out_edges)\n",
        "  link_error = torch.mean(torch.square(adj_vec[edge_indices] - out_edges))\n",
        "  print(GMSE_error/num_samples)\n",
        "  print(torch.sqrt(link_error))\n",
        "  auc = roc_auc_score(adj_vec.to('cpu')[0], w.to('cpu')[0])\n",
        "  f1 = f1_score(adj_vec.to('cpu')[0], (w>0.8).to('cpu')[0])\n",
        "  print(auc, f1)\n",
        "  # auc = roc_auc_score(adj_vec[edge_indices].to('cpu').detach().numpy(), out_edge\n",
        "\n",
        "\n",
        "estimate_w(signal_vtx, signals_edge, adj_tsr, pds_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k1teprfrc85",
        "outputId": "ea8c3b76-d382-4c2d-8350-8a8a24717f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50, 50, 15])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[ 9.3078e-02, -2.9427e-44,  5.7762e-02,  ..., -2.9427e-44,\n",
            "          1.6641e-01,  9.5891e-02]], device='cuda:0')\n",
            "tensor([0.9519, 0.8509, 0.8758, 0.9388, 1.0000, 0.8812, 0.9650, 0.9385, 0.9189,\n",
            "        0.8664, 0.8285, 0.8937, 0.8985, 0.9194, 0.9301, 0.9270, 0.9160, 0.9065,\n",
            "        0.8700, 0.9062, 0.9256, 0.9198, 0.8712, 0.9219, 0.9439, 0.8959, 0.9051,\n",
            "        0.8782, 0.8873, 0.9201, 0.9253, 0.9095, 0.8782, 0.8949, 0.9091, 0.9214,\n",
            "        0.8798, 0.8581, 0.9152, 0.9520, 0.9108, 0.8998, 0.9200, 0.9185, 0.8673,\n",
            "        0.8894, 0.9047, 0.9358, 0.9261, 0.9774], device='cuda:0')\n",
            "tensor(0.0736, device='cuda:0')\n",
            "tensor(0.0966, device='cuda:0')\n",
            "0.999587448840382\n"
          ]
        }
      ],
      "source": [
        "admm_opt = ADMM(l2_penalty=2, log_penalty=1, step_size=1e-02, relaxation_factor = 1.8)\n",
        "estimate_w(signal_vtx, signals_edge, adj_tsr, admm_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcO5vCZzw4BA"
      },
      "source": [
        "# Graph Sampling from huge heterogeneous graph\n",
        "\n",
        "Loading graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "id": "JAVnfyAiPXVJ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import IMDB\n",
        "\n",
        "dataset_dblp = IMDB(root='./data/imdb')\n",
        "data = dataset_dblp[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEz1bUQ1BODt",
        "outputId": "ff8b6e18-9d3d-487e-ca3b-3d20d771c281"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mmovie\u001b[0m={\n",
              "    x=[4278, 3066],\n",
              "    y=[4278],\n",
              "    train_mask=[4278],\n",
              "    val_mask=[4278],\n",
              "    test_mask=[4278]\n",
              "  },\n",
              "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
              "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
              "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
              "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 12828] },\n",
              "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
              "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 12828] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_idx = data[('movie', 'to', 'actor')].edge_index\n",
        "x_movie = data['movie'].x[edge_idx[0]]\n",
        "x_actor = data['actor'].x[edge_idx[1]]\n",
        "edge_nonzeros = x_movie * x_actor"
      ],
      "metadata": {
        "id": "cjvDrroPi4_7"
      },
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(torch.sum(edge_nonzeros, dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaH8Ak00vFto",
        "outputId": "5f31a697-dc40-4c37-a11d-e768c9e962b9"
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(733.7616)"
            ]
          },
          "metadata": {},
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values, indices = torch.topk(torch.sum(edge_nonzeros, dim=0),k=25)"
      ],
      "metadata": {
        "id": "WW4Y_n6Q4Opl"
      },
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_non_zero = torch.sum(edge_nonzeros[:,indices], dim=-1)"
      ],
      "metadata": {
        "id": "nfs7ouvF4mLb"
      },
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum((torch_non_zero!=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNbBf9-A5JP8",
        "outputId": "03d1945a-2b02-4b3d-c45b-6f55e96dec95"
      },
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6274)"
            ]
          },
          "metadata": {},
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_non_zero[torch_non_zero !=0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtAxl_-j46eX",
        "outputId": "c3e23d10-d02f-4eb7-8c18-2d959f26be0d"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6274])"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.where(edge_nonzeros!=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRdzdWXfut9e",
        "outputId": "81c9f296-43fb-49f5-e32b-ccd45131f820"
      },
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    0,     0,     0,  ..., 12821, 12821, 12821]),\n",
              " tensor([ 230, 1125, 1673,  ..., 2749, 2828, 3029]))"
            ]
          },
          "metadata": {},
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random.mtrand import noncentral_chisquare\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.loader import HGTLoader\n",
        "\n",
        "def data_preprocessing(data):\n",
        "  # node type processing\n",
        "  # for node_type in data.node_types:\n",
        "  #   if data[node_type].x is None:\n",
        "  # data['conference'].x = torch.eye(data['conference'].num_nodes)\n",
        "\n",
        "  # edge type processing\n",
        "  edge_onehot = torch.eye(len(data.edge_types))\n",
        "  i=0\n",
        "  for edge_type in data.edge_types:\n",
        "    data[edge_type].x = edge_onehot[i].reshape(1,-1)\n",
        "    i+=1\n",
        "  return data\n",
        "\n",
        "def data_spliting(data):\n",
        "  transform = RandomLinkSplit(num_val=0.3, num_test=0.2, \n",
        "                            is_undirected=True,\n",
        "                            neg_sampling_ratio=0,\n",
        "                            add_negative_train_samples=False,\n",
        "                            edge_types=data.edge_types)\n",
        "  train_test_split = transform(data)\n",
        "  data_list = []\n",
        "  for b_data in train_test_split:\n",
        "    b_data.generate_ids()\n",
        "    \n",
        "    for edge_type in b_data.edge_types:\n",
        "      b_data[edge_type].e_id = torch.arange(len(b_data[edge_type].edge_label))\n",
        "      b_data[edge_type].edge_index = b_data[edge_type].edge_label_index\n",
        "      del b_data[edge_type].edge_label_index\n",
        "    data_list.append(b_data)\n",
        "  \n",
        "  return data_list\n",
        "\n",
        "def data_batching(data, batch_size, input_nodes):\n",
        "    loader = HGTLoader(\n",
        "    data,\n",
        "    # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "    num_samples={key: [2] * 8 for key in data.node_types},\n",
        "    # Use a batch size of 128 for sampling training nodes of type paper\n",
        "    batch_size = batch_size,\n",
        "    input_nodes=input_nodes,\n",
        "    )\n",
        "    return loader\n",
        "\n",
        "\n",
        "data = data_preprocessing(data)\n",
        "train_data, val_data, test_data = data_spliting(data)\n",
        "train_loader = data_batching(train_data, 1, ('movie'))\n",
        "val_loader = data_batching(val_data, 1, ('movie'))\n",
        "test_loader = data_batching(test_data, 1, ('movie'))"
      ],
      "metadata": {
        "id": "PqJVtxOhBLZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "dK8HUug-BvI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import scipy.sparse as sparse\n",
        "\n",
        "def coo_to_sparseTensor(coo):\n",
        "    values = coo.data\n",
        "    indices = np.vstack((coo.row, coo.col))\n",
        "\n",
        "    i = torch.LongTensor(indices)\n",
        "    v = torch.FloatTensor(values)\n",
        "    shape = coo.shape\n",
        "\n",
        "    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()\n",
        "\n",
        "def get_degree_operator(m):\n",
        "  \n",
        "    ncols =int(m*(m - 1)/2)\n",
        "\n",
        "    I = np.zeros(ncols)\n",
        "    J = np.zeros(ncols)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        I[k:(k + m - i)] = np.arange(i, m)\n",
        "        k = k + (m - i)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        J[k: (k + m - i)] = i - 1\n",
        "        k = k + m - i\n",
        "\n",
        "    Row = np.tile(np.arange(0, ncols), 2)\n",
        "    Col = np.append(I, J)\n",
        "    Data = np.ones(Col.size)\n",
        "    St = sparse.coo_matrix((Data, (Row, Col)), shape=(ncols, m))\n",
        "    return St.T"
      ],
      "metadata": {
        "id": "6g0QFxKLXNt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Softmax\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "\n",
        "class EdgeLinearProj(torch.nn.Module):\n",
        "    def __init__(self, edge_shape, out_channels):\n",
        "        super().__init__()\n",
        "        # if node_shape\n",
        "        self.EdgeLinear = Linear(edge_shape[0],out_channels)\n",
        "        self.sfx = Softmax(dim=1)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      sigma = 1e-3\n",
        "      edge_in = torch.cat([batch[edge_type].x for edge_type in batch.edge_types], dim=0)\n",
        "      edge_out = self.EdgeLinear(edge_in)\n",
        "      # edge_out = sigma * self.sfx(F.relu(edge_out)/sigma)\n",
        "      return edge_out\n",
        "\n",
        "\n",
        "class Model_simplified(torch.nn.Module):\n",
        "    def __init__(self, edge_shape, w_l, D, out_channels=100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.out_channels = out_channels\n",
        "        self.w = torch.nn.Parameter(torch.rand(w_l))\n",
        "        self.D = D\n",
        "        self.hetero_linear = EdgeLinearProj(edge_shape, out_channels=out_channels)\n",
        "        self.sigma = 1\n",
        "        #self.classifier = Classifier()\n",
        "        \n",
        "\n",
        "    def forward(self, batch, device):\n",
        "\n",
        "        # D is the degree operator\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        \n",
        "        pred_list = []\n",
        "        m = batch.num_nodes\n",
        "        r = len(batch.edge_types)\n",
        "        batch_size = 1\n",
        "        n_emb = torch.zeros(m, self.out_channels).to(device)\n",
        "        \n",
        "        for n_type in batch.node_types:\n",
        "          n_emb[batch[n_type].n_id_tsr] = batch[n_type].x\n",
        "          # print('node_out shape',node_out[n_type].shape)\n",
        "          # print(batch[n_type].n_id)\n",
        "        r_emb = self.hetero_linear(batch)\n",
        "\n",
        "        # diff_tensor = (n_emb[:, None, None, :] * n_emb[None,: , None, :])**2\n",
        "        # diff_tensor = n_emb[:, None, None, :] * n_emb[None,: , None, :] * r_emb[ None, None, :, :]\n",
        "        diff_tensor = (n_emb[:, None, None, :] - n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "\n",
        "        smooth_tensor = torch.sum(diff_tensor**2, dim=-1)\n",
        "        smooth_tensor = torch.exp( - 1/self.sigma * smooth_tensor)\n",
        "        smooth_tensor = smooth_tensor.unsqueeze(0)\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        # print(smooth_tensor[0,:,:,0])\n",
        "        z = smooth_tensor[:, mask].view(batch_size, -1)\n",
        "        # print(indices)\n",
        "        # print(smooth_tensor)\n",
        "        # print(smooth_tensor[:,indices[0], indices[1]].reshape(-1))\n",
        "        # print(smooth_tensor[smooth_tensor!=0].reshape(-1))\n",
        "\n",
        "        return self.w.view(1,-1), z, smooth_tensor\n"
      ],
      "metadata": {
        "id": "zfRtdLEzDxHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_adjtensor(batch, node_out):\n",
        "  # create an empty dictionary to store the indices\n",
        "  indices_dict = {}\n",
        "  # list to hold the tensors\n",
        "  tensor_list = []\n",
        "  start_index = 0\n",
        "  for node_type in batch.node_types:\n",
        "    node_emb = node_out[node_type]\n",
        "    end_index = start_index + node_emb.size(0)\n",
        "    indices_dict[node_type] = (start_index, end_index)  # store the start and end index for this type\n",
        "    batch[node_type].n_id_tsr= torch.arange(start_index, end_index).int()\n",
        "    tensor_list.append(node_emb)\n",
        "    start_index = end_index  # update the start index for the next type\n",
        "    # concatenate the tensors\n",
        "\n",
        "  node_tensor = torch.cat(tensor_list, dim=0)\n",
        "  print(node_tensor.shape)\n",
        "\n",
        "  adj_matrices = []\n",
        "  # print('start transforming')\n",
        "  for edge_type in batch.edge_types:\n",
        "    # print(edge_type, batch[edge_type].edge_index)\n",
        "    \n",
        "    if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "        continue\n",
        "    # Initialize the adjacency matrix\n",
        "    N = node_tensor.size(0)\n",
        "    adj_matrix = torch.zeros(N, N)\n",
        "    # Populate the adjacency matrix\n",
        "    s_ntype, _, e_ntype = edge_type\n",
        "    start_indices = indices_dict[s_ntype]\n",
        "    end_indices = indices_dict[e_ntype]\n",
        "\n",
        "    # map the indices in edge_index to their corresponding indices in the big tensor\n",
        "    edge_idx = batch[edge_type].edge_index.detach().clone()\n",
        "    edge_label = batch[edge_type].edge_label\n",
        "    edge_idx[0] += start_indices[0]  # add the start index of the start node type to the start nodes in edge_index\n",
        "    edge_idx[1] += end_indices[0]  # add the start index of the end node type to the end nodes in edge_index\n",
        "\n",
        "    for i in range(edge_idx.shape[1]):\n",
        "      if edge_label[i] == 1:\n",
        "        one_edge = edge_idx[:, i]\n",
        "        adj_matrix[one_edge[0], one_edge[1]] = 1\n",
        "    adj_matrices.append(adj_matrix)\n",
        "\n",
        "  adj_matrices = torch.stack(adj_matrices, dim=-1)\n",
        "  return node_tensor, adj_matrices"
      ],
      "metadata": {
        "id": "opmw9nQdDRQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import itertools\n",
        "\n",
        "def objective(w, D, z, l2_penalty=1, log_penalty=1):\n",
        "  alpha = log_penalty\n",
        "  beta = l2_penalty \n",
        "\n",
        "  w = F.relu(w)\n",
        "  '''\n",
        "  f1 = beta * torch.norm(w, 2)\n",
        "  f2 =  w @ z.T \n",
        "  f3 = - alpha * torch.sum(torch.log(w@D.T))\n",
        "  f4 = 1 * torch.norm(z, 1)\n",
        "  '''\n",
        "  f1 = beta * torch.norm(z, 2)\n",
        "  f2 =  z @ torch.ones_like(z).T\n",
        "  f3 = - alpha * torch.sum(torch.log(z@D.T))\n",
        "  print(f1,f2[0][0],f3)\n",
        "\n",
        "  if torch.all(w.ge(0)) >= 0:\n",
        "    return f1 + f2[0][0] + f3 \n",
        "  else:\n",
        "    return 10**3\n",
        "\n",
        "\n",
        "def permute_auc(predict_w, rel_num, adj_vec):\n",
        "  predict_w = predict_w/(torch.max(predict_w))\n",
        "  predict_w = predict_w.reshape(-1, rel_num)\n",
        "  # generate all permutations of the indices [0, 1, ..., dim_size-1]\n",
        "  permutations = list(itertools.permutations(range(rel_num)))\n",
        "  # convert to a list of PyTorch tensors\n",
        "  idx_list = [torch.tensor(p) for p in permutations]\n",
        "  auc_max = 0\n",
        "  auc_list = []\n",
        "  GMSE_smallest = 1\n",
        "  GMSE_list = []\n",
        "  for permute_idx in idx_list:\n",
        "    predict_w_flatten = predict_w[:, permute_idx].view(1,-1)\n",
        "    auc = roc_auc_score(adj_vec[0].long().numpy(), predict_w_flatten.to('cpu')[0].detach())\n",
        "    auc_list.append(auc)\n",
        "    GMSE_error = torch.mean(torch.square(predict_w[:, permute_idx].view(1,-1).to('cpu')-adj_vec.to('cpu')))\n",
        "    GMSE_list.append(GMSE_error)\n",
        "  return np.max(auc_list), auc_list, torch.min(GMSE_error), GMSE_list\n",
        "  "
      ],
      "metadata": {
        "id": "UX-RcOb5PNnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = 'cpu'\n",
        "def train(data, device):\n",
        "  \n",
        "  node_shape = {node_type: data[node_type].x.shape[-1] for node_type in data.node_types}\n",
        "  edge_shape = [data[edge_type].x.shape[-1] for edge_type in data.edge_types]\n",
        "  \n",
        "  w_l = int(data.num_nodes*(data.num_nodes-1)*len(data.edge_types)/2)\n",
        "  D_ori = coo_to_sparseTensor(get_degree_operator(data.num_nodes)).to(device)\n",
        "  eye = torch.eye(int(data.num_nodes*(data.num_nodes-1)/2))\n",
        "  shift_sum = eye.repeat_interleave(len(data.edge_types), dim=1)\n",
        "  D = D_ori @ shift_sum.to(device)\n",
        "  nt_ran = data.node_types[0]\n",
        "  sql_dim = data[nt_ran].x.shape[-1]\n",
        "\n",
        "  model = Model_simplified(edge_shape, w_l, D, out_channels=sql_dim)\n",
        "\n",
        "  mask = torch.triu(torch.ones(data.num_nodes, data.num_nodes), diagonal=1).bool()\n",
        "\n",
        "  \n",
        "  node_out = {node_type:data[node_type].x for node_type in data.node_types}\n",
        "  data = data.to(device)\n",
        "  model = model.to(device)\n",
        "  r_emb = model.hetero_linear(data)\n",
        "  n_emb, adj_tsr = batch_to_adjtensor(batch, node_out)\n",
        "  # indices = torch.where(adj_tsr.sum(dim=-1) == 1)\n",
        "\n",
        "  adj_vec = torch.Tensor(adj_tsr)[mask].view(1, -1)\n",
        "\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
        "\n",
        "  for epoch in range(1, 2001):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0\n",
        "    w, z, smooth_vector = model(data, device)\n",
        "    loss = objective(w=w.to(device), D=D.to(device), z=z.to(device))\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    clip_grad_norm_(model.parameters(), 20)\n",
        "    optimizer.step()\n",
        "\n",
        "  \n",
        "    auc, auc_list, GMSE, GMSE_list = permute_auc(z, len(data.edge_types), adj_vec)\n",
        "    print('loss: {}, epoch: {}, auc: {}, GMSE: {}'.format(loss, epoch, auc, GMSE))\n",
        "\n",
        "  return model,w,z, adj_vec, adj_tsr\n",
        "\n",
        "\n",
        "model,w,z, adj_vec, adj_tsr = train(batch, device)"
      ],
      "metadata": {
        "id": "wt4xo1ekBIuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def w_permute(adj_vec, predict_w, rel_num = len(batch.edge_types)):\n",
        "  predict_w = predict_w.reshape(-1, rel_num)\n",
        "  indices = torch.where(adj_vec==1)\n",
        "  permutations = list(itertools.permutations(range(rel_num)))\n",
        "  # convert to a list of PyTorch tensors\n",
        "  idx_list = [torch.tensor(p) for p in permutations]\n",
        "  auc_max = 0\n",
        "  for permute_idx in idx_list:\n",
        "    \n",
        "    predict_w_flatten = predict_w[:, permute_idx].view(1,-1)\n",
        "    auc = roc_auc_score(adj_vec[0].long().numpy(), F.relu(predict_w_flatten).to('cpu')[0].detach())\n",
        "    \n",
        "    if auc>auc_max:\n",
        "      auc_max = auc\n",
        "      w_max = F.relu(predict_w_flatten-torch.mean(predict_w_flatten))[indices]\n",
        "      w_best = predict_w_flatten\n",
        "      best_permute_idx = permute_idx\n",
        "\n",
        "    # print(F.relu(predict_w_flatten))\n",
        "    # print(F.relu(predict_w_flatten-torch.mean(predict_w_flatten))[indices])\n",
        "    print(w_max, auc_max)\n",
        "  return w_max, w_best\n",
        "w_max, w_best = w_permute(adj_vec, z)"
      ],
      "metadata": {
        "id": "EIaOsLGpwrk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_vec[0, 400:600]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eJEjQQAprTO",
        "outputId": "cad1cbb5-4266-4d45-ff0e-85878a0a5ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_best[0, 400:600]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPbnaosLwa0b",
        "outputId": "025dc508-0bc0-4fcf-f0db-2755ed127e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8815e-03, 1.8979e-02,\n",
              "        1.5725e-02, 1.7558e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        1.7773e-01, 2.0637e-01, 1.6258e-01, 1.7320e-01, 1.2471e-02, 2.6492e-02,\n",
              "        1.9928e-02, 1.9650e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3366e-02, 2.3183e-02,\n",
              "        1.6744e-02, 1.8497e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        6.5925e-02, 1.1939e-01, 1.0299e-01, 1.1833e-01, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 2.2767e-01, 2.1916e-01, 2.1679e-01, 2.5298e-01,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6017e-02, 1.5343e-02,\n",
              "        1.5156e-02, 1.8064e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        1.3525e-01, 1.2991e-01, 1.2842e-01, 1.5131e-01, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 1.9717e-02, 2.0051e-04, 7.1418e-04, 2.0643e-02,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5A_1jP9rmui"
      },
      "source": [
        "## Link Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k2yyvqZBGAN"
      },
      "outputs": [],
      "source": [
        "from numpy.random.mtrand import noncentral_chisquare\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.loader import HGTLoader\n",
        "\n",
        "def data_preprocessing(data):\n",
        "  # node type processing\n",
        "  # for node_type in data.node_types:\n",
        "  #   if data[node_type].x is None:\n",
        "  data['conference'].x = torch.eye(data['conference'].num_nodes)\n",
        "\n",
        "  # edge type processing\n",
        "  edge_onehot = torch.eye(len(data.edge_types))\n",
        "  i=0\n",
        "  for edge_type in data.edge_types:\n",
        "    data[edge_type].x = edge_onehot[i].reshape(1,-1)\n",
        "    i+=1\n",
        "  return data\n",
        "\n",
        "def data_spliting(data):\n",
        "  transform = RandomLinkSplit(num_val=0.3, num_test=0.2, \n",
        "                            is_undirected=True,\n",
        "                            neg_sampling_ratio=1.0,\n",
        "                            add_negative_train_samples=True,\n",
        "                            edge_types=data.edge_types)\n",
        "  train_test_split = transform(data)\n",
        "  data_list = []\n",
        "  for b_data in train_test_split:\n",
        "    b_data.generate_ids()\n",
        "    \n",
        "    for edge_type in b_data.edge_types:\n",
        "      b_data[edge_type].e_id = torch.arange(len(b_data[edge_type].edge_label))\n",
        "      b_data[edge_type].edge_index = b_data[edge_type].edge_label_index\n",
        "      del b_data[edge_type].edge_label_index\n",
        "    data_list.append(b_data)\n",
        "  \n",
        "  return data_list\n",
        "\n",
        "def data_batching(data, batch_size, input_nodes):\n",
        "    loader = HGTLoader(\n",
        "    data,\n",
        "    # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "    num_samples={key: [8] * 4 for key in data.node_types},\n",
        "    # Use a batch size of 128 for sampling training nodes of type paper\n",
        "    batch_size = batch_size,\n",
        "    input_nodes=input_nodes,\n",
        "    )\n",
        "    return loader\n",
        "\n",
        "\n",
        "data = data_preprocessing(data)\n",
        "train_data, val_data, test_data = data_spliting(data)\n",
        "train_loader = data_batching(train_data, 8, ('paper'))\n",
        "val_loader = data_batching(val_data, 8, ('paper'))\n",
        "test_loader = data_batching(test_data, 4, ('paper'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7_RdFuTdhtB",
        "outputId": "95585fa6-0ccc-40dd-e3b7-177989cefee2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mauthor\u001b[0m={\n",
              "    x=[29, 334],\n",
              "    y=[29],\n",
              "    train_mask=[29],\n",
              "    val_mask=[29],\n",
              "    test_mask=[29],\n",
              "    n_id=[29]\n",
              "  },\n",
              "  \u001b[1mpaper\u001b[0m={\n",
              "    x=[32, 4231],\n",
              "    n_id=[32],\n",
              "    input_id=[8],\n",
              "    batch_size=8\n",
              "  },\n",
              "  \u001b[1mterm\u001b[0m={\n",
              "    x=[32, 50],\n",
              "    n_id=[32]\n",
              "  },\n",
              "  \u001b[1mconference\u001b[0m={\n",
              "    num_nodes=10,\n",
              "    x=[10, 20],\n",
              "    n_id=[10]\n",
              "  },\n",
              "  \u001b[1m(author, to, paper)\u001b[0m={\n",
              "    edge_index=[2, 31],\n",
              "    x=[1, 6],\n",
              "    edge_label=[31],\n",
              "    e_id=[31]\n",
              "  },\n",
              "  \u001b[1m(paper, to, author)\u001b[0m={\n",
              "    edge_index=[2, 19],\n",
              "    x=[1, 6],\n",
              "    edge_label=[19],\n",
              "    e_id=[19]\n",
              "  },\n",
              "  \u001b[1m(paper, to, term)\u001b[0m={\n",
              "    edge_index=[2, 16],\n",
              "    x=[1, 6],\n",
              "    edge_label=[16],\n",
              "    e_id=[16]\n",
              "  },\n",
              "  \u001b[1m(paper, to, conference)\u001b[0m={\n",
              "    edge_index=[2, 0],\n",
              "    x=[1, 6],\n",
              "    edge_label=[0],\n",
              "    e_id=[0]\n",
              "  },\n",
              "  \u001b[1m(term, to, paper)\u001b[0m={\n",
              "    edge_index=[2, 34],\n",
              "    x=[1, 6],\n",
              "    edge_label=[34],\n",
              "    e_id=[34]\n",
              "  },\n",
              "  \u001b[1m(conference, to, paper)\u001b[0m={\n",
              "    edge_index=[2, 21],\n",
              "    x=[1, 6],\n",
              "    edge_label=[21],\n",
              "    e_id=[21]\n",
              "  }\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "530j0V6WrgIu",
        "outputId": "7dc07820-503a-4830-d9a8-e640b2d797ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([19646])\n",
            "torch.Size([19646])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([85810])\n",
            "torch.Size([14330])\n",
            "torch.Size([2, 19646])\n",
            "torch.Size([2, 19646])\n",
            "torch.Size([2, 85810])\n",
            "torch.Size([2, 14330])\n",
            "torch.Size([2, 85810])\n",
            "torch.Size([2, 14330])\n"
          ]
        }
      ],
      "source": [
        "for edge_type in train_data.edge_types:\n",
        "  print(train_data[edge_type].edge_label.shape)\n",
        "for edge_type in train_data.edge_types:\n",
        "  print(train_data[edge_type].edge_index.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv6rioeGWUtD"
      },
      "outputs": [],
      "source": [
        "def get_complete_subgraph(subgraph, graph):\n",
        "  for edge_type in subgraph.edge_types:\n",
        "    # assuming edge_index is your edge index tensor with shape [2, E]\n",
        "    # and sampled_nodes is your tensor of node indices to include in the subgraph\n",
        "\n",
        "    # get the start and end nodes for each edge\n",
        "    s_ntype, _, t_ntype = edge_type\n",
        "    s_mapping = {old_id: new_id for new_id, old_id in enumerate(subgraph[s_ntype].n_id.tolist())}\n",
        "    t_mapping = {old_id: new_id for new_id, old_id in enumerate(subgraph[t_ntype].n_id.tolist())}\n",
        "\n",
        "    s_nodes, t_nodes = graph[edge_type].edge_index\n",
        "\n",
        "    # find the indices of the edges where both the start node and end node are in sampled_nodes\n",
        "    mask = (torch.isin(s_nodes, subgraph[s_ntype].n_id) & torch.isin(t_nodes, subgraph[t_ntype].n_id))\n",
        "    print(mask.shape)\n",
        "\n",
        "    # subset the edge index tensor to include only these edges\n",
        "    subgraph_edge_index = graph[edge_type].edge_index[:, mask]\n",
        "    s_idx, t_idx = subgraph_edge_index\n",
        "    new_s_nodes = torch.tensor([s_mapping[node.item()] for node in s_idx])\n",
        "    new_e_nodes = torch.tensor([t_mapping[node.item()] for node in t_idx])\n",
        "\n",
        "    # create a new edge index tensor with the re-indexed node IDs\n",
        "    subgraph[edge_type].edge_index = torch.stack([new_s_nodes, new_e_nodes])\n",
        "    subgraph[edge_type].edge_label = graph[edge_type].edge_label[mask]\n",
        "    subgraph[edge_type].e_id = graph[edge_type].e_id[mask]\n",
        "  \n",
        "  return subgraph\n",
        "\n",
        "for batch in test_loader:\n",
        "  batch = get_complete_subgraph(batch, train_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ummtLl6jouRC"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import HeteroConv, Linear, SAGEConv, HeteroDictLinear\n",
        "\n",
        "class NodeLinProj(torch.nn.Module):\n",
        "    def __init__(self, node_shape, out_channels):\n",
        "        super().__init__()\n",
        "        self.NodeLinear = HeteroDictLinear(in_channels=node_shape,out_channels=out_channels)\n",
        "        self.EdgeLinear = Linear(in_features=edge_shape, out_features=out_channels)\n",
        "        \n",
        "\n",
        "    def forward(self, batch):\n",
        "      node_attrs = {node_type: batch[node_type].x for node_type in batch.node_types}\n",
        "      edge_attrs = {'_'.join(edge_type): batch[edge_type].x for edge_type in batch.edge_types}\n",
        "\n",
        "      node_out = self.NodeLinear(node_attrs)\n",
        "      edge_out = {'_'.join(edge_type): self.EdgeLinear(batch[edge_type].x) for edge_type in batch.edge_types}(edge_attrs)\n",
        "      \n",
        "      for node_type in batch.node_types:\n",
        "        node_out[node_type] = node_out[node_type]/(node_out[node_type].norm(dim=1)[:, None])\n",
        "      for edge_type in edge_attrs:\n",
        "        edge_out[edge_type] = edge_out[edge_type]/(edge_out[edge_type].norm(dim=1)[:, None]) \n",
        "\n",
        "      return (node_out, edge_out)\n",
        "\n",
        "class EdgeLinProj(torch.nn.Module):\n",
        "  def __init__(self, edge_shape, out_channels):\n",
        "    self.EdgeLinear = Linear(in_features=edge_shape, out_features=out_channels)\n",
        "  \n",
        "  def forward(self, batch):\n",
        "    edge_attrs = {'_'.join(edge_type): batch[edge_type].x for edge_type in batch.edge_types}\n",
        "\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, s_node_x, t_node_x ,r_emb, edge_index):\n",
        "        sigma = 1e-3\n",
        "        s_idx, t_idx = edge_index[0], edge_index[1]\n",
        "        s_nemb, t_nemb = s_node_x[s_idx], t_node_x[t_idx]\n",
        "        diff_vector = r_emb * (s_nemb - t_nemb)\n",
        "        smooth = torch.exp(- 1/sigma * torch.norm(diff_vector, dim=-1)**2)\n",
        "        # print(diff_vector.shape, torch.norm(diff_vector, dim=-1).shape)\n",
        "        # print(torch.norm(diff_vector, dim=-1)**2)\n",
        "        # smooth = torch.exp(-1/sigma* (torch.norm(diff_vector, dim=-1)))\n",
        "        \n",
        "        return smooth\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, node_shape, edge_shape, out_channels=100):\n",
        "        super().__init__()\n",
        "        self.hetero_linear = LinearProj(node_shape, edge_shape, out_channels=100)\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        node_out, edge_out = self.hetero_linear(batch)\n",
        "        pred_list = []\n",
        "        for edge_type in batch.edge_types:\n",
        "          s_ntype, _, t_ntype = edge_type\n",
        "          s_emb, t_emb = node_out[s_ntype], node_out[t_ntype]\n",
        "          r_emb = edge_out['_'.join(edge_type)]\n",
        "          # print(self.classifier(s_emb, t_emb, r_emb, batch[edge_type].edge_index).shape)\n",
        "          # print('gt: {}'.format(batch[edge_type].edge_label))\n",
        "          # print('pred:{}'.format(self.classifier(s_emb, t_emb, r_emb, batch[edge_type].edge_index)))\n",
        "          pred_list += [self.classifier(s_emb, t_emb, r_emb, batch[edge_type].edge_index)]\n",
        "        pred = torch.cat(pred_list)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qFg0FHhpL8X"
      },
      "outputs": [],
      "source": [
        "node_shape = {node_type: train_data[node_type].x.shape[-1] for node_type in train_data.node_types}\n",
        "# edge_shape = {'_'.join(edge_type): train_data[edge_type].x.shape[-1] for edge_type in train_data.edge_types}\n",
        "edge_shape = train_data[edge_type].x.shape[-1]\n",
        "\n",
        "model = Model(node_shape, edge_shape, out_channels=500)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZRbI6I48SDi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "def auc_test(mode, loader, device):\n",
        "  preds = []\n",
        "  ground_truths = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  for test_batch in tqdm.tqdm(loader):\n",
        "      test_batch = test_batch.to(device)\n",
        "      preds.append(model(test_batch))\n",
        "      with torch.no_grad():\n",
        "        for edge_type in test_batch.edge_types:\n",
        "          ground_truths.append(test_batch[edge_type].edge_label)\n",
        "  pred = torch.cat(preds, dim=0).cpu().detach().numpy()\n",
        "  pred = pred/np.max(pred)\n",
        "  ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "  auc = roc_auc_score(ground_truth, pred)\n",
        "  f1 = f1_score(ground_truth, (pred>0.5))\n",
        "  return auc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek5vyZo9mqNI",
        "outputId": "705d1f3a-8655-42de-865d-44d2dd90abd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: 'cuda:0'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:32<00:00, 55.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 0.2719, learning_rate: 0.0096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 60.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 002, Loss: 0.2668, learning_rate: 0.0085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 59.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 003, Loss: 0.2626, learning_rate: 0.0069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:30<00:00, 58.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 004, Loss: 0.2570, learning_rate: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 61.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 005, Loss: 0.2516, learning_rate: 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 61.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 006, Loss: 0.2465, learning_rate: 0.0015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 61.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 007, Loss: 0.2434, learning_rate: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:30<00:00, 59.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 008, Loss: 0.2412, learning_rate: 0.0100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 61.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 009, Loss: 0.2563, learning_rate: 0.0096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 60.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.2556, learning_rate: 0.0085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:15<00:00, 117.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.8055, f1 score: 0.7232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:31<00:00, 56.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 011, Loss: 0.2534, learning_rate: 0.0069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:30<00:00, 59.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 012, Loss: 0.2491, learning_rate: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 60.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 013, Loss: 0.2442, learning_rate: 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 60.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 014, Loss: 0.2422, learning_rate: 0.0015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:29<00:00, 60.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 015, Loss: 0.2392, learning_rate: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:30<00:00, 57.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 016, Loss: 0.2374, learning_rate: 0.0100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:31<00:00, 57.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 017, Loss: 0.2501, learning_rate: 0.0096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:30<00:00, 58.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 018, Loss: 0.2491, learning_rate: 0.0085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:31<00:00, 56.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 019, Loss: 0.2480, learning_rate: 0.0069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:30<00:00, 58.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 020, Loss: 0.2445, learning_rate: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:15<00:00, 115.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.7990, f1 score: 0.7138\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import HGTLoader\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: '{device}'\")\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, \n",
        "                                        T_0 = 8,# Number of iterations for the first restart\n",
        "                                        T_mult = 1, # A factor increases TiTi after a restart\n",
        "                                        eta_min = 1e-5) # Minimum learning rate\n",
        "# Adam best learning rate: 1e-2, sigma= 1e-3, weight decay = 0\n",
        "# SGD best learning rate: 1e-3, decay = 0.1, no sigma\n",
        "\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    total_loss = total_examples = 0\n",
        "    for batch in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch)\n",
        "        \n",
        "        gt_list = []\n",
        "        for edge_type in batch.edge_types:\n",
        "          gt_list.append(batch[edge_type].edge_label)\n",
        "        ground_truth = torch.cat(gt_list)\n",
        "        loss = F.binary_cross_entropy(pred, ground_truth, reduction='mean')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}, learning_rate: {get_lr(optimizer):.4f}\")\n",
        "    if epoch % 10 == 0:\n",
        "      auc_result, f1_sco = auc_test(model,val_loader, device)\n",
        "      print(f\"AUC: {auc_result:.4f}, f1 score: {f1_sco:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsNFzMM4D5PF",
        "outputId": "6e5ce76e-bbb9-47ed-d046-e6f835fbc218"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1791/1791 [00:17<00:00, 100.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7989262263970094 0.7137463638051619\n"
          ]
        }
      ],
      "source": [
        "auc_result, f1 = auc_test(model,val_loader, device)\n",
        "print(auc_result, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpHhum2n7jNi"
      },
      "outputs": [],
      "source": [
        "path = 'gdrive/MyDrive/heterograph_learning/linear_model.pth'\n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX-M3NMwYZow",
        "outputId": "c39f6cf0-f062-462b-c88b-1d849974c4b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loading model\n",
        "path = 'gdrive/MyDrive/heterograph_learning/linear_model.pth'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl18YKLh7rmr"
      },
      "outputs": [],
      "source": [
        "def batch_to_adjtensor(batch, node_out, edge_out):\n",
        "  # create an empty dictionary to store the indices\n",
        "  indices_dict = {}\n",
        "  # list to hold the tensors\n",
        "  tensor_list = []\n",
        "  start_index = 0\n",
        "  for node_type in batch.node_types:\n",
        "    node_emb = node_out[node_type]\n",
        "    end_index = start_index + node_emb.size(0)\n",
        "    indices_dict[node_type] = (start_index, end_index)  # store the start and end index for this type\n",
        "    tensor_list.append(node_emb)\n",
        "    start_index = end_index  # update the start index for the next type\n",
        "    # concatenate the tensors\n",
        "\n",
        "  node_tensor = torch.cat(tensor_list, dim=0)\n",
        "\n",
        "  adj_matrices = []\n",
        "  # print('start transforming')\n",
        "  for edge_type in batch.edge_types:\n",
        "    # print(edge_type, batch[edge_type].edge_index)\n",
        "    \n",
        "    if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "        continue\n",
        "    # Initialize the adjacency matrix\n",
        "    N = node_tensor.size(0)\n",
        "    adj_matrix = torch.zeros(N, N)\n",
        "    # Populate the adjacency matrix\n",
        "    s_ntype, _, e_ntype = edge_type\n",
        "    start_indices = indices_dict[s_ntype]\n",
        "    end_indices = indices_dict[e_ntype]\n",
        "\n",
        "    # map the indices in edge_index to their corresponding indices in the big tensor\n",
        "    edge_idx = batch[edge_type].edge_index\n",
        "    edge_label = batch[edge_type].edge_label\n",
        "    edge_idx[0] += start_indices[0]  # add the start index of the start node type to the start nodes in edge_index\n",
        "    edge_idx[1] += end_indices[0]  # add the start index of the end node type to the end nodes in edge_index\n",
        "    \n",
        "    for i in range(edge_idx.shape[1]):\n",
        "      if edge_label[i] == 1:\n",
        "        one_edge = edge_idx[:, i]\n",
        "        adj_matrix[one_edge[0], one_edge[1]] = 1\n",
        "    adj_matrices.append(adj_matrix)\n",
        "\n",
        "  adj_matrices = torch.stack(adj_matrices, dim=-1)\n",
        "  return node_tensor, adj_matrices\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "jy9Uo58f7zSQ",
        "outputId": "a25795a5-64c0-4c83-d955-dabd5c3a92df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3582 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9158dd1eef86>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0madj_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mestimate_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpds_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mGMSE_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_tensor\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0madj_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pds_opt' is not defined"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "step = 0\n",
        "GMSE_error = 0\n",
        "total_samples = 0\n",
        "link_errors = []\n",
        "sigma = 1e-3\n",
        "\n",
        "for batch in tqdm.tqdm(test_loader):\n",
        "  batch.to(device)\n",
        "  model.to(device)\n",
        "  step+=1\n",
        "  node_out, edge_out = model.hetero_linear(batch)\n",
        "  n_emb, adj_tensor = batch_to_adjtensor(batch, node_out, edge_out)\n",
        "  # r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[0] != 0]\n",
        "  r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[-1] != 0]\n",
        "  \n",
        "  r_emb = torch.cat(r_emb, dim=0)\n",
        "  diff_tensor = (n_emb[:, None, None, :] - n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "  num_nodes,_,num_relations ,K = diff_tensor.shape\n",
        "  smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "  est_tensor = torch.exp(- 1/sigma * smooth_tensor)\n",
        "  \n",
        "  adj_tsr = adj_tensor.to(device)\n",
        "  \n",
        "  GMSE_error += torch.sum(torch.square(est_tensor-adj_tensor))\n",
        "\n",
        "  num_samples = est_tensor.shape[0] * est_tensor.shape[1]*est_tensor.shape[0]\n",
        "  total_samples += num_samples\n",
        "\n",
        "  edge_indices = torch.where(adj_tensor == 1)\n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = est_tensor[edge_indices]\n",
        "  link_error = torch.mean(torch.square(adj_tensor[edge_indices] - out_edges))\n",
        "  link_errors.append(torch.sqrt(link_error))\n",
        "\n",
        "print(GMSE_error/total_samples)\n",
        "print(torch.mean(torch.tensor(link_errors)))\n",
        "\n",
        "# Find the indices of the 1 elements in A\n",
        "\n",
        "'''\n",
        "  # combinations = itertools.combinations_with_replacement(batch.node_types, 2)\n",
        "  # possible_edge =  [(s_type,'to',t_type) for s_type,t_type in combinations]\n",
        "  true_edge_types = batch.edge_types\n",
        "  for edge_type in true_edge_types:\n",
        "    if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "      continue\n",
        "    if edge_type in true_edge_types:\n",
        "      print(batch[edge_type].edge_index)\n",
        "    s_ntype, _ , t_ntype = edge_type\n",
        "    # source node embedding and target node embedding\n",
        "    s_nemb, t_nemb = node_out[s_ntype], node_out[t_ntype]\n",
        "    \n",
        "    n_emb = torch.cat([s_nemb, t_nemb], dim=0)\n",
        "    r_emb = edge_out['_'.join(edge_type)]\n",
        "    out_product = n_emb[:, None, :] * n_emb[None,: , :] * r_emb[0][ None, None, :]\n",
        "    N,_,K = out_product.shape\n",
        "    out_adj = torch.sum(out_product, dim=2)\n",
        "    print(out_adj.shape)\n",
        "    # Use torch.topk to get the indices of K largest entrie\n",
        "    values, indices = torch.topk(out_adj.view(-1), K)\n",
        "    row_indices = indices // N\n",
        "    col_indices = indices % N\n",
        "\n",
        "    indices = torch.stack([row_indices, col_indices], dim=0)\n",
        "    # Convert tensors to sets\n",
        "    true_idx = batch[edge_type].edge_index\n",
        "    true_idx[1] += s_nemb.shape[0]\n",
        "    set1 = set(map(tuple, true_idx.t().tolist()))\n",
        "    set2 = set(map(tuple, indices.t().tolist()))\n",
        "    # Find the difference between sets\n",
        "    print(set1,set2)\n",
        "    acc = len(set1 - set2)/len(set1)\n",
        "    print(acc)\n",
        "'''\n",
        "    \n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD0Trli-ZW0p",
        "outputId": "e310ce79-6c17-4558-fc90-d19063f121bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5301)\n"
          ]
        }
      ],
      "source": [
        "print(GMSE_error/total_samples)\n",
        "print(torch.mean(torch.tensor(link_errors)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIodzxzGQRV3"
      },
      "source": [
        "## Estimate adjacency tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n7ldolBQfrN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import scipy.sparse as sparse\n",
        "\n",
        "def coo_to_sparseTensor(coo):\n",
        "    values = coo.data\n",
        "    indices = np.vstack((coo.row, coo.col))\n",
        "\n",
        "    i = torch.LongTensor(indices)\n",
        "    v = torch.FloatTensor(values)\n",
        "    shape = coo.shape\n",
        "\n",
        "    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()\n",
        "\n",
        "def get_degree_operator(m):\n",
        "  \n",
        "    ncols =int(m*(m - 1)/2)\n",
        "\n",
        "    I = np.zeros(ncols)\n",
        "    J = np.zeros(ncols)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        I[k:(k + m - i)] = np.arange(i, m)\n",
        "        k = k + (m - i)\n",
        "\n",
        "    k = 0\n",
        "    for i in np.arange(1, m):\n",
        "        J[k: (k + m - i)] = i - 1\n",
        "        k = k + m - i\n",
        "\n",
        "    Row = np.tile(np.arange(0, ncols), 2)\n",
        "    Col = np.append(I, J)\n",
        "    Data = np.ones(Col.size)\n",
        "    St = sparse.coo_matrix((Data, (Row, Col)), shape=(ncols, m))\n",
        "    return St.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjO1shkKN5iU"
      },
      "outputs": [],
      "source": [
        "class ADMM():\n",
        "    def __init__(self, l2_penalty, log_penalty, step_size=1e-02, relaxation_factor = 1.8):\n",
        "        self.alpha = log_penalty  # the penalty before log barrier\n",
        "        self.beta = l2_penalty  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "        self.relax = relaxation_factor\n",
        "\n",
        "    def initialisation(self, l, m, batch_size=1):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        up = y ** 2 + 4 * gn * alpha\n",
        "        up = torch.clamp(up, 1e-08)\n",
        "        return (y - torch.sqrt(up)) / 2\n",
        "\n",
        "    def objective(self, w, D, z):\n",
        "        f1 = self.beta * torch.norm(w, 2) ** 2\n",
        "        f2 = w.T @ z\n",
        "        f3 = - self.alpha * torch.sum(torch.log(D @ w))\n",
        "\n",
        "        if all(np.round(w, 4) >= 0):\n",
        "            return f1 + f2 + f3\n",
        "        else:\n",
        "            return 10**3\n",
        "\n",
        "    def solve(self, smooth, max_iter=1000, verbose=True):\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # D * shift_sum if the new operator\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_ite, l))\n",
        "        # print(w_list.shape)\n",
        "\n",
        "        lambda_ = self.relax\n",
        "\n",
        "        for i in range(max_iter):\n",
        "\n",
        "            y1 = w - self.gn * (2 * self.beta * w + torch.matmul(v, D))\n",
        "            p1 = torch.max(zero_vec, y1 - 2 * self.gn * z)\n",
        "\n",
        "            y2 = v + self.gn * torch.matmul(2 * p1 - w, D.T)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            w = w + lambda_ * (p1 - w)\n",
        "            v = v + lambda_ * (p2 - v)\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n",
        "\n",
        "#%%\n",
        "\n",
        "class PDS():\n",
        "    def __init__(self, l2_psi, log_psi, step_size):\n",
        "        self.alpha = log_psi  # the penalty before log barrier\n",
        "        self.beta = l2_psi  # the penalty before l2 term\n",
        "        self.gn = step_size\n",
        "\n",
        "    def prox_log_barrier(self, y, gn, alpha):\n",
        "        return (y - torch.sqrt(y ** 2 + 4 * gn * alpha)) / 2\n",
        "\n",
        "    def initialisation(self, l, m, batch_size):\n",
        "        w = torch.zeros((batch_size, l)).float().to(device)\n",
        "        v = torch.zeros((batch_size, m)).float().to(device)\n",
        "        return w, v\n",
        "\n",
        "    def solve(self, smooth, max_iter = 500):\n",
        "        # z \\in 1* m* m * r\n",
        "        batch_size, m, _, r = smooth.shape\n",
        "        mask = torch.triu(torch.ones(m, m), diagonal=1).bool()\n",
        "        z = smooth[:, mask].view(batch_size, -1)\n",
        "        l = int(m*(m-1)*r/2)\n",
        "\n",
        "        D_ori = coo_to_sparseTensor(get_degree_operator(m)).to(device)\n",
        "        eye = torch.eye(int(m*(m-1)/2))\n",
        "        shift_sum = eye.repeat_interleave(r, dim=1)\n",
        "        D = D_ori @ shift_sum.to(device)\n",
        "\n",
        "        # initialise:\n",
        "        w, v = self.initialisation(l, m, batch_size)\n",
        "        zero_vec = torch.zeros((batch_size, l)).to(device)\n",
        "        # w_list = torch.empty(size=(batch_size, max_iter, l)).to(device)\n",
        "        for i in range(max_iter):\n",
        "            # print(z.shape)\n",
        "            y1 = w - self.gn * (2 * self.beta * w + 2 * z + torch.matmul(v, D))\n",
        "            y2 = v + self.gn * torch.matmul(w, D.T)\n",
        "\n",
        "            p1 = torch.max(zero_vec, y1)\n",
        "            p2 = self.prox_log_barrier(y2, self.gn, self.alpha)\n",
        "\n",
        "            q1 = p1 - self.gn * (2 * self.beta * p1 + 2 * z + torch.matmul(p2, D))\n",
        "            q2 = p2 + self.gn * torch.matmul(p1, D.T)\n",
        "\n",
        "            w = w - y1 + q1\n",
        "            v = v - y2 + q2\n",
        "\n",
        "            # w_list[:, i, :] = w\n",
        "\n",
        "        return w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "iZJ7R5XIH6NN",
        "outputId": "991e63d5-2f16-4ce6-acf7-bb1401bc36ee"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-20ca17942a00>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mestimate_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_vtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignals_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpds_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'signal_vtx' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def estimate_w(signal_vtx, signals_edge, adj_tensor, optimizer):\n",
        "  diff_tensor = (signal_vtx[:, None, None, :] - signal_vtx[None,: , None, :]) * signals_edge[ None, None, :, :]\n",
        "  diff_tensor = torch.Tensor(diff_tensor)\n",
        "  num_nodes,_,num_relations ,K = diff_tensor.shape\n",
        "  smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "  # est_tensor = torch.exp(- 1/sigma * smooth_tensor)\n",
        "  adj_tensor = torch.Tensor(adj_tensor).unsqueeze(0).to(device)\n",
        "  mask = torch.triu(torch.ones(num_nodes, num_nodes), diagonal=1).bool()\n",
        "  adj_vec = adj_tensor[:, mask].view(1, -1)\n",
        "  print(smooth_tensor.shape)\n",
        "  w = optimizer.solve(smooth_tensor.unsqueeze(0).to(device), max_iter = 500)\n",
        "  # Normalization\n",
        "  w = w/torch.max(w)\n",
        "  GMSE_error = torch.sum(torch.square(w-adj_vec)/(w+1e-12))\n",
        "\n",
        "  num_samples = w.shape[0] * w.shape[1]*w.shape[0]\n",
        "  edge_indices = torch.where(adj_vec == 1)\n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = w[edge_indices]\n",
        "  print(adj_vec[edge_indices])\n",
        "  print(w)\n",
        "  print(out_edges)\n",
        "  link_error = torch.mean(torch.square(adj_vec[edge_indices] - out_edges))\n",
        "  print(GMSE_error/num_samples)\n",
        "  print(torch.sqrt(link_error))\n",
        "  auc = roc_auc_score(adj_vec.to('cpu').detach().numpy()[0], w.to('cpu').detach().numpy()[0])\n",
        "  f1 = f1_score(adj_vec.to('cpu')[0], (w>0.8).to('cpu')[0])\n",
        "  print(auc, f1)\n",
        "  # auc = roc_auc_score(adj_vec[edge_indices].to('cpu').detach().numpy(), out_edge\n",
        "\n",
        "\n",
        "estimate_w(signal_vtx, signals_edge, adj_tsr, pds_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73Eowy8-Oz7r",
        "outputId": "93191e7a-e5f8-46df-da28-55798d836df9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3582 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([71, 71, 5])\n",
            "torch.Size([71, 71, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/3582 [00:01<1:44:25,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.8955, 0.8936, 0.8577,  ..., 0.9024, 0.9070, 0.8666]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8718, 0.8692, 0.8106, 0.9026, 0.8503, 0.8872, 0.8704, 0.8463, 0.9093,\n",
            "        0.8792], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1332, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8211115585984696 0.0035868005738880914\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0587, 0.0586, 0.0562,  ..., 0.0591, 0.0594, 0.0568]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9430)\n",
            "torch.Size([68, 68, 6])\n",
            "torch.Size([68, 68, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 2/3582 [00:02<1:08:01,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9288, 0.9237, 0.6749,  ..., 0.9217, 0.9272, 0.9238]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9171, 0.9174, 0.8865, 0.8997, 0.8952, 0.9023, 0.9095, 0.9094, 0.9027,\n",
            "        0.9120, 0.9074], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7720, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0950, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8469050170741612 0.0029617662897145933\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0548, 0.0545, 0.0398,  ..., 0.0544, 0.0547, 0.0545]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9448)\n",
            "torch.Size([65, 65, 5])\n",
            "torch.Size([65, 65, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 3/3582 [00:03<54:06,  1.10it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9229, 0.9226, 0.6851,  ..., 0.9294, 0.9307, 0.8882]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8925, 0.8982, 0.8612, 0.8273, 0.8993, 0.9073, 0.8944, 0.8951, 0.9057,\n",
            "        0.9231, 0.8961, 0.8999], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1109, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8353669297907842 0.004595060310166571\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0614, 0.0614, 0.0456,  ..., 0.0618, 0.0619, 0.0591]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9434)\n",
            "torch.Size([63, 63, 6])\n",
            "torch.Size([63, 63, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 4/3582 [00:03<48:07,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9685, 0.9689, 0.4605,  ..., 0.9250, 0.9247, 0.9166]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9505, 0.8891, 0.9100, 0.8536, 0.9293, 0.8948, 0.8987, 0.9036, 0.8954,\n",
            "        0.8951, 0.8940, 0.9042, 0.8985, 0.8954, 0.8959, 0.8927, 0.8909],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1023, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8311255448252287 0.005299251870324188\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0596, 0.0596, 0.0283,  ..., 0.0569, 0.0569, 0.0564]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9437)\n",
            "torch.Size([75, 75, 6])\n",
            "torch.Size([75, 75, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 5/3582 [00:04<47:52,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.8392, 0.8879, 0.4653,  ..., 0.9015, 0.9012, 0.8955]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8777, 0.8781, 0.8880, 0.8790, 0.8745, 0.8903, 0.8781, 0.8735, 0.8507,\n",
            "        0.8070, 0.8671, 0.8733, 0.8835, 0.8751], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1304, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8594077388108405 0.0036425133342005986\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0490, 0.0519, 0.0272,  ..., 0.0527, 0.0527, 0.0523]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9448)\n",
            "torch.Size([70, 70, 5])\n",
            "torch.Size([70, 70, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 6/3582 [00:05<49:02,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.8757, 0.8737, 0.8358,  ..., 0.8886, 0.8888, 0.8625]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8559, 0.8411, 0.8547, 0.8413, 0.8579, 0.8205, 0.8325, 0.8754, 0.8524,\n",
            "        0.8329, 0.8660, 0.8250, 0.8464, 0.8483, 0.8418, 0.8505, 0.8531, 0.8491,\n",
            "        0.8598, 0.8517, 0.8529], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1525, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8390654752028569 0.008320126782884312\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0593, 0.0592, 0.0566,  ..., 0.0602, 0.0602, 0.0584]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9444)\n",
            "torch.Size([69, 69, 6])\n",
            "torch.Size([69, 69, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 7/3582 [00:06<52:10,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9424, 0.9470, 0.8713,  ..., 0.9467, 0.9539, 0.8943]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9307, 0.9206, 0.9085, 0.9126, 0.9101, 0.9164, 0.9147, 0.9144, 0.9204,\n",
            "        0.9144, 0.9103, 0.9461, 0.9455, 0.9198, 0.9220, 0.9214, 0.9166, 0.9202,\n",
            "        0.9152, 0.9120, 0.8874, 0.9503, 0.9148], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0818, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8502470461204323 0.0056379458266944465\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0541, 0.0544, 0.0500,  ..., 0.0544, 0.0548, 0.0514]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9448)\n",
            "torch.Size([61, 61, 5])\n",
            "torch.Size([61, 61, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 8/3582 [00:07<50:43,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9782, 0.9220, 0.8974,  ..., 0.9295, 0.9335, 0.8917]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9234, 0.9015, 0.8977, 0.8982, 0.9041, 0.9020, 0.8993, 0.8892, 0.8999,\n",
            "        0.8977, 0.9052, 0.9010, 0.9032, 0.8996, 0.9031, 0.8910, 0.8968, 0.9021,\n",
            "        0.8959, 0.9001, 0.9019], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.8145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0996, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.800145011449645 0.006676204101096804\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0654, 0.0616, 0.0600,  ..., 0.0621, 0.0624, 0.0596]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9442)\n",
            "torch.Size([76, 76, 5])\n",
            "torch.Size([76, 76, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 9/3582 [00:08<56:02,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.8497, 0.8321, 0.7636,  ..., 0.8793, 0.8822, 0.8600]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8464, 0.8468, 0.8060, 0.8199, 0.8328, 0.8280, 0.8572, 0.8643, 0.8447,\n",
            "        0.8633, 0.8731, 0.8491, 0.8446], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1567, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8262382416347437 0.004779411764705882\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0557, 0.0545, 0.0500,  ..., 0.0576, 0.0578, 0.0564]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9443)\n",
            "torch.Size([63, 63, 5])\n",
            "torch.Size([63, 63, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 10/3582 [00:09<51:27,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.8992, 0.9175, 0.3415,  ..., 0.9088, 0.9102, 0.8915]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8875, 0.8885, 0.8986, 0.8849, 0.8867, 0.9024, 0.9200, 0.8876, 0.9175,\n",
            "        0.8674, 0.8872, 0.9047, 0.9029, 0.9106], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1048, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8877331262727632 0.006012454369765944\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0617, 0.0630, 0.0234,  ..., 0.0624, 0.0625, 0.0612]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9437)\n",
            "torch.Size([71, 71, 5])\n",
            "torch.Size([71, 71, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 11/3582 [00:09<48:04,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.8480, 0.8892, 0.1342,  ..., 0.8894, 0.8952, 0.8675]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8595, 0.8616, 0.8160, 0.8540, 0.8491, 0.8562, 0.8057, 0.8570, 0.8885,\n",
            "        0.8540, 0.8514, 0.8575, 0.8594, 0.8613, 0.8571, 0.8710],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1475, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8363889112740752 0.005923731951129212\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0569, 0.0596, 0.0090,  ..., 0.0596, 0.0600, 0.0582]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9436)\n",
            "torch.Size([68, 68, 6])\n",
            "torch.Size([68, 68, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 12/3582 [00:10<45:30,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9378, 0.9407, 0.7727,  ..., 0.9137, 0.9217, 0.8749]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8862, 0.9055, 0.8907, 0.9021, 0.8806, 0.8593, 0.8876, 0.8915, 0.8826,\n",
            "        0.8790, 0.8931, 0.8947, 0.8828, 0.9100, 0.9141], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1102, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.838621548377646 0.004257734885041158\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0564, 0.0565, 0.0464,  ..., 0.0549, 0.0554, 0.0526]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9438)\n",
            "torch.Size([58, 58, 5])\n",
            "torch.Size([58, 58, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 13/3582 [00:10<41:28,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9018, 0.9256, 0.3236,  ..., 0.9181, 0.9189, 0.8943]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8923, 0.8859, 0.8891, 0.8868, 0.8854, 0.8789, 0.8857, 0.8781, 0.8908,\n",
            "        0.8865, 0.8874, 0.8921, 0.8867, 0.8760], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1143, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8477240853922468 0.0064709960711809575\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0640, 0.0657, 0.0230,  ..., 0.0652, 0.0652, 0.0635]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9433)\n",
            "torch.Size([65, 65, 5])\n",
            "torch.Size([65, 65, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 14/3582 [00:11<39:41,  1.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.8697, 0.8717, 0.8150,  ..., 0.8902, 0.8904, 0.8650]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8575, 0.8200, 0.8378, 0.8503, 0.8758, 0.8545, 0.8542, 0.8470, 0.9092,\n",
            "        0.8545, 0.8497, 0.8543, 0.8556, 0.8514, 0.8870, 0.8542, 0.8476],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7310, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1447, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8310133646061717 0.007192722657076369\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0608, 0.0610, 0.0570,  ..., 0.0623, 0.0623, 0.0605]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9431)\n",
            "torch.Size([62, 62, 6])\n",
            "torch.Size([62, 62, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 15/3582 [00:12<38:26,  1.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9246, 0.9518, 0.5972,  ..., 0.9319, 0.9321, 0.9068]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9306, 0.9352, 0.8474, 0.9017, 0.9096, 0.9076, 0.8861, 0.9030, 0.8980,\n",
            "        0.9001, 0.8994, 0.8918, 0.8957, 0.8944], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1019, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8352642327668802 0.004477134633834346\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0571, 0.0587, 0.0369,  ..., 0.0575, 0.0575, 0.0560]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9432)\n",
            "torch.Size([70, 70, 6])\n",
            "torch.Size([70, 70, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 16/3582 [00:12<39:07,  1.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.8934, 0.9243, 0.1007,  ..., 0.8914, 0.8973, 0.8917]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8996, 0.8559, 0.8812, 0.8839, 0.8701, 0.8769, 0.8810, 0.8865, 0.8674,\n",
            "        0.8667, 0.8797], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7304, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1233, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8994342904143304 0.0033082706766917294\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0544, 0.0563, 0.0061,  ..., 0.0543, 0.0546, 0.0543]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9434)\n",
            "torch.Size([67, 67, 5])\n",
            "torch.Size([67, 67, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 17/3582 [00:13<38:31,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.], device='cuda:0')\n",
            "tensor([[0.8969, 0.9001, 0.7181,  ..., 0.8915, 0.8960, 0.7873]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8660, 0.8931, 0.8820, 0.8315, 0.8653, 0.8534, 0.8719, 0.8672, 0.8763,\n",
            "        0.8831, 0.9012, 0.8711, 0.8783, 0.8790, 0.9016, 0.8976, 0.8710, 0.8736,\n",
            "        0.8807, 0.8779], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1249, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8554191209787041 0.007366482504604051\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.], device='cuda:0')\n",
            "tensor([[0.0603, 0.0606, 0.0483,  ..., 0.0600, 0.0603, 0.0530]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9433)\n",
            "torch.Size([70, 70, 6])\n",
            "torch.Size([70, 70, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 18/3582 [00:14<39:21,  1.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.8942, 0.8901, 0.6602,  ..., 0.9068, 0.9076, 0.8767]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8826, 0.8684, 0.8791, 0.8852, 0.8769, 0.8745, 0.8669, 0.8865, 0.8826,\n",
            "        0.8861, 0.8841, 0.8797, 0.8996], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7379, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1193, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8532951472096323 0.0038382049010924125\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0537, 0.0535, 0.0397,  ..., 0.0545, 0.0545, 0.0527]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9435)\n",
            "torch.Size([72, 72, 6])\n",
            "torch.Size([72, 72, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 19/3582 [00:14<40:27,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9445, 0.9474, 0.2945,  ..., 0.8997, 0.9016, 0.8751]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8620, 0.8944, 0.9121, 0.8872, 0.8740, 0.8830, 0.8319, 0.8733, 0.8797,\n",
            "        0.8889, 0.8704, 0.8835, 0.8856, 0.8684, 0.8859, 0.8808],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1223, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8466710182767624 0.004596380350474001\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0562, 0.0564, 0.0175,  ..., 0.0535, 0.0537, 0.0521]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9437)\n",
            "torch.Size([69, 69, 6])\n",
            "torch.Size([69, 69, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 20/3582 [00:15<40:28,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.], device='cuda:0')\n",
            "tensor([[0.9040, 0.9053, 0.8766,  ..., 0.9036, 0.9080, 0.8618]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8354, 0.8792, 0.8802, 0.8697, 0.8724, 0.8817, 0.8822, 0.8714, 0.8632,\n",
            "        0.8841, 0.8803, 0.8795, 0.8767, 0.8702, 0.8699, 0.8722, 0.8850, 0.8697,\n",
            "        0.8689, 0.8741], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1271, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8348000853727945 0.005685856432125089\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.], device='cuda:0')\n",
            "tensor([[0.0547, 0.0547, 0.0530,  ..., 0.0546, 0.0549, 0.0521]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9439)\n",
            "torch.Size([72, 72, 6])\n",
            "torch.Size([72, 72, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 21/3582 [00:16<41:36,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9849, 0.9878, 0.3613,  ..., 0.9438, 0.9437, 0.8908]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8383, 0.9243, 0.9270, 0.9145, 0.8838, 0.9030, 0.9186, 0.8818, 0.8827,\n",
            "        0.9039, 0.8970, 0.9106, 0.8909, 0.9108], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1033, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8204822197773509 0.0035769034236075624\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0564, 0.0566, 0.0207,  ..., 0.0540, 0.0540, 0.0510]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9441)\n",
            "torch.Size([69, 69, 5])\n",
            "torch.Size([69, 69, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 22/3582 [00:16<40:32,  1.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9477, 0.9605, 0.9201,  ..., 0.9304, 0.9404, 0.9022]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8845, 0.9062, 0.9121, 0.9079, 0.9376, 0.9102, 0.9119, 0.9191, 0.9127,\n",
            "        0.9087, 0.9080, 0.9125, 0.9046, 0.9124], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0900, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8112410378968931 0.0043811610076670325\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0600, 0.0609, 0.0583,  ..., 0.0589, 0.0596, 0.0572]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9440)\n",
            "torch.Size([75, 75, 6])\n",
            "torch.Size([75, 75, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 23/3582 [00:17<42:34,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9141, 0.9185, 0.8528,  ..., 0.9199, 0.9222, 0.8981]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8742, 0.8904, 0.9047, 0.9378, 0.9400, 0.9148, 0.9025, 0.9005, 0.8758,\n",
            "        0.8813, 0.8988, 0.8737, 0.8808, 0.8824, 0.8956, 0.8785, 0.8739, 0.8745,\n",
            "        0.8860, 0.8843, 0.8883, 0.8954, 0.8445], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7465, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1115, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.867358225620455 0.005577785861525402\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0527, 0.0529, 0.0491,  ..., 0.0530, 0.0531, 0.0517]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9442)\n",
            "torch.Size([68, 68, 5])\n",
            "torch.Size([68, 68, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 24/3582 [00:18<41:12,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9000, 0.9003, 0.8609,  ..., 0.9184, 0.9197, 0.8979]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8820, 0.8747, 0.8838, 0.8350, 0.8371, 0.8431, 0.8883, 0.8813, 0.8749,\n",
            "        0.9015, 0.8477, 0.8844], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1323, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.7811822522997597 0.004289544235924933\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0597, 0.0597, 0.0571,  ..., 0.0609, 0.0610, 0.0595]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9441)\n",
            "torch.Size([59, 59, 6])\n",
            "torch.Size([59, 59, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 25/3582 [00:19<41:17,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.8951, 0.9550, 0.6215,  ..., 0.9495, 0.9492, 0.9376]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9231, 0.9338, 0.9406, 0.9186, 0.9288, 0.9329, 0.9193, 0.8857],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7973, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0787, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8814461883408071 0.0027127839945744322\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0555, 0.0592, 0.0385,  ..., 0.0589, 0.0589, 0.0582]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9441)\n",
            "torch.Size([69, 69, 5])\n",
            "torch.Size([69, 69, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 26/3582 [00:19<44:48,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9063, 0.9106, 0.6471,  ..., 0.9149, 0.9205, 0.9200]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8679, 0.8310, 0.8705, 0.8695, 0.8756, 0.8747, 0.8658, 0.8743, 0.8942,\n",
            "        0.8948, 0.8923, 0.9167, 0.8986, 0.8917, 0.9287, 0.8782],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1193, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8488880826361619 0.005804462180301106\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0595, 0.0597, 0.0425,  ..., 0.0600, 0.0604, 0.0604]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9440)\n",
            "torch.Size([74, 74, 6])\n",
            "torch.Size([74, 74, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 27/3582 [00:20<50:00,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9199, 0.9226, 0.8355,  ..., 0.9198, 0.9200, 0.8748]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8745, 0.8983, 0.8822, 0.9099, 0.9035, 0.8939, 0.8832, 0.8832, 0.9055,\n",
            "        0.8989, 0.8874, 0.8967, 0.9281, 0.9132, 0.8810, 0.8954, 0.8631],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7551, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1071, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8310781104090287 0.004276729559748427\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0527, 0.0529, 0.0479,  ..., 0.0527, 0.0527, 0.0502]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9442)\n",
            "torch.Size([65, 65, 5])\n",
            "torch.Size([65, 65, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 28/3582 [00:21<49:47,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9075, 0.9092, 0.8785,  ..., 0.9317, 0.9325, 0.9054]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8933, 0.8867, 0.8825, 0.9081, 0.9008, 0.8927, 0.8979, 0.8821, 0.9040,\n",
            "        0.8990, 0.9066], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7801, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1046, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8349128011270662 0.004117536964252292\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0599, 0.0600, 0.0580,  ..., 0.0615, 0.0616, 0.0598]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9441)\n",
            "torch.Size([69, 69, 5])\n",
            "torch.Size([69, 69, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 29/3582 [00:22<49:59,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9757, 0.9660, 0.4660,  ..., 0.9521, 0.9622, 0.9069]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9410, 0.9322, 0.9356, 0.9312, 0.9325, 0.9229, 0.9341, 0.9167, 0.9234,\n",
            "        0.9047, 0.9360, 0.9339, 0.9329, 0.9551, 0.9299, 0.9294, 0.9306, 0.9506],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.8020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0691, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8565336596842744 0.005568445475638051\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0606, 0.0600, 0.0289,  ..., 0.0591, 0.0597, 0.0563]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9440)\n",
            "torch.Size([67, 67, 6])\n",
            "torch.Size([67, 67, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 30/3582 [00:23<46:26,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9034, 0.8955, 0.7684,  ..., 0.9027, 0.9040, 0.8724]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8633, 0.8890, 0.9029, 0.8777, 0.9361, 0.8948, 0.8816, 0.9257, 0.8911],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1064, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8645663087844577 0.0024526502248262707\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0546, 0.0541, 0.0464,  ..., 0.0545, 0.0546, 0.0527]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9441)\n",
            "torch.Size([67, 67, 5])\n",
            "torch.Size([67, 67, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 31/3582 [00:23<43:26,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9238, 0.9192, 0.8294,  ..., 0.9488, 0.9532, 0.9101]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9036, 0.8268, 0.9113, 0.8982, 0.9037, 0.9204, 0.8999, 0.9075, 0.9237,\n",
            "        0.9006, 0.9284, 0.8983, 0.9484, 0.9124, 0.9111, 0.9076, 0.8622, 0.9055],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7765, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0993, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8374885486192906 0.006396588486140726\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0599, 0.0596, 0.0538,  ..., 0.0616, 0.0618, 0.0590]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9440)\n",
            "torch.Size([72, 72, 6])\n",
            "torch.Size([72, 72, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 32/3582 [00:24<43:17,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.9660, 0.9560, 0.8037,  ..., 0.9250, 0.9253, 0.9053]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.8608, 0.9312, 0.8895, 0.8952, 0.8686, 0.8944, 0.8800, 0.8962, 0.8830,\n",
            "        0.8945, 0.8848, 0.8889, 0.8836, 0.8832, 0.8847, 0.8918, 0.8778, 0.9011,\n",
            "        0.8974, 0.8760, 0.9476, 0.8884], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1106, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8131374143683141 0.005517933283170304\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([[0.0562, 0.0556, 0.0468,  ..., 0.0538, 0.0538, 0.0527]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9441)\n",
            "torch.Size([67, 67, 5])\n",
            "torch.Size([67, 67, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 33/3582 [00:25<41:09,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9064, 0.9519, 0.4195,  ..., 0.9577, 0.9625, 0.9210]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9147, 0.9168, 0.9230, 0.9173, 0.9304, 0.9167, 0.9230, 0.9278, 0.9224,\n",
            "        0.9323, 0.9212, 0.9221, 0.9117, 0.9389, 0.9194, 0.9250, 0.9273],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor(0.7872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0773, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.875014655255108 0.0058219178082191785\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0579, 0.0608, 0.0268,  ..., 0.0612, 0.0615, 0.0589]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9440)\n",
            "torch.Size([72, 72, 5])\n",
            "torch.Size([72, 72, 5])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 34/3582 [00:25<40:57,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.9218, 0.9390, 0.6540,  ..., 0.9314, 0.9389, 0.9234]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.9400, 0.8947, 0.9178, 0.9030, 0.9100, 0.8940, 0.9118, 0.8996, 0.8961,\n",
            "        0.9135, 0.8967, 0.9067, 0.9010, 0.9439, 0.9050], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor(0.7671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0923, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
            "0.8796500848674762 0.004731114966093676\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0581, 0.0592, 0.0412,  ..., 0.0587, 0.0592, 0.0582]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9440)\n",
            "torch.Size([78, 78, 6])\n",
            "torch.Size([78, 78, 6])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 34/3582 [00:26<46:32,  1.27it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-0667ad4e3e86>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpds_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mestimate_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpds_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0mGMSE_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0madj_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-20ca17942a00>\u001b[0m in \u001b[0;36mestimate_w\u001b[0;34m(signal_vtx, signals_edge, adj_tensor, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0madj_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-7204c37dd995>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, smooth, max_iter)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# w_list[:, i, :] = w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "step = 0\n",
        "GMSE_error = 0\n",
        "total_samples = 0\n",
        "link_errors = []\n",
        "sigma = 1e-3\n",
        "\n",
        "for batch in tqdm.tqdm(test_loader):\n",
        "  step+=1\n",
        "  batch.to(device)\n",
        "  model.to(device)\n",
        "  pds_opt = PDS(1, 1, 1e-2)\n",
        "  \n",
        "  node_out, edge_out = model.hetero_linear(batch)\n",
        "  n_emb, adj_tsr = batch_to_adjtensor(batch, node_out, edge_out)\n",
        "  # r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[0] != 0]\n",
        "  r_emb = [edge_out['_'.join(e_type)] for e_type in batch.edge_types if batch[e_type].edge_index.shape[-1] != 0]\n",
        "  \n",
        "  r_emb = torch.cat(r_emb, dim=0)\n",
        "  diff_tensor = (n_emb[:, None, None, :] - n_emb[None,: , None, :]) * r_emb[ None, None, :, :]\n",
        "  num_nodes,_,num_relations ,K = diff_tensor.shape\n",
        "  smooth_tensor = torch.norm(diff_tensor, dim=-1)**2\n",
        "  # est_tensor = torch.exp(- 1/sigma * smooth_tensor)\n",
        "  adj_tsr = adj_tsr.unsqueeze(0).to(device)\n",
        "  \n",
        "  mask = torch.triu(torch.ones(num_nodes, num_nodes), diagonal=1).bool()\n",
        "  adj_vec = adj_tsr[:, mask].view(1, -1)\n",
        "  print(smooth_tensor.shape)\n",
        "  w = pds_opt.solve(smooth_tensor.unsqueeze(0), max_iter = 500)\n",
        "  estimate_w(n_emb, r_emb, adj_tsr.squeeze(0), pds_opt)\n",
        "  GMSE_error += torch.sum(torch.square(w-adj_vec))\n",
        "\n",
        "  num_samples = w.shape[0] * w.shape[1]*w.shape[0]\n",
        "  total_samples += num_samples\n",
        "\n",
        "  edge_indices = torch.where(adj_vec == 1)\n",
        "  \n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = w[edge_indices]\n",
        "  print(adj_vec[edge_indices])\n",
        "  print(w)\n",
        "  link_error = torch.mean(torch.square(adj_vec[edge_indices] - out_edges))\n",
        "  link_errors.append(torch.sqrt(link_error))\n",
        "  print(GMSE_error/total_samples)\n",
        "  print(torch.mean(torch.tensor(link_errors)))\n",
        "  # auc = roc_auc_score(adj_vec[edge_indices].to('cpu').detach().numpy(), out_edges.to('cpu').detach().numpy())\n",
        "  # print(auc)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C3OSs4jQQFy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAyG4X36D1Bt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "a = torch.arange(36).view(3,3,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AOCOAEb_8bV",
        "outputId": "f28a9917-c1d1-44fc-852f-05f31a4c26ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 1., 1.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_matrix(a, k):\n",
        "    # Create an identity matrix with shape a * b\n",
        "    eye = np.eye(a)\n",
        "\n",
        "    # Repeat each element k times along the column axis\n",
        "    repeated_eye = np.repeat(eye, k, axis=1)\n",
        "\n",
        "    return repeated_eye\n",
        "\n",
        "generate_matrix(2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnjCbMepfG3I"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import HGTLoader\n",
        "\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "import torch_geometric.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "loader = HGTLoader(\n",
        "  data,\n",
        "  # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "  num_samples={key: [16] * 4 for key in data.node_types},\n",
        "  # Use a batch size of 128 for sampling training nodes of type paper\n",
        "  batch_size=8,\n",
        "  input_nodes=('paper'),\n",
        "  )\n",
        "\n",
        "sampled_hetero_data = next(iter(loader))\n",
        "def connected_graph(sampled_graph):\n",
        "  subsampled_G = sampled_graph.to_homogeneous()\n",
        "  largest_component = T.LargestConnectedComponents(num_components=1, connection = 'strong')(subsampled_G)\n",
        "  adj = to_scipy_sparse_matrix(subsampled_G.edge_index, num_nodes=subsampled_G.num_nodes)\n",
        "  return largest_component, adj\n",
        "\n",
        "connected_subsample, adj = connected_graph(sampled_hetero_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldJSUBTJCQBF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWHBVXiljqdb"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "# from torch_geometric.data import dataset\n",
        "def sampling_hetero_graphs(hetero_graph, nnodes_per_type,graph_depth):\n",
        "  input_node = 'paper'\n",
        "  num_samples = 1000\n",
        "  rd_idx = np.random.choice(len(data[input_node].x),num_samples,replace=False)\n",
        "  \n",
        "  loader = HGTLoader(\n",
        "  hetero_graph,\n",
        "  # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "  num_samples={key: [nnodes_per_type] * graph_depth for key in hetero_graph.node_types},\n",
        "  # Use a batch size of 128 for sampling training nodes of type paper\n",
        "  batch_size=1,\n",
        "  input_nodes=(input_node),\n",
        "  )\n",
        "  sub_graphs = []\n",
        "  for idx in rd_idx:\n",
        "    sampled_graph = loader.collate_fn(index=[idx])\n",
        "    connected_subsample, adj = connected_graph(loader.filter_fn(sampled_graph))\n",
        "    sub_graphs.append(connected_subsample)\n",
        "    # sub_graphs.append(sampled_graph)\n",
        "  graph_loader = DataLoader(sub_graphs, batch_size=4, shuffle=False)\n",
        "  return graph_loader\n",
        "\n",
        "data_loader = sampling_hetero_graphs(data, 16, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdkRrtaVA48P"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import HeteroConv, Linear, SAGEConv, HeteroDictLinear\n",
        "\n",
        "class LinearProj(torch.nn.Module):\n",
        "    def __init__(self, node_shape, edge_shape, out_channels):\n",
        "        super().__init__()\n",
        "        self.NodeLinear = HeteroDictLinear(in_channels=node_shape,out_channels=out_channels)\n",
        "        self.EdgeLinear = HeteroDictLinear(in_channels=edge_shape,out_channels=out_channels)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      node_attrs = {node_type: batch[node_type].x for node_type in batch.node_types}\n",
        "      num_edges = {edge_type: len(batch[edge_type].e_id) for edge_type in batch.edge_types}\n",
        "      edge_attrs = {'_'.join(edge_type): batch[edge_type].x.repeat(num_edges[edge_type], 1) for edge_type in batch.edge_types}\n",
        "      node_out = self.NodeLinear(node_attrs)\n",
        "      edge_out = self.EdgeLinear(edge_attrs)\n",
        "      \n",
        "      for node_type in batch.node_types:\n",
        "        node_out[node_type] = node_out[node_type]/(node_out[node_type].norm(dim=1)[:, None])\n",
        "      for edge_type in edge_attrs:\n",
        "        edge_out[edge_type] = edge_out[edge_type]/(edge_out[edge_type].norm(dim=1)[:, None])\n",
        "      \n",
        "\n",
        "      return (node_out, edge_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X86GvFMfdBZf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import numpy as np\n",
        "\n",
        "def neg_sample(batch, s_ntype, s_idx, num_samples):\n",
        "  possible_edge = [(s_type, t_type) for s_type, _ , t_type in batch.edge_types if s_ntype in [s_type, t_type]]\n",
        "  # print(possible_edge)\n",
        "  # possible_edge += [(s_ntype, s_ntype)]\n",
        "  samples = []\n",
        "  for t_type in batch.node_types:\n",
        "    # print(t_type)\n",
        "    if s_ntype == t_type: continue;\n",
        "    if (s_ntype, t_type) not in possible_edge and (t_type, s_ntype) not in possible_edge:\n",
        "      sample = np.random.choice(range(batch[t_type].x.shape[0]), num_samples, replace=True)\n",
        "      samples += [{t_type: val} for val in sample]\n",
        "    # print(samples)\n",
        "  \n",
        "  while len(samples) <= 2*num_samples:\n",
        "    # within type sampling\n",
        "    for t_type in batch.node_types:\n",
        "      if (s_ntype, t_type) in possible_edge:\n",
        "        # print((s_ntype, 'to', t_type))\n",
        "        edge_idx = batch[(s_ntype, 'to', t_type)].edge_index\n",
        "        # print(edge_idx)\n",
        "        # within_samples = negative_sampling(edge_idx, num_neg_samples=num_samples)\n",
        "        # print(edge_idx, s_idx)\n",
        "        indices = torch.where(edge_idx == s_idx)[0]\n",
        "        # Create a list of integers from 0 to 33, excluding 2, 5, and 10\n",
        "        numbers = [i for i in range(batch[t_type].x.shape[0]) if i not in indices.tolist()]\n",
        "        try:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=False)\n",
        "        except:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=True)\n",
        "        samples += [{t_type: idx} for idx in sampled_node]\n",
        "      elif (t_type, s_ntype) in possible_edge:\n",
        "        edge_idx = batch[(t_type, 'to', s_ntype)].edge_index\n",
        "        # within_samples = negative_sampling(edge_idx, num_neg_samples=num_samples)\n",
        "        indices = torch.where(edge_idx == s_idx)[0]\n",
        "        # Create a list of integers from 0 to 33, excluding 2, 5, and 10\n",
        "        numbers = [i for i in range(batch[t_type].x.shape[0]) if i not in indices.tolist()]\n",
        "        try:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=False)\n",
        "        except:\n",
        "          sampled_node = np.random.choice(numbers, num_samples, replace=True)\n",
        "        samples += [{t_type: idx} for idx in sampled_node]\n",
        "  random.shuffle(samples)\n",
        "  samples = samples[0:2*num_samples]\n",
        "  sampels_dict = {}\n",
        "  for t_type in batch.node_types:\n",
        "    element = []\n",
        "    for item in samples:\n",
        "      key = next(iter(item))\n",
        "      if key == t_type:\n",
        "        element += [item[key]]\n",
        "    sampels_dict[t_type] =  torch.LongTensor(element)\n",
        "\n",
        "  return sampels_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvHKpXBDN5D2",
        "outputId": "339709b3-00a5-444c-8ad4-e00a9e7ea808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  \u001b[1mauthor\u001b[0m={\n",
            "    x=[35, 334],\n",
            "    y=[35],\n",
            "    train_mask=[35],\n",
            "    val_mask=[35],\n",
            "    test_mask=[35],\n",
            "    n_id=[35]\n",
            "  },\n",
            "  \u001b[1mpaper\u001b[0m={\n",
            "    x=[56, 4231],\n",
            "    n_id=[56],\n",
            "    input_id=[8],\n",
            "    batch_size=8\n",
            "  },\n",
            "  \u001b[1mterm\u001b[0m={\n",
            "    x=[64, 50],\n",
            "    n_id=[64]\n",
            "  },\n",
            "  \u001b[1mconference\u001b[0m={\n",
            "    num_nodes=11,\n",
            "    x=[11, 20],\n",
            "    n_id=[11]\n",
            "  },\n",
            "  \u001b[1m(author, to, paper)\u001b[0m={\n",
            "    edge_index=[2, 63],\n",
            "    x=[6],\n",
            "    e_id=[63]\n",
            "  },\n",
            "  \u001b[1m(paper, to, author)\u001b[0m={\n",
            "    edge_index=[2, 63],\n",
            "    x=[6],\n",
            "    e_id=[63]\n",
            "  },\n",
            "  \u001b[1m(paper, to, term)\u001b[0m={\n",
            "    edge_index=[2, 90],\n",
            "    x=[6],\n",
            "    e_id=[90]\n",
            "  },\n",
            "  \u001b[1m(paper, to, conference)\u001b[0m={\n",
            "    edge_index=[2, 3],\n",
            "    x=[6],\n",
            "    e_id=[3]\n",
            "  },\n",
            "  \u001b[1m(term, to, paper)\u001b[0m={\n",
            "    edge_index=[2, 143],\n",
            "    x=[6],\n",
            "    e_id=[143]\n",
            "  },\n",
            "  \u001b[1m(conference, to, paper)\u001b[0m={\n",
            "    edge_index=[2, 52],\n",
            "    x=[6],\n",
            "    e_id=[52]\n",
            "  }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for batch in loader:\n",
        "  print(batch)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGIS3gw65ky1"
      },
      "outputs": [],
      "source": [
        "def loss_ns(embs, neg_embs, sigma = 0.01):\n",
        "  # loss with negative sampling\n",
        "  s_emb, r_emb, t_emb = embs\n",
        "  diff_vector = r_emb * (s_emb - t_emb)\n",
        "  smooth = - 1/sigma * torch.diagonal(diff_vector @ diff_vector.t())\n",
        "  diff_neg = r_emb[None,:,:] * (s_emb[None,:,:] - neg_embs)\n",
        "  # N \\times neg_sample \\times K -> N * neg_sample \\times K\n",
        "  inner_product = torch.bmm(diff_neg, diff_neg.permute(0,2,1))\n",
        "  diagonal = torch.diagonal(inner_product, dim1 = 1, dim2= 2)\n",
        "  smooth_neg = torch.sum(torch.exp( - 1/sigma * diagonal), dim=0) + torch.exp(smooth)\n",
        "  # print(torch.exp(smooth)/smooth_neg)\n",
        "  loss = - torch.sum(torch.log(torch.exp(smooth)/smooth_neg))\n",
        "  # loss = - torch.sum(torch.exp(smooth)/smooth_neg)\n",
        "  # loss = torch.sum(smooth - torch.log(smooth_neg))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cynixjstWlZR"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loader, device):\n",
        "    total_examples = total_loss = 0\n",
        "    \"\"\"\n",
        "    for batch in loader:\n",
        "      for edge_type in batch.edge_types:\n",
        "          if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "            continue\n",
        "          s_ntype, _ , t_ntype = edge_type\n",
        "          # source node index and target node idx\n",
        "          s_idx, t_idx  = batch[edge_type].edge_index\n",
        "          for s in s_idx:\n",
        "            samples = neg_sample(batch, s_ntype, s, 5)\n",
        "    \"\"\"\n",
        "    step=0\n",
        "    for batch in loader:\n",
        "        step += 1\n",
        "        if step == 100:break;\n",
        "        optimizer.zero_grad()\n",
        "        batch_size = batch['paper'].batch_size\n",
        "        batch = batch.to(device)\n",
        "        node_out, edge_out = model(batch)\n",
        "        loss = 0\n",
        "        num_edges = 0\n",
        "        \n",
        "        for edge_type in batch.edge_types:\n",
        "          if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "            continue\n",
        "          num_edges += batch[edge_type].edge_index.shape[1]\n",
        "          # source node type and target node type\n",
        "          s_ntype, _ , t_ntype = edge_type\n",
        "          # source node index and target node idx\n",
        "          s_idx, t_idx  = batch[edge_type].edge_index\n",
        "          # source node embedding and target node embedding\n",
        "          s_nemb, t_nemb = node_out[s_ntype][s_idx], node_out[t_ntype][t_idx]\n",
        "          # relation embedding\n",
        "          r_emb = edge_out['_'.join(edge_type)]\n",
        "          tensor_list = []\n",
        "          for s in s_idx:\n",
        "            samples = neg_sample(batch, s_ntype, s, 5)\n",
        "\n",
        "            neg_emb_list = []\n",
        "            for node_type, idx_tensor in samples.items():\n",
        "              if idx_tensor is not None:\n",
        "                neg_emb_list += [node_out[node_type][idx_tensor]]\n",
        "            tensor_list += [torch.cat(neg_emb_list, dim=0)]\n",
        "          \n",
        "          neg_emb = torch.stack(tensor_list, dim=0).permute(1,0,2)\n",
        "          \n",
        "          # print(neg_emb.shape)\n",
        "          # print(s_nemb.shape, t_nemb.shape, r_emb.shape)\n",
        "          loss += loss_ns((s_nemb, r_emb, t_nemb), neg_emb, sigma = 1e-3)\n",
        "          \n",
        "          # diff_vector = r_emb * (s_nemb - t_nemb)\n",
        "          # loss += torch.trace(diff_vector.t() @ diff_vector)\n",
        "        # loss = loss / num_edges\n",
        "        # print('Your bullshit training process: step {}, loss {}'.format(step, loss))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_loss += float(loss) * batch_size\n",
        "\n",
        "    return total_loss / total_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "ikzVN0S0extJ",
        "outputId": "f80da534-17d3-41c8-bf5e-f4ea4bac2dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 596.065084129873, epoch: 1\n",
            "loss: 372.0150146484375, epoch: 2\n",
            "loss: 307.96123543170967, epoch: 3\n",
            "loss: 275.6006227743746, epoch: 4\n",
            "loss: 253.29685789166075, epoch: 5\n",
            "loss: 244.41133672540838, epoch: 6\n",
            "loss: 239.55379478377526, epoch: 7\n",
            "loss: 233.59777955334596, epoch: 8\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-64f20fafa9a9>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: {}, epoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-99e5c0013e1a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0mtensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_ntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mneg_emb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-301ba4b60674>\u001b[0m in \u001b[0;36mneg_sample\u001b[0;34m(batch, s_ntype, s_idx, num_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Create a list of integers from 0 to 33, excluding 2, 5, and 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0msampled_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-301ba4b60674>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Create a list of integers from 0 to 33, excluding 2, 5, and 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0msampled_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loader = HGTLoader(\n",
        "  data,\n",
        "  # Sample 512 nodes per type and per iteration for 4 iterations\n",
        "  num_samples={key: [16] * 4 for key in data.node_types},\n",
        "  # Use a batch size of 128 for sampling training nodes of type paper\n",
        "  batch_size=8,\n",
        "  input_nodes=('paper'),\n",
        "  )\n",
        "device = 'cuda:0'\n",
        "node_shape = {node_type: data[node_type].x.shape[-1] for node_type in data.node_types}\n",
        "edge_shape = {'_'.join(edge_type): data[edge_type].x.shape[-1] for edge_type in data.edge_types}\n",
        "model = LinearProj(node_shape, edge_shape, 100)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=0.001)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "  model.train()\n",
        "  loss = train(model, optimizer, loader, device)\n",
        "  print('loss: {}, epoch: {}'.format(loss, epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22yPa42lNwFx"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "model2 = copy.deepcopy(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-bTUsiFQPgD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "7zJB7rfelb-h",
        "outputId": "53aa1bc0-96d1-4649-bb8a-a3464e9e65b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.7781e-05, grad_fn=<DivBackward0>)\n",
            "tensor(0.9894)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n  # combinations = itertools.combinations_with_replacement(batch.node_types, 2)\\n  # possible_edge =  [(s_type,'to',t_type) for s_type,t_type in combinations]\\n  true_edge_types = batch.edge_types\\n  for edge_type in true_edge_types:\\n    if batch[edge_type].edge_index.shape[-1] ==0:\\n      continue\\n    if edge_type in true_edge_types:\\n      print(batch[edge_type].edge_index)\\n    s_ntype, _ , t_ntype = edge_type\\n    # source node embedding and target node embedding\\n    s_nemb, t_nemb = node_out[s_ntype], node_out[t_ntype]\\n    \\n    n_emb = torch.cat([s_nemb, t_nemb], dim=0)\\n    r_emb = edge_out['_'.join(edge_type)]\\n    out_product = n_emb[:, None, :] * n_emb[None,: , :] * r_emb[0][ None, None, :]\\n    N,_,K = out_product.shape\\n    out_adj = torch.sum(out_product, dim=2)\\n    print(out_adj.shape)\\n    # Use torch.topk to get the indices of K largest entrie\\n    values, indices = torch.topk(out_adj.view(-1), K)\\n    row_indices = indices // N\\n    col_indices = indices % N\\n\\n    indices = torch.stack([row_indices, col_indices], dim=0)\\n    # Convert tensors to sets\\n    true_idx = batch[edge_type].edge_index\\n    true_idx[1] += s_nemb.shape[0]\\n    set1 = set(map(tuple, true_idx.t().tolist()))\\n    set2 = set(map(tuple, indices.t().tolist()))\\n    # Find the difference between sets\\n    print(set1,set2)\\n    acc = len(set1 - set2)/len(set1)\\n    print(acc)\\n\""
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "step = 0\n",
        "model = model.to('cpu')\n",
        "GMSE_error = 0\n",
        "total_samples = 0\n",
        "link_errors = []\n",
        "\n",
        "for batch in loader:\n",
        "  step+=1\n",
        "  if step <= 100:\n",
        "    continue\n",
        "  \n",
        "  if step ==200:\n",
        "    break\n",
        "\n",
        "  node_out, edge_out = model(batch)\n",
        "  n_emb, adj_matrices = batch_to_adjtensor(batch, node_out, edge_out)\n",
        "  r_emb = [e_tensor[0] for e_type, e_tensor in edge_out.items() if e_tensor.shape[0] != 0]\n",
        "  r_emb = torch.stack(r_emb, dim=0)\n",
        "  out_product = n_emb[:, None, None, :] * n_emb[None,: , None, :] * r_emb[ None, None, :, :]\n",
        "  num_nodes,_,num_relations ,K = out_product.shape\n",
        "  out_adj = torch.sum(out_product, dim=3)\n",
        "  # print(out_adj, adj_matrices)\n",
        "  GMSE_error += torch.sum(torch.square(out_adj-adj_matrices))\n",
        "  num_samples = out_adj.shape[0] * out_adj.shape[1]*out_adj.shape[0]\n",
        "  total_samples += num_samples\n",
        "\n",
        "  edge_indices = torch.where(adj_matrices == 1)\n",
        "  # Use these indices to access the corresponding elements in B\n",
        "  out_edges = out_adj[edge_indices]\n",
        "  link_error = torch.mean(torch.square(adj_matrices[edge_indices] - out_edges))\n",
        "  link_errors.append(link_error)\n",
        "\n",
        "print(GMSE_error/total_samples)\n",
        "print(torch.mean(torch.tensor(link_errors)))\n",
        "\n",
        "# Find the indices of the 1 elements in A\n",
        "\n",
        "'''\n",
        "  # combinations = itertools.combinations_with_replacement(batch.node_types, 2)\n",
        "  # possible_edge =  [(s_type,'to',t_type) for s_type,t_type in combinations]\n",
        "  true_edge_types = batch.edge_types\n",
        "  for edge_type in true_edge_types:\n",
        "    if batch[edge_type].edge_index.shape[-1] ==0:\n",
        "      continue\n",
        "    if edge_type in true_edge_types:\n",
        "      print(batch[edge_type].edge_index)\n",
        "    s_ntype, _ , t_ntype = edge_type\n",
        "    # source node embedding and target node embedding\n",
        "    s_nemb, t_nemb = node_out[s_ntype], node_out[t_ntype]\n",
        "    \n",
        "    n_emb = torch.cat([s_nemb, t_nemb], dim=0)\n",
        "    r_emb = edge_out['_'.join(edge_type)]\n",
        "    out_product = n_emb[:, None, :] * n_emb[None,: , :] * r_emb[0][ None, None, :]\n",
        "    N,_,K = out_product.shape\n",
        "    out_adj = torch.sum(out_product, dim=2)\n",
        "    print(out_adj.shape)\n",
        "    # Use torch.topk to get the indices of K largest entrie\n",
        "    values, indices = torch.topk(out_adj.view(-1), K)\n",
        "    row_indices = indices // N\n",
        "    col_indices = indices % N\n",
        "\n",
        "    indices = torch.stack([row_indices, col_indices], dim=0)\n",
        "    # Convert tensors to sets\n",
        "    true_idx = batch[edge_type].edge_index\n",
        "    true_idx[1] += s_nemb.shape[0]\n",
        "    set1 = set(map(tuple, true_idx.t().tolist()))\n",
        "    set2 = set(map(tuple, indices.t().tolist()))\n",
        "    # Find the difference between sets\n",
        "    print(set1,set2)\n",
        "    acc = len(set1 - set2)/len(set1)\n",
        "    print(acc)\n",
        "'''\n",
        "    \n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gzov4LywHNS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Assuming you have two tensors of shape 2xK\n",
        "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor2 = torch.tensor([[1, 2, 7], [4, 5, 8]])\n",
        "\n",
        "# Convert tensors to sets\n",
        "set1 = set(map(tuple, tensor1.t().tolist()))\n",
        "set2 = set(map(tuple, tensor2.t().tolist()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3apSmsYKYyTV"
      },
      "source": [
        "## Blessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFxAgVNc0zOO"
      },
      "outputs": [],
      "source": [
        "# Divine beast bless no bug here! \n",
        "#             \n",
        "#        \n",
        "#                         \n",
        "#                    \n",
        "#               \n",
        "#                         \n",
        "#                    \n",
        "#                         \n",
        "#               \n",
        "#                   \n",
        "#                   \n",
        "#                   \n",
        "#                   \n",
        "#                                            \n",
        "#                                            \n",
        "#                                            \n",
        "#                                            \n",
        "#                \n",
        "#                           \n",
        "#                     "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}